{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "1263ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d123af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "bfb10c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_version = 54\n",
    "CFG = {\n",
    "    'EPOCHS': 30,\n",
    "    'LEARNING_RATE':1e-2,    # 0.01\n",
    "    'BATCH_SIZE':256,  #256\n",
    "    'SEED':43,\n",
    "    'log_transform_turn': 1,  # 로그 트랜스폼을 몇번 돌릴 것인가?\n",
    "    'skew_cut':0.01,           # 왜도 얼마 이상을 로그값으로 정규화할 것인가?(100이면 안하겠다는 것)\n",
    "    'vif_cut': 10,           # 다중공선성 vif 얼마 이상을 제거할 것인가?\n",
    "    'corr_cut': 0.004,     # 일정 상관관계 이하 칼럼은 드랍\n",
    "    'outlier_corr_cut': 100,    # 이값 이상의 상관관계를 갖는 칼럼에 대해서만 아웃라이어 제거(100이면 미적용)\n",
    "    'T_Thresh': 0.3,     # Teacher model train Threshhold 최초 0.35\n",
    "    'S_Thresh': 0.325,     # Student model train Threshold 최초 0.35\n",
    "    'reduct' : 'sum',      # sum, mean\n",
    "    'drop_rate': 0.2,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "ec56d6d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/53_1_train_X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [931]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#불러오기\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_version\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_1_train_X\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pickle_filename:\n\u001b[0;32m      5\u001b[0m     train_X_1 \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(pickle_filename)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_1_train_y\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pickle_filename:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/53_1_train_X'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#불러오기\n",
    "\n",
    "with open(f\"./data/{file_version}_1_train_X\", 'rb') as pickle_filename:\n",
    "    train_X_1 = pickle.load(pickle_filename)\n",
    "with open(f\"./data/{file_version}_1_train_y\", 'rb') as pickle_filename:\n",
    "    train_y_1 = pickle.load(pickle_filename)\n",
    "with open(f\"./data/{file_version}_1_val_X\", 'rb') as pickle_filename:\n",
    "    val_X_1 = pickle.load(pickle_filename)\n",
    "with open(f\"./data/{file_version}_1_val_y\", 'rb') as pickle_filename:\n",
    "    val_y_1 = pickle.load(pickle_filename)     \n",
    "with open(f\"./data/{file_version}_1_test\", 'rb') as pickle_filename:\n",
    "    test_1 = pickle.load(pickle_filename)\n",
    "\n",
    "with open(f\"./data/{file_version}_2_train_X\", 'rb') as pickle_filename:\n",
    "    train_X_2 = pickle.load(pickle_filename)\n",
    "with open(f\"./data/{file_version}_2_train_y\", 'rb') as pickle_filename:\n",
    "    train_y_2 = pickle.load(pickle_filename)\n",
    "with open(f\"./data/{file_version}_2_val_X\", 'rb') as pickle_filename:\n",
    "    val_X_2 = pickle.load(pickle_filename)\n",
    "with open(f\"./data/{file_version}_2_val_y\", 'rb') as pickle_filename:\n",
    "    val_y_2 = pickle.load(pickle_filename)     \n",
    "with open(f\"./data/{file_version}_2_test\", 'rb') as pickle_filename:\n",
    "    test_2 = pickle.load(pickle_filename)\n",
    "\n",
    "with open(f\"./data/{file_version}_3_train_X\", 'rb') as pickle_filename:\n",
    "    train_X_3 = pickle.load(pickle_filename)\n",
    "with open(f\"./data/{file_version}_3_train_y\", 'rb') as pickle_filename:\n",
    "    train_y_3 = pickle.load(pickle_filename)\n",
    "with open(f\"./data/{file_version}_3_val_X\", 'rb') as pickle_filename:\n",
    "    val_X_3 = pickle.load(pickle_filename)\n",
    "with open(f\"./data/{file_version}_3_val_y\", 'rb') as pickle_filename:\n",
    "    val_y_3 = pickle.load(pickle_filename)     \n",
    "with open(f\"./data/{file_version}_3_test\", 'rb') as pickle_filename:\n",
    "    test_3 = pickle.load(pickle_filename)\n",
    "    \n",
    "with open(f\"./data/{file_version}_4_train_X\", 'rb') as pickle_filename:\n",
    "    train_X_4 = pickle.load(pickle_filename)\n",
    "with open(f\"./data/{file_version}_4_train_y\", 'rb') as pickle_filename:\n",
    "    train_y_4 = pickle.load(pickle_filename)\n",
    "with open(f\"./data/{file_version}_4_val_X\", 'rb') as pickle_filename:\n",
    "    val_X_4 = pickle.load(pickle_filename)\n",
    "with open(f\"./data/{file_version}_4_val_y\", 'rb') as pickle_filename:\n",
    "    val_y_4 = pickle.load(pickle_filename)     \n",
    "with open(f\"./data/{file_version}_4_test\", 'rb') as pickle_filename:\n",
    "    test_4 = pickle.load(pickle_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dbc3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_list = [train_X_1, train_X_2, train_X_3, train_X_4]\n",
    "train_y_list = [train_y_1, train_y_2, train_y_3, train_y_4]\n",
    "val_X_list = [val_X_1, val_X_2, val_X_3, val_X_4]\n",
    "val_y_list = [val_y_1, val_y_2, val_y_3, val_y_4]\n",
    "test_list = [test_1, test_2, test_3, test_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e01e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_1.shape, train_y_1.shape, val_X_1.shape, val_y_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_1.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa346ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_X, data_y, distillation=False):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.data_X = data_X\n",
    "        self.data_y = data_y\n",
    "        self.distillation = distillation\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.distillation:\n",
    "            # 지식 증류 학습 시\n",
    "            teacher_X = torch.Tensor(self.data_X.iloc[index])\n",
    "            student_X = torch.Tensor(self.data_X[test_stage_features].iloc[index])\n",
    "            y = self.data_y.values[index]\n",
    "            return teacher_X, student_X, y\n",
    "        else:\n",
    "            if self.data_y is None:\n",
    "                test_X = torch.Tensor(self.data_X.iloc[index])\n",
    "                return test_X\n",
    "            else:\n",
    "                teacher_X = torch.Tensor(self.data_X.iloc[index])\n",
    "\n",
    "                y = self.data_y.values[index]\n",
    "                return teacher_X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a5729",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_loaders = []\n",
    "val_loaders = []\n",
    "\n",
    "for a, b, c, d, e in zip(train_X_list, train_y_list, val_X_list, val_y_list, test_list):\n",
    "    \n",
    "    test_stage_features = e.iloc[:,:-1].columns\n",
    "    \n",
    "    train_dataset = CustomDataset(a, b, False)\n",
    "    val_dataset = CustomDataset(c, d, False)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False)\n",
    "    \n",
    "#     print(train_loader)\n",
    "#     print(list(train_loader))\n",
    "    \n",
    "    train_loaders.append(train_loader)\n",
    "    val_loaders.append(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f82d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Teacher, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=train_col_num, out_features=256),\n",
    "            nn.Dropout(p=CFG['drop_rate']),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=256, out_features=1024),\n",
    "            nn.Dropout(p=CFG['drop_rate']),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=256),\n",
    "            nn.Dropout(p=CFG['drop_rate']),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=256, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df40f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    # Loss Function 정의\n",
    "    criterion = nn.BCELoss(reduction = CFG['reduct']).to(device)  #BCEWithLogitsLoss\n",
    "#     criterion = nn.BCEWithLogitsLoss(reduction = CFG['reduct']).to(device)  #BCEWithLogitsLoss\n",
    "\n",
    "    for epoch in range(CFG[\"EPOCHS\"]):\n",
    "        train_loss = []\n",
    "  \n",
    "        model.train()\n",
    "        for X, y in tqdm(train_loader):\n",
    "            X = X.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_pred = model(X)\n",
    "            \n",
    "            loss = criterion(y_pred, y.reshape(-1, 1))  # loss_fn(input, target)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        val_loss, val_score = validation_teacher(model, val_loader, criterion, device)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{np.mean(train_loss) :.5f}] Val Loss : [{np.mean(val_loss) :.5f}] Val F1 Score : [{val_score:.5f}]')\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_score)\n",
    "            \n",
    "        if best_score < val_score:\n",
    "            best_model = model\n",
    "            best_score = val_score\n",
    "    print(f\"Teacher Train Best Score는 {best_score} 입니다.\")\n",
    "    return best_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ba187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def competition_metric(true, pred):\n",
    "    return f1_score(true, pred, average=\"macro\")\n",
    "\n",
    "\n",
    "def validation_teacher(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = []\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    threshold = CFG['T_Thresh']     \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(val_loader):\n",
    "            X = X.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            model_pred = model(X.to(device))\n",
    "            \n",
    "            loss = criterion(model_pred, y.reshape(-1, 1))\n",
    "            val_loss.append(loss.item())      \n",
    "            \n",
    "            model_pred = model_pred.squeeze(1).to('cpu')  # squeeze함수는 차원이 1인 차원을 제거해준다.\n",
    "            pred_labels += model_pred.tolist()\n",
    "            true_labels += y.tolist()\n",
    "        \n",
    "        #print(pred_labels[0:10])\n",
    "        # 오일상태는 0: 정상, 1: 이상\n",
    "        # 어느 임계점 thrshold보다 큰 예측 라벨을 1로 하고, 나머지를 0으로 할 것인가?\n",
    "        pred_labels = np.where(np.array(pred_labels) > threshold, 1, 0)\n",
    "        #print(pred_labels[0:10])\n",
    "        cf = confusion_matrix(true_labels, pred_labels)\n",
    "        val_f1 = competition_metric(true_labels, pred_labels)\n",
    "        \n",
    "        print(cf)\n",
    "        print(classification_report(true_labels, pred_labels, target_names=[\"0: 정상\", \"1: 이상\"]))\n",
    "    return val_loss, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8234a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teachers = []\n",
    "\n",
    "for a, b, c, d in zip(train_loaders, val_loaders, train_X_list, test_list):\n",
    "    train_col_num = len(c.columns)\n",
    "    test_stage_features = d.iloc[:,:-1].columns\n",
    "    test_col_num = len(d.columns)\n",
    "    \n",
    "    print(\"***\")\n",
    "    \n",
    "    model = Teacher()\n",
    "    model.eval()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1, threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "\n",
    "    teacher_model = train(model, optimizer, a, b, scheduler, device)\n",
    "    teachers.append(teacher_model)\n",
    "    \n",
    "    print(\"부분학습 종료\")\n",
    "    \n",
    "    \n",
    "print(\"전체 학습 종료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472994f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f48801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, teacher in enumerate(teachers):\n",
    "    PATH1 = f\"./models/{file_version}_{i}_teacher_net.pth\"\n",
    "    torch.save(teacher.state_dict(), PATH1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a48542",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Student, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=test_col_num, out_features=128),\n",
    "            nn.Dropout(p=CFG['drop_rate']),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=128, out_features=512),\n",
    "            nn.Dropout(p=CFG['drop_rate']),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=512, out_features=128),\n",
    "            nn.Dropout(p=CFG['drop_rate']),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=128, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "id": "2c14e299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distillation Function 정의\n",
    "\n",
    "# def distillation(student_logits, labels, teacher_logits, alpha, T):\n",
    "def distillation(student_logits, labels, teacher_logits, alpha):\n",
    "\n",
    "    student_loss = nn.BCELoss(reduction = CFG['reduct'])(student_logits, labels.reshape(-1, 1)) #BCEWithLogitsLoss\n",
    "#     student_loss = nn.BCEWithLogitsLoss(reduction = CFG['reduct'])(student_logits, labels.reshape(-1, 1)) #BCEWithLogitsLoss\n",
    "    \n",
    "    distillation_loss = nn.BCELoss()(student_logits, teacher_logits)\n",
    "#     distillation_loss = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(student_logits/T, dim=1), F.softmax(teacher_logits/T, dim=1)) * (T * T)\n",
    "    \n",
    "    return alpha * student_loss + (1-alpha) * distillation_loss\n",
    "\n",
    "def distill_loss(output, target, teacher_output, loss_fn=distillation, opt=optimizer):\n",
    "#     loss_b = loss_fn(output, target, teacher_output, alpha=0.1, T=10)\n",
    "    loss_b = loss_fn(output, target, teacher_output, alpha=0.1)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss_b.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss_b.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "id": "f9f84cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_train(s_model, t_model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    s_model.to(device)\n",
    "    t_model.to(device)\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(CFG[\"EPOCHS\"]):\n",
    "        train_loss = []\n",
    "        s_model.train()\n",
    "        t_model.eval()    # teather는 이번에는 학습하지 않으므로 .eval()로 불러온다\n",
    "        \n",
    "        for X_t, X_s, y in tqdm(train_loader):\n",
    "            X_t = X_t.float().to(device)\n",
    "            X_s = X_s.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = s_model(X_s)\n",
    "            with torch.no_grad():\n",
    "                teacher_output = t_model(X_t)\n",
    "                \n",
    "            loss_b = distill_loss(output, y, teacher_output, loss_fn=distillation, opt=optimizer)\n",
    "\n",
    "            train_loss.append(loss_b)\n",
    "\n",
    "        val_loss, val_score = validation_student(s_model, t_model, val_loader, distill_loss, device)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{np.mean(train_loss) :.5f}] Val Loss : [{np.mean(val_loss) :.5f}] Val F1 Score : [{val_score:.5f}]')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_score)\n",
    "            \n",
    "        if best_score < val_score:\n",
    "            best_model = s_model\n",
    "            best_score = val_score\n",
    "    \n",
    "    print(f\"Student Train Best Score는 {best_score} 입니다.\")\n",
    "        \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "id": "82f4a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_student(s_model, t_model, val_loader, criterion, device):\n",
    "    s_model.eval()\n",
    "    t_model.eval()\n",
    "\n",
    "    val_loss = []\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    threshold = CFG['S_Thresh']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_t, X_s, y in tqdm(val_loader):\n",
    "            X_t = X_t.float().to(device)\n",
    "            X_s = X_s.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            model_pred = s_model(X_s)\n",
    "            teacher_output = t_model(X_t)\n",
    "            \n",
    "            loss_b = distill_loss(model_pred, y, teacher_output, loss_fn=distillation, opt=None)\n",
    "            val_loss.append(loss_b)\n",
    "            \n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            pred_labels += model_pred.tolist()\n",
    "            true_labels += y.tolist()\n",
    "        \n",
    "        pred_labels = np.where(np.array(pred_labels) > threshold, 1, 0)\n",
    "        val_f1 = competition_metric(true_labels, pred_labels)\n",
    "        cf = confusion_matrix(true_labels, pred_labels)        \n",
    "        print(cf)\n",
    "        print(classification_report(true_labels, pred_labels, target_names=[\"0: 정상\", \"1: 이상\"]))\n",
    "        \n",
    "    return val_loss, val_f1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "id": "6a37f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_train_loaders = []\n",
    "s_val_loaders = []\n",
    "\n",
    "for a, b, c, d, e in zip(train_X_list, train_y_list, val_X_list, val_y_list, test_list):\n",
    "    \n",
    "    test_stage_features = e.iloc[:,:-1].columns\n",
    "    \n",
    "    train_dataset = CustomDataset(a, b, True)\n",
    "    val_dataset = CustomDataset(c, d, True)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False)\n",
    "    \n",
    "#     print(train_loader)\n",
    "#     print(list(train_loader))\n",
    "    \n",
    "    s_train_loaders.append(train_loader)\n",
    "    s_val_loaders.append(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "id": "c1a5581f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da121ff40ce3457d9186bd092879170a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b59a92a094744e4a00221732b20a435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[653  63]\n",
      " [ 51  11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.91      0.92       716\n",
      "       1: 이상       0.15      0.18      0.16        62\n",
      "\n",
      "    accuracy                           0.85       778\n",
      "   macro avg       0.54      0.54      0.54       778\n",
      "weighted avg       0.87      0.85      0.86       778\n",
      "\n",
      "Epoch [0], Train Loss : [9.26073] Val Loss : [6.28388] Val F1 Score : [0.54074]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d90748cbbc40289bf761a975dcc44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1ec31a112247bcbbbdc2ba2b51587d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[599 117]\n",
      " [ 43  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.84      0.88       716\n",
      "       1: 이상       0.14      0.31      0.19        62\n",
      "\n",
      "    accuracy                           0.79       778\n",
      "   macro avg       0.54      0.57      0.54       778\n",
      "weighted avg       0.87      0.79      0.83       778\n",
      "\n",
      "Epoch [1], Train Loss : [7.03595] Val Loss : [6.55925] Val F1 Score : [0.53705]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f64052cd304a248b2ea78ebded3f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eebc4e2a2ae4f4f9a0f3dbd11dd217e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[692  24]\n",
      " [ 55   7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.97      0.95       716\n",
      "       1: 이상       0.23      0.11      0.15        62\n",
      "\n",
      "    accuracy                           0.90       778\n",
      "   macro avg       0.58      0.54      0.55       778\n",
      "weighted avg       0.87      0.90      0.88       778\n",
      "\n",
      "Epoch [2], Train Loss : [6.43197] Val Loss : [5.77777] Val F1 Score : [0.54827]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9f007819a34cd4917a5cceee8410a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56eeb7344c54972ac42c4d684f8b7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[661  55]\n",
      " [ 52  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.92      0.93       716\n",
      "       1: 이상       0.15      0.16      0.16        62\n",
      "\n",
      "    accuracy                           0.86       778\n",
      "   macro avg       0.54      0.54      0.54       778\n",
      "weighted avg       0.87      0.86      0.86       778\n",
      "\n",
      "Epoch [3], Train Loss : [6.07848] Val Loss : [6.05607] Val F1 Score : [0.54130]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab6a08eb85b45d69364fe17ee155c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ce21b58b444ca0bd67ce1e829ed5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[677  39]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.95      0.94       716\n",
      "       1: 이상       0.19      0.15      0.16        62\n",
      "\n",
      "    accuracy                           0.88       778\n",
      "   macro avg       0.56      0.55      0.55       778\n",
      "weighted avg       0.87      0.88      0.87       778\n",
      "\n",
      "Epoch [4], Train Loss : [6.04638] Val Loss : [5.97990] Val F1 Score : [0.55001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05774ecc20664a8aaf4abf511ac6ac04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0760cb73a141a1951f372786532eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[679  37]\n",
      " [ 55   7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.95      0.94       716\n",
      "       1: 이상       0.16      0.11      0.13        62\n",
      "\n",
      "    accuracy                           0.88       778\n",
      "   macro avg       0.54      0.53      0.53       778\n",
      "weighted avg       0.86      0.88      0.87       778\n",
      "\n",
      "Epoch [5], Train Loss : [5.86318] Val Loss : [6.11696] Val F1 Score : [0.53431]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b364acd1a3804c3db20ef675775574ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a374ffc2384141928f48d712540a0d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[663  53]\n",
      " [ 52  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93       716\n",
      "       1: 이상       0.16      0.16      0.16        62\n",
      "\n",
      "    accuracy                           0.87       778\n",
      "   macro avg       0.54      0.54      0.54       778\n",
      "weighted avg       0.87      0.87      0.87       778\n",
      "\n",
      "Epoch [6], Train Loss : [5.73010] Val Loss : [6.39017] Val F1 Score : [0.54331]\n",
      "Epoch 00007: reducing learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9e1b53a7c7448c8778bb18a9022d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a08ffcc0bc247098fd641bcbf2e958f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[678  38]\n",
      " [ 57   5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.92      0.95      0.93       716\n",
      "       1: 이상       0.12      0.08      0.10        62\n",
      "\n",
      "    accuracy                           0.88       778\n",
      "   macro avg       0.52      0.51      0.51       778\n",
      "weighted avg       0.86      0.88      0.87       778\n",
      "\n",
      "Epoch [7], Train Loss : [5.53677] Val Loss : [6.29874] Val F1 Score : [0.51488]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432d56ece4c74b0f86eeed62dda0d510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbc1b31e2e14fd6bb5d4f2f0df7a892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[675  41]\n",
      " [ 55   7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.92      0.94      0.93       716\n",
      "       1: 이상       0.15      0.11      0.13        62\n",
      "\n",
      "    accuracy                           0.88       778\n",
      "   macro avg       0.54      0.53      0.53       778\n",
      "weighted avg       0.86      0.88      0.87       778\n",
      "\n",
      "Epoch [8], Train Loss : [5.37042] Val Loss : [6.39044] Val F1 Score : [0.53044]\n",
      "Epoch 00009: reducing learning rate of group 0 to 2.5000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda2ad13a8e8464db147cf47ce855d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943fd28992ad42d58bb8793a77bab9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[680  36]\n",
      " [ 55   7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.95      0.94       716\n",
      "       1: 이상       0.16      0.11      0.13        62\n",
      "\n",
      "    accuracy                           0.88       778\n",
      "   macro avg       0.54      0.53      0.54       778\n",
      "weighted avg       0.86      0.88      0.87       778\n",
      "\n",
      "Epoch [9], Train Loss : [5.24564] Val Loss : [6.32694] Val F1 Score : [0.53531]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a50c8dab84848a3a76d691cc45deda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46810fcc9c994ddaa6b1fc7bc796750c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[675  41]\n",
      " [ 55   7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.92      0.94      0.93       716\n",
      "       1: 이상       0.15      0.11      0.13        62\n",
      "\n",
      "    accuracy                           0.88       778\n",
      "   macro avg       0.54      0.53      0.53       778\n",
      "weighted avg       0.86      0.88      0.87       778\n",
      "\n",
      "Epoch [10], Train Loss : [5.02855] Val Loss : [6.48258] Val F1 Score : [0.53044]\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.2500e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3fbc9d21424c11af43480cab7d0f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c486e650ade41a7977a4e716f9847cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[670  46]\n",
      " [ 54   8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.94      0.93       716\n",
      "       1: 이상       0.15      0.13      0.14        62\n",
      "\n",
      "    accuracy                           0.87       778\n",
      "   macro avg       0.54      0.53      0.53       778\n",
      "weighted avg       0.86      0.87      0.87       778\n",
      "\n",
      "Epoch [11], Train Loss : [4.88741] Val Loss : [6.50769] Val F1 Score : [0.53424]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07634570185142bb96ed0b6963dbe9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33323e540da243658850c974568f658f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[671  45]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.94      0.93       716\n",
      "       1: 이상       0.17      0.15      0.16        62\n",
      "\n",
      "    accuracy                           0.87       778\n",
      "   macro avg       0.55      0.54      0.54       778\n",
      "weighted avg       0.87      0.87      0.87       778\n",
      "\n",
      "Epoch [12], Train Loss : [4.91885] Val Loss : [6.49265] Val F1 Score : [0.54356]\n",
      "Epoch 00013: reducing learning rate of group 0 to 6.2500e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c7b286abed4a71ba00e386d25ec7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343f1c4b9cf14402bf83044b4624c66b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[666  50]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93       716\n",
      "       1: 이상       0.15      0.15      0.15        62\n",
      "\n",
      "    accuracy                           0.87       778\n",
      "   macro avg       0.54      0.54      0.54       778\n",
      "weighted avg       0.86      0.87      0.87       778\n",
      "\n",
      "Epoch [13], Train Loss : [4.90934] Val Loss : [6.49167] Val F1 Score : [0.53849]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91384fed67d54d709af114e88ec21a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5742122e75e343009c721d822bcc4fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[667  49]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93       716\n",
      "       1: 이상       0.16      0.15      0.15        62\n",
      "\n",
      "    accuracy                           0.87       778\n",
      "   macro avg       0.54      0.54      0.54       778\n",
      "weighted avg       0.86      0.87      0.87       778\n",
      "\n",
      "Epoch [14], Train Loss : [4.87833] Val Loss : [6.49837] Val F1 Score : [0.53948]\n",
      "Epoch 00015: reducing learning rate of group 0 to 3.1250e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcbaa8d27424d0f81a2c7865f2ea797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba827753c8743b6a19e14531694bd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[665  51]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93       716\n",
      "       1: 이상       0.15      0.15      0.15        62\n",
      "\n",
      "    accuracy                           0.87       778\n",
      "   macro avg       0.54      0.54      0.54       778\n",
      "weighted avg       0.86      0.87      0.87       778\n",
      "\n",
      "Epoch [15], Train Loss : [4.72022] Val Loss : [6.55146] Val F1 Score : [0.53751]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98520a91bb743bd8522edc878e77be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe0bafe35064593899d85691952cc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[664  52]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93       716\n",
      "       1: 이상       0.15      0.15      0.15        62\n",
      "\n",
      "    accuracy                           0.87       778\n",
      "   macro avg       0.54      0.54      0.54       778\n",
      "weighted avg       0.86      0.87      0.86       778\n",
      "\n",
      "Epoch [16], Train Loss : [4.75230] Val Loss : [6.55720] Val F1 Score : [0.53653]\n",
      "Epoch 00017: reducing learning rate of group 0 to 1.5625e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85710b1fe3434743b7657f4e83d1fb61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b718406ffbd45af855ac95feb1092a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[666  50]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93       716\n",
      "       1: 이상       0.15      0.15      0.15        62\n",
      "\n",
      "    accuracy                           0.87       778\n",
      "   macro avg       0.54      0.54      0.54       778\n",
      "weighted avg       0.86      0.87      0.87       778\n",
      "\n",
      "Epoch [17], Train Loss : [4.68142] Val Loss : [6.52740] Val F1 Score : [0.53849]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18d26063bc34921a8523d7ac5bce584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7ef1b49aea458f93fd23215c03c603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[665  51]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93       716\n",
      "       1: 이상       0.15      0.15      0.15        62\n",
      "\n",
      "    accuracy                           0.87       778\n",
      "   macro avg       0.54      0.54      0.54       778\n",
      "weighted avg       0.86      0.87      0.87       778\n",
      "\n",
      "Epoch [18], Train Loss : [4.78561] Val Loss : [6.53291] Val F1 Score : [0.53751]\n",
      "Epoch 00019: reducing learning rate of group 0 to 7.8125e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc077c452ba4521b629c7caf1ca530d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3f7edff5e744a39889893bc1d01c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[670  46]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.94      0.93       716\n",
      "       1: 이상       0.16      0.15      0.15        62\n",
      "\n",
      "    accuracy                           0.87       778\n",
      "   macro avg       0.55      0.54      0.54       778\n",
      "weighted avg       0.87      0.87      0.87       778\n",
      "\n",
      "Epoch [19], Train Loss : [4.66543] Val Loss : [6.52283] Val F1 Score : [0.54252]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9790d313f6dd4a82a969712fe4e5e38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851db1d133464cd4b9071a609ad99e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[661  55]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.92      0.92       716\n",
      "       1: 이상       0.14      0.15      0.14        62\n",
      "\n",
      "    accuracy                           0.86       778\n",
      "   macro avg       0.53      0.53      0.53       778\n",
      "weighted avg       0.86      0.86      0.86       778\n",
      "\n",
      "Epoch [20], Train Loss : [4.69104] Val Loss : [6.56667] Val F1 Score : [0.53367]\n",
      "Epoch 00021: reducing learning rate of group 0 to 3.9063e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70ae42121304fdc8e49540403de4e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6451cf5cefdf4cb5913188d8a5de89d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[663  53]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93       716\n",
      "       1: 이상       0.15      0.15      0.15        62\n",
      "\n",
      "    accuracy                           0.86       778\n",
      "   macro avg       0.54      0.54      0.54       778\n",
      "weighted avg       0.86      0.86      0.86       778\n",
      "\n",
      "Epoch [21], Train Loss : [4.72749] Val Loss : [6.56020] Val F1 Score : [0.53557]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b059b668dc6b449b8b2a2e6d01a4d2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4307a5f879fc49d2a60768760697c8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[662  54]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.92      0.93       716\n",
      "       1: 이상       0.14      0.15      0.14        62\n",
      "\n",
      "    accuracy                           0.86       778\n",
      "   macro avg       0.53      0.53      0.53       778\n",
      "weighted avg       0.86      0.86      0.86       778\n",
      "\n",
      "Epoch [22], Train Loss : [4.55813] Val Loss : [6.58000] Val F1 Score : [0.53461]\n",
      "Epoch 00023: reducing learning rate of group 0 to 1.9531e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f5e5940d774c95a11d61bf73e5258e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca97f112333c4774a054594d7c43bf8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[664  52]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93       716\n",
      "       1: 이상       0.15      0.15      0.15        62\n",
      "\n",
      "    accuracy                           0.87       778\n",
      "   macro avg       0.54      0.54      0.54       778\n",
      "weighted avg       0.86      0.87      0.86       778\n",
      "\n",
      "Epoch [23], Train Loss : [4.66620] Val Loss : [6.57029] Val F1 Score : [0.53653]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606948ad34534516b22306c71fc9a0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56936d5a77494d4c80ef312597553738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[662  54]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.92      0.93       716\n",
      "       1: 이상       0.14      0.15      0.14        62\n",
      "\n",
      "    accuracy                           0.86       778\n",
      "   macro avg       0.53      0.53      0.53       778\n",
      "weighted avg       0.86      0.86      0.86       778\n",
      "\n",
      "Epoch [24], Train Loss : [4.52573] Val Loss : [6.55774] Val F1 Score : [0.53461]\n",
      "Epoch 00025: reducing learning rate of group 0 to 9.7656e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999528c7506f43b2ab11622a7614e070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6196cb33f50d419d9650d9a78219965d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[665  51]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93       716\n",
      "       1: 이상       0.15      0.15      0.15        62\n",
      "\n",
      "    accuracy                           0.87       778\n",
      "   macro avg       0.54      0.54      0.54       778\n",
      "weighted avg       0.86      0.87      0.87       778\n",
      "\n",
      "Epoch [25], Train Loss : [4.70290] Val Loss : [6.55591] Val F1 Score : [0.53751]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2410fe61ade14704b3ac881bce9d530e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2822ed0eb34358a33b994bc72836ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[659  57]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.92      0.92       716\n",
      "       1: 이상       0.14      0.15      0.14        62\n",
      "\n",
      "    accuracy                           0.86       778\n",
      "   macro avg       0.53      0.53      0.53       778\n",
      "weighted avg       0.86      0.86      0.86       778\n",
      "\n",
      "Epoch [26], Train Loss : [4.61809] Val Loss : [6.59656] Val F1 Score : [0.53180]\n",
      "Epoch 00027: reducing learning rate of group 0 to 4.8828e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc59f2eac5342fc956d723a1f4615ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cd312d8cea4e098dbcf6c74998eb6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[663  53]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93       716\n",
      "       1: 이상       0.15      0.15      0.15        62\n",
      "\n",
      "    accuracy                           0.86       778\n",
      "   macro avg       0.54      0.54      0.54       778\n",
      "weighted avg       0.86      0.86      0.86       778\n",
      "\n",
      "Epoch [27], Train Loss : [4.66940] Val Loss : [6.57349] Val F1 Score : [0.53557]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9552d0de250541e194eb0b90ab0f0e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464ccad4038c4d68b80a3ccd3ad49503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[661  55]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.92      0.92       716\n",
      "       1: 이상       0.14      0.15      0.14        62\n",
      "\n",
      "    accuracy                           0.86       778\n",
      "   macro avg       0.53      0.53      0.53       778\n",
      "weighted avg       0.86      0.86      0.86       778\n",
      "\n",
      "Epoch [28], Train Loss : [4.67149] Val Loss : [6.60620] Val F1 Score : [0.53367]\n",
      "Epoch 00029: reducing learning rate of group 0 to 2.4414e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e73531afed487e9ee4da48ab938ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf79690323f4d70a1bac198d3fda279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[662  54]\n",
      " [ 53   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.92      0.93       716\n",
      "       1: 이상       0.14      0.15      0.14        62\n",
      "\n",
      "    accuracy                           0.86       778\n",
      "   macro avg       0.53      0.53      0.53       778\n",
      "weighted avg       0.86      0.86      0.86       778\n",
      "\n",
      "Epoch [29], Train Loss : [4.68638] Val Loss : [6.56858] Val F1 Score : [0.53461]\n",
      "Student Train Best Score는 0.5500062869357475 입니다.\n",
      "부분학습 종료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bd1663716149e7a85dfefb8a6b4417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fc021a0dba458d8490db8a0f34c623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[417   6]\n",
      " [ 41   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.99      0.95       423\n",
      "       1: 이상       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.90       464\n",
      "   macro avg       0.46      0.49      0.47       464\n",
      "weighted avg       0.83      0.90      0.86       464\n",
      "\n",
      "Epoch [0], Train Loss : [9.56210] Val Loss : [7.83331] Val F1 Score : [0.47333]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57dfa15df39c47d1a2f99ae600cad8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e4f1aa666f4ba59106c3782c090d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[419   4]\n",
      " [ 41   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.99      0.95       423\n",
      "       1: 이상       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.90       464\n",
      "   macro avg       0.46      0.50      0.47       464\n",
      "weighted avg       0.83      0.90      0.87       464\n",
      "\n",
      "Epoch [1], Train Loss : [7.99039] Val Loss : [7.75665] Val F1 Score : [0.47452]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abfb907b46a4ffaa633be13a39b48be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb8e0e46c4c4e1e896e4b4fdbf39477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[408  15]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.96      0.94       423\n",
      "       1: 이상       0.17      0.07      0.10        41\n",
      "\n",
      "    accuracy                           0.89       464\n",
      "   macro avg       0.54      0.52      0.52       464\n",
      "weighted avg       0.85      0.89      0.87       464\n",
      "\n",
      "Epoch [2], Train Loss : [7.02063] Val Loss : [7.97448] Val F1 Score : [0.52035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5e8f1302aa41dc96bcc4a59afb27cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd43f6bd5c64614b0670358024eb7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[411  12]\n",
      " [ 41   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.97      0.94       423\n",
      "       1: 이상       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.89       464\n",
      "   macro avg       0.45      0.49      0.47       464\n",
      "weighted avg       0.83      0.89      0.86       464\n",
      "\n",
      "Epoch [3], Train Loss : [6.63590] Val Loss : [8.12063] Val F1 Score : [0.46971]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a6207e108843068b60e4da72dfc3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528430680b064ef88233639fcc043f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[422   1]\n",
      " [ 41   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      1.00      0.95       423\n",
      "       1: 이상       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.91       464\n",
      "   macro avg       0.46      0.50      0.48       464\n",
      "weighted avg       0.83      0.91      0.87       464\n",
      "\n",
      "Epoch [4], Train Loss : [6.28609] Val Loss : [8.33312] Val F1 Score : [0.47630]\n",
      "Epoch 00005: reducing learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbbec562ef84e81a69be867ce18eec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9f7be94ea44b3db00b00c8deab923f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[416   7]\n",
      " [ 41   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.98      0.95       423\n",
      "       1: 이상       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.90       464\n",
      "   macro avg       0.46      0.49      0.47       464\n",
      "weighted avg       0.83      0.90      0.86       464\n",
      "\n",
      "Epoch [5], Train Loss : [6.12524] Val Loss : [8.23694] Val F1 Score : [0.47273]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f80b5f19e140859cedd7eafcfb5104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6e6dc4172e4b8b88a803f365853883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[410  13]\n",
      " [ 41   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.97      0.94       423\n",
      "       1: 이상       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.88       464\n",
      "   macro avg       0.45      0.48      0.47       464\n",
      "weighted avg       0.83      0.88      0.86       464\n",
      "\n",
      "Epoch [6], Train Loss : [5.91146] Val Loss : [8.42414] Val F1 Score : [0.46911]\n",
      "Epoch 00007: reducing learning rate of group 0 to 2.5000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80f4af6e7634916886041dec0e00b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1426adc08074181a0113607ff583a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[406  17]\n",
      " [ 40   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.96      0.93       423\n",
      "       1: 이상       0.06      0.02      0.03        41\n",
      "\n",
      "    accuracy                           0.88       464\n",
      "   macro avg       0.48      0.49      0.48       464\n",
      "weighted avg       0.83      0.88      0.85       464\n",
      "\n",
      "Epoch [7], Train Loss : [5.86587] Val Loss : [8.38147] Val F1 Score : [0.48415]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e11144cabf499c84685411d465d1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e363f3404dbf475e872dfab9bed603fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[405  18]\n",
      " [ 39   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.96      0.93       423\n",
      "       1: 이상       0.10      0.05      0.07        41\n",
      "\n",
      "    accuracy                           0.88       464\n",
      "   macro avg       0.51      0.50      0.50       464\n",
      "weighted avg       0.84      0.88      0.86       464\n",
      "\n",
      "Epoch [8], Train Loss : [5.66863] Val Loss : [8.33381] Val F1 Score : [0.49991]\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.2500e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d74d3d5541e4a5a80c9949f19b43c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449b8fc4600042438b036877c28b509a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[406  17]\n",
      " [ 39   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.96      0.94       423\n",
      "       1: 이상       0.11      0.05      0.07        41\n",
      "\n",
      "    accuracy                           0.88       464\n",
      "   macro avg       0.51      0.50      0.50       464\n",
      "weighted avg       0.84      0.88      0.86       464\n",
      "\n",
      "Epoch [9], Train Loss : [5.67843] Val Loss : [8.40897] Val F1 Score : [0.50108]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a5a8ccbcc4407f882fe09710a27aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7350a26f4f2b48029aee49e3ebabfbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[407  16]\n",
      " [ 39   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.96      0.94       423\n",
      "       1: 이상       0.11      0.05      0.07        41\n",
      "\n",
      "    accuracy                           0.88       464\n",
      "   macro avg       0.51      0.51      0.50       464\n",
      "weighted avg       0.84      0.88      0.86       464\n",
      "\n",
      "Epoch [10], Train Loss : [5.42459] Val Loss : [8.41096] Val F1 Score : [0.50225]\n",
      "Epoch 00011: reducing learning rate of group 0 to 6.2500e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7547483faa4336a48618ca829eb719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03a1fb6250748f7a6b77265ae497e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[406  17]\n",
      " [ 39   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.96      0.94       423\n",
      "       1: 이상       0.11      0.05      0.07        41\n",
      "\n",
      "    accuracy                           0.88       464\n",
      "   macro avg       0.51      0.50      0.50       464\n",
      "weighted avg       0.84      0.88      0.86       464\n",
      "\n",
      "Epoch [11], Train Loss : [5.51441] Val Loss : [8.44967] Val F1 Score : [0.50108]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b75e44c7534328a4a83e96b7fa1871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db221d5a6dd94d6184122c76119ce1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[406  17]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.96      0.94       423\n",
      "       1: 이상       0.15      0.07      0.10        41\n",
      "\n",
      "    accuracy                           0.88       464\n",
      "   macro avg       0.53      0.52      0.52       464\n",
      "weighted avg       0.85      0.88      0.86       464\n",
      "\n",
      "Epoch [12], Train Loss : [5.49103] Val Loss : [8.51329] Val F1 Score : [0.51746]\n",
      "Epoch 00013: reducing learning rate of group 0 to 3.1250e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23c269b07d64b15bc6062f47eb159ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770c49814ee241b580a21219ba873684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[403  20]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.95      0.93       423\n",
      "       1: 이상       0.13      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.88       464\n",
      "   macro avg       0.52      0.51      0.51       464\n",
      "weighted avg       0.84      0.88      0.86       464\n",
      "\n",
      "Epoch [13], Train Loss : [5.51247] Val Loss : [8.52752] Val F1 Score : [0.51331]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7790effc07a141d8875ad04631fa0f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1c69db318a4eb199abc391f9845b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[402  21]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.95      0.93       423\n",
      "       1: 이상       0.12      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.87       464\n",
      "   macro avg       0.52      0.51      0.51       464\n",
      "weighted avg       0.84      0.87      0.86       464\n",
      "\n",
      "Epoch [14], Train Loss : [5.54014] Val Loss : [8.54035] Val F1 Score : [0.51197]\n",
      "Epoch 00015: reducing learning rate of group 0 to 1.5625e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1be880d43734cb9aa2db6a4c49e430f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1cc94fb54c34e4a8b43d266e3ad5fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[402  21]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.95      0.93       423\n",
      "       1: 이상       0.12      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.87       464\n",
      "   macro avg       0.52      0.51      0.51       464\n",
      "weighted avg       0.84      0.87      0.86       464\n",
      "\n",
      "Epoch [15], Train Loss : [5.51081] Val Loss : [8.56103] Val F1 Score : [0.51197]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496f7e4635804357b3d7a26036931eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58694b201e1a4994b9c46f295fa7dae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[402  21]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.95      0.93       423\n",
      "       1: 이상       0.12      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.87       464\n",
      "   macro avg       0.52      0.51      0.51       464\n",
      "weighted avg       0.84      0.87      0.86       464\n",
      "\n",
      "Epoch [16], Train Loss : [5.40408] Val Loss : [8.54688] Val F1 Score : [0.51197]\n",
      "Epoch 00017: reducing learning rate of group 0 to 7.8125e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6243b587b24190b53e7cc7a1d90db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06da4ca20a6d4b0cb5a8392bab5b0910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[401  22]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.95      0.93       423\n",
      "       1: 이상       0.12      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.87       464\n",
      "   macro avg       0.52      0.51      0.51       464\n",
      "weighted avg       0.84      0.87      0.86       464\n",
      "\n",
      "Epoch [17], Train Loss : [5.49234] Val Loss : [8.55482] Val F1 Score : [0.51065]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6785f530e4dd46feb0ad8151ab9afb95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd4f903bdb44216a618db712d6aa57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[402  21]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.95      0.93       423\n",
      "       1: 이상       0.12      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.87       464\n",
      "   macro avg       0.52      0.51      0.51       464\n",
      "weighted avg       0.84      0.87      0.86       464\n",
      "\n",
      "Epoch [18], Train Loss : [5.34977] Val Loss : [8.56639] Val F1 Score : [0.51197]\n",
      "Epoch 00019: reducing learning rate of group 0 to 3.9063e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4cae7e7ab74559868956240b0d1743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5d6e0c82fc4982a2b0f65423155b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[401  22]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.95      0.93       423\n",
      "       1: 이상       0.12      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.87       464\n",
      "   macro avg       0.52      0.51      0.51       464\n",
      "weighted avg       0.84      0.87      0.86       464\n",
      "\n",
      "Epoch [19], Train Loss : [5.48058] Val Loss : [8.57921] Val F1 Score : [0.51065]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654315a024444761b60ac6e329205634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f184f4c779418ab4347ccb5b357cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[400  23]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.95      0.93       423\n",
      "       1: 이상       0.12      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.87       464\n",
      "   macro avg       0.51      0.51      0.51       464\n",
      "weighted avg       0.84      0.87      0.85       464\n",
      "\n",
      "Epoch [20], Train Loss : [5.44900] Val Loss : [8.57462] Val F1 Score : [0.50935]\n",
      "Epoch 00021: reducing learning rate of group 0 to 1.9531e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c078f2ffca5447298c3bf5834918de21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61518432af96463ba38901e48691fa31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[401  22]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.95      0.93       423\n",
      "       1: 이상       0.12      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.87       464\n",
      "   macro avg       0.52      0.51      0.51       464\n",
      "weighted avg       0.84      0.87      0.86       464\n",
      "\n",
      "Epoch [21], Train Loss : [5.47220] Val Loss : [8.56888] Val F1 Score : [0.51065]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16f57bdb078451cac5bab8a6d2bd0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c5b6a683c644d39fb4619694e81341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[401  22]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.95      0.93       423\n",
      "       1: 이상       0.12      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.87       464\n",
      "   macro avg       0.52      0.51      0.51       464\n",
      "weighted avg       0.84      0.87      0.86       464\n",
      "\n",
      "Epoch [22], Train Loss : [5.60742] Val Loss : [8.54874] Val F1 Score : [0.51065]\n",
      "Epoch 00023: reducing learning rate of group 0 to 9.7656e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7678b3a6514f4649b63259818c7034eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ace33e574da4668aba7076f02bc15a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[402  21]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.95      0.93       423\n",
      "       1: 이상       0.12      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.87       464\n",
      "   macro avg       0.52      0.51      0.51       464\n",
      "weighted avg       0.84      0.87      0.86       464\n",
      "\n",
      "Epoch [23], Train Loss : [5.47465] Val Loss : [8.55959] Val F1 Score : [0.51197]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5018490cc8e4af69bd81825e0fc5c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6371696a892e42828d77fbdab59aa92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[399  24]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.94      0.93       423\n",
      "       1: 이상       0.11      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.87       464\n",
      "   macro avg       0.51      0.51      0.51       464\n",
      "weighted avg       0.84      0.87      0.85       464\n",
      "\n",
      "Epoch [24], Train Loss : [5.47801] Val Loss : [8.57498] Val F1 Score : [0.50807]\n",
      "Epoch 00025: reducing learning rate of group 0 to 4.8828e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060656e12cdb4fa19da6fc143ee82f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ecdc5803de14e569c9a89914de8a0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[398  25]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.94      0.93       423\n",
      "       1: 이상       0.11      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.86       464\n",
      "   macro avg       0.51      0.51      0.51       464\n",
      "weighted avg       0.84      0.86      0.85       464\n",
      "\n",
      "Epoch [25], Train Loss : [5.34886] Val Loss : [8.53440] Val F1 Score : [0.50681]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cedd92b17044cb9cdbce589ec9b8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea6cfdb071141ffbf8737c8e95be9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[397  26]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.94      0.93       423\n",
      "       1: 이상       0.10      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.86       464\n",
      "   macro avg       0.51      0.51      0.51       464\n",
      "weighted avg       0.84      0.86      0.85       464\n",
      "\n",
      "Epoch [26], Train Loss : [5.53238] Val Loss : [8.56793] Val F1 Score : [0.50556]\n",
      "Epoch 00027: reducing learning rate of group 0 to 2.4414e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9458b1708ee54c64ac0899b1686661b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f988e4808da47918d3fd3e91a337989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[399  24]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.94      0.93       423\n",
      "       1: 이상       0.11      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.87       464\n",
      "   macro avg       0.51      0.51      0.51       464\n",
      "weighted avg       0.84      0.87      0.85       464\n",
      "\n",
      "Epoch [27], Train Loss : [5.41296] Val Loss : [8.57659] Val F1 Score : [0.50807]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a85815169b04013a968a09a7c90beb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a3b0fd89b34cb3a53be33b203adfe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[399  24]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.94      0.93       423\n",
      "       1: 이상       0.11      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.87       464\n",
      "   macro avg       0.51      0.51      0.51       464\n",
      "weighted avg       0.84      0.87      0.85       464\n",
      "\n",
      "Epoch [28], Train Loss : [5.44916] Val Loss : [8.56931] Val F1 Score : [0.50807]\n",
      "Epoch 00029: reducing learning rate of group 0 to 1.2207e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cccadabb9ca4ef789a7773e179f3da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac807cc75de4d95bd38207d2a8a7e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[399  24]\n",
      " [ 38   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.94      0.93       423\n",
      "       1: 이상       0.11      0.07      0.09        41\n",
      "\n",
      "    accuracy                           0.87       464\n",
      "   macro avg       0.51      0.51      0.51       464\n",
      "weighted avg       0.84      0.87      0.85       464\n",
      "\n",
      "Epoch [29], Train Loss : [5.39818] Val Loss : [8.57081] Val F1 Score : [0.50807]\n",
      "Student Train Best Score는 0.5203526359930565 입니다.\n",
      "부분학습 종료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1dddf40b7c94ed2b3470fc5576323bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7179c9fc6aa4f87986d592302659173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1140  143]\n",
      " [ 106   21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.89      0.90      1283\n",
      "       1: 이상       0.13      0.17      0.14       127\n",
      "\n",
      "    accuracy                           0.82      1410\n",
      "   macro avg       0.52      0.53      0.52      1410\n",
      "weighted avg       0.84      0.82      0.83      1410\n",
      "\n",
      "Epoch [0], Train Loss : [9.57970] Val Loss : [8.29978] Val F1 Score : [0.52294]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff65a3468a8464aa2f5ea6827527c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59646b1b47e40e9b2b744a457eeb642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1230   53]\n",
      " [ 114   13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.92      0.96      0.94      1283\n",
      "       1: 이상       0.20      0.10      0.13       127\n",
      "\n",
      "    accuracy                           0.88      1410\n",
      "   macro avg       0.56      0.53      0.54      1410\n",
      "weighted avg       0.85      0.88      0.86      1410\n",
      "\n",
      "Epoch [1], Train Loss : [7.40649] Val Loss : [7.38711] Val F1 Score : [0.53557]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac39529936c745bfa22f31a196375ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3a951aa1634792b8188a2829c01979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1221   62]\n",
      " [ 111   16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.92      0.95      0.93      1283\n",
      "       1: 이상       0.21      0.13      0.16       127\n",
      "\n",
      "    accuracy                           0.88      1410\n",
      "   macro avg       0.56      0.54      0.54      1410\n",
      "weighted avg       0.85      0.88      0.86      1410\n",
      "\n",
      "Epoch [2], Train Loss : [7.09253] Val Loss : [7.48422] Val F1 Score : [0.54497]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43545f7fb004589a569fd73cb35e22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de974ed30b2449a59ef2096b068fc454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1241   42]\n",
      " [ 114   13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.92      0.97      0.94      1283\n",
      "       1: 이상       0.24      0.10      0.14       127\n",
      "\n",
      "    accuracy                           0.89      1410\n",
      "   macro avg       0.58      0.53      0.54      1410\n",
      "weighted avg       0.85      0.89      0.87      1410\n",
      "\n",
      "Epoch [3], Train Loss : [6.88698] Val Loss : [7.23715] Val F1 Score : [0.54186]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbbd87b2e1d4886b10f072e083b81d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffe748215d441bdbdaf508257a8273b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1227   56]\n",
      " [ 114   13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.91      0.96      0.94      1283\n",
      "       1: 이상       0.19      0.10      0.13       127\n",
      "\n",
      "    accuracy                           0.88      1410\n",
      "   macro avg       0.55      0.53      0.53      1410\n",
      "weighted avg       0.85      0.88      0.86      1410\n",
      "\n",
      "Epoch [4], Train Loss : [6.81508] Val Loss : [7.48838] Val F1 Score : [0.53393]\n",
      "Epoch 00005: reducing learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca7e6731c474e3183968e80058c15ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c07b07f56a4ede9dd2fc485cb8abaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1210   73]\n",
      " [ 102   25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.92      0.94      0.93      1283\n",
      "       1: 이상       0.26      0.20      0.22       127\n",
      "\n",
      "    accuracy                           0.88      1410\n",
      "   macro avg       0.59      0.57      0.58      1410\n",
      "weighted avg       0.86      0.88      0.87      1410\n",
      "\n",
      "Epoch [5], Train Loss : [6.70892] Val Loss : [7.34537] Val F1 Score : [0.57739]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3654ea562d9144bea3f576ca4769ed34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c3c9bd38bd4e78b95f51a0301541c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1200   83]\n",
      " [ 104   23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.92      0.94      0.93      1283\n",
      "       1: 이상       0.22      0.18      0.20       127\n",
      "\n",
      "    accuracy                           0.87      1410\n",
      "   macro avg       0.57      0.56      0.56      1410\n",
      "weighted avg       0.86      0.87      0.86      1410\n",
      "\n",
      "Epoch [6], Train Loss : [6.58332] Val Loss : [7.43783] Val F1 Score : [0.56257]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf84dd8ddab4e21b91afa896359008b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eee5c88b17d46208e76499072d78f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1189   94]\n",
      " [  98   29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.92      0.93      0.93      1283\n",
      "       1: 이상       0.24      0.23      0.23       127\n",
      "\n",
      "    accuracy                           0.86      1410\n",
      "   macro avg       0.58      0.58      0.58      1410\n",
      "weighted avg       0.86      0.86      0.86      1410\n",
      "\n",
      "Epoch [7], Train Loss : [6.49183] Val Loss : [7.41757] Val F1 Score : [0.57865]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dccfa40d50c45ca837fb48aec0af0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e6479b3dd34bc0956dfc14c105f9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1225   58]\n",
      " [ 107   20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.92      0.95      0.94      1283\n",
      "       1: 이상       0.26      0.16      0.20       127\n",
      "\n",
      "    accuracy                           0.88      1410\n",
      "   macro avg       0.59      0.56      0.57      1410\n",
      "weighted avg       0.86      0.88      0.87      1410\n",
      "\n",
      "Epoch [8], Train Loss : [6.45169] Val Loss : [7.33360] Val F1 Score : [0.56601]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f65dc9c56a94c768d1a325f582d6a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f7a3d537fc46debb5ad829356367b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1221   62]\n",
      " [ 104   23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.92      0.95      0.94      1283\n",
      "       1: 이상       0.27      0.18      0.22       127\n",
      "\n",
      "    accuracy                           0.88      1410\n",
      "   macro avg       0.60      0.57      0.58      1410\n",
      "weighted avg       0.86      0.88      0.87      1410\n",
      "\n",
      "Epoch [9], Train Loss : [6.35807] Val Loss : [7.48454] Val F1 Score : [0.57667]\n",
      "Epoch 00010: reducing learning rate of group 0 to 2.5000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5689956d680749109225caf40f9f306c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69289d41c4f641799dbb88596dcda7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1182  101]\n",
      " [  97   30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.92      0.92      0.92      1283\n",
      "       1: 이상       0.23      0.24      0.23       127\n",
      "\n",
      "    accuracy                           0.86      1410\n",
      "   macro avg       0.58      0.58      0.58      1410\n",
      "weighted avg       0.86      0.86      0.86      1410\n",
      "\n",
      "Epoch [10], Train Loss : [6.17124] Val Loss : [7.49927] Val F1 Score : [0.57764]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca6e9fce51d49928374e229a0c56820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf067c31a8224b05be4fa16c9ec77956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1178  105]\n",
      " [  93   34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.92      0.92      1283\n",
      "       1: 이상       0.24      0.27      0.26       127\n",
      "\n",
      "    accuracy                           0.86      1410\n",
      "   macro avg       0.59      0.59      0.59      1410\n",
      "weighted avg       0.87      0.86      0.86      1410\n",
      "\n",
      "Epoch [11], Train Loss : [6.03799] Val Loss : [7.57359] Val F1 Score : [0.58906]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b87747fe12d473d813dcd843e0b1d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5af0e6b3db44414a80f0c4fc08589cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1201   82]\n",
      " [  98   29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.92      0.94      0.93      1283\n",
      "       1: 이상       0.26      0.23      0.24       127\n",
      "\n",
      "    accuracy                           0.87      1410\n",
      "   macro avg       0.59      0.58      0.59      1410\n",
      "weighted avg       0.86      0.87      0.87      1410\n",
      "\n",
      "Epoch [12], Train Loss : [5.92684] Val Loss : [7.70827] Val F1 Score : [0.58699]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef24d60ec44458d899d69a404affacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee61143a21c4bbaae29e62124c4b05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1212   71]\n",
      " [  98   29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.94      0.93      1283\n",
      "       1: 이상       0.29      0.23      0.26       127\n",
      "\n",
      "    accuracy                           0.88      1410\n",
      "   macro avg       0.61      0.59      0.60      1410\n",
      "weighted avg       0.87      0.88      0.87      1410\n",
      "\n",
      "Epoch [13], Train Loss : [5.97168] Val Loss : [7.67903] Val F1 Score : [0.59517]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56aa8a39da0940a490028867cae4bd14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9e229be1054e069c6e8bce58af596e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1169  114]\n",
      " [  94   33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.91      0.92      1283\n",
      "       1: 이상       0.22      0.26      0.24       127\n",
      "\n",
      "    accuracy                           0.85      1410\n",
      "   macro avg       0.58      0.59      0.58      1410\n",
      "weighted avg       0.86      0.85      0.86      1410\n",
      "\n",
      "Epoch [14], Train Loss : [5.85456] Val Loss : [8.03380] Val F1 Score : [0.57959]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10676724c4f1458697a5a5b9f52adc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7419dee35c9a49dd8d33596b7d045906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1178  105]\n",
      " [  95   32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.92      0.92      1283\n",
      "       1: 이상       0.23      0.25      0.24       127\n",
      "\n",
      "    accuracy                           0.86      1410\n",
      "   macro avg       0.58      0.59      0.58      1410\n",
      "weighted avg       0.86      0.86      0.86      1410\n",
      "\n",
      "Epoch [15], Train Loss : [5.84043] Val Loss : [7.87844] Val F1 Score : [0.58209]\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.2500e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5866d6dfcce947afb28615b8e14784fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca5b72c85bd4a7fa23710dd73926050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1192   91]\n",
      " [  98   29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.92      0.93      0.93      1283\n",
      "       1: 이상       0.24      0.23      0.23       127\n",
      "\n",
      "    accuracy                           0.87      1410\n",
      "   macro avg       0.58      0.58      0.58      1410\n",
      "weighted avg       0.86      0.87      0.86      1410\n",
      "\n",
      "Epoch [16], Train Loss : [5.62109] Val Loss : [7.92718] Val F1 Score : [0.58068]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f88fe6e47ad440b9dcdc77c72df0924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a21aa1ce227459c925d0055b56f5be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1215   68]\n",
      " [  97   30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.95      0.94      1283\n",
      "       1: 이상       0.31      0.24      0.27       127\n",
      "\n",
      "    accuracy                           0.88      1410\n",
      "   macro avg       0.62      0.59      0.60      1410\n",
      "weighted avg       0.87      0.88      0.88      1410\n",
      "\n",
      "Epoch [17], Train Loss : [5.63476] Val Loss : [7.93406] Val F1 Score : [0.60154]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3acd51ca67a4640aecc74ff842ba817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1071ea86808646adb7c36614d47ee56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1188   95]\n",
      " [  95   32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93      1283\n",
      "       1: 이상       0.25      0.25      0.25       127\n",
      "\n",
      "    accuracy                           0.87      1410\n",
      "   macro avg       0.59      0.59      0.59      1410\n",
      "weighted avg       0.87      0.87      0.87      1410\n",
      "\n",
      "Epoch [18], Train Loss : [5.45061] Val Loss : [8.13204] Val F1 Score : [0.58896]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39c2454efa5409b990f32f48821fe2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30fdc489150c4a4f83e21c5285ccca95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1184   99]\n",
      " [  92   35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.92      0.93      1283\n",
      "       1: 이상       0.26      0.28      0.27       127\n",
      "\n",
      "    accuracy                           0.86      1410\n",
      "   macro avg       0.59      0.60      0.60      1410\n",
      "weighted avg       0.87      0.86      0.87      1410\n",
      "\n",
      "Epoch [19], Train Loss : [5.56493] Val Loss : [8.02156] Val F1 Score : [0.59678]\n",
      "Epoch 00020: reducing learning rate of group 0 to 6.2500e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da971dc138c446a1b23954a8803b0d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0698c3c2952647c3834f784409396164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1187   96]\n",
      " [  94   33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93      1283\n",
      "       1: 이상       0.26      0.26      0.26       127\n",
      "\n",
      "    accuracy                           0.87      1410\n",
      "   macro avg       0.59      0.59      0.59      1410\n",
      "weighted avg       0.87      0.87      0.87      1410\n",
      "\n",
      "Epoch [20], Train Loss : [5.48639] Val Loss : [8.09007] Val F1 Score : [0.59185]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b67b3919184a338ad31c44de515031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d772b6924041f390443701c043e513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1220   63]\n",
      " [  98   29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.95      0.94      1283\n",
      "       1: 이상       0.32      0.23      0.26       127\n",
      "\n",
      "    accuracy                           0.89      1410\n",
      "   macro avg       0.62      0.59      0.60      1410\n",
      "weighted avg       0.87      0.89      0.88      1410\n",
      "\n",
      "Epoch [21], Train Loss : [5.43143] Val Loss : [8.00557] Val F1 Score : [0.60147]\n",
      "Epoch 00022: reducing learning rate of group 0 to 3.1250e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdf0f070e0f4418acd7074148e478a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcee08fe7f54ed284093aa84e7cfd6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1197   86]\n",
      " [  95   32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93      1283\n",
      "       1: 이상       0.27      0.25      0.26       127\n",
      "\n",
      "    accuracy                           0.87      1410\n",
      "   macro avg       0.60      0.59      0.60      1410\n",
      "weighted avg       0.87      0.87      0.87      1410\n",
      "\n",
      "Epoch [22], Train Loss : [5.32244] Val Loss : [8.06945] Val F1 Score : [0.59547]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4563169987664daf870c98af6943053e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ad8aba0c8f4f1fa1a2c1204c005e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1192   91]\n",
      " [  92   35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93      1283\n",
      "       1: 이상       0.28      0.28      0.28       127\n",
      "\n",
      "    accuracy                           0.87      1410\n",
      "   macro avg       0.60      0.60      0.60      1410\n",
      "weighted avg       0.87      0.87      0.87      1410\n",
      "\n",
      "Epoch [23], Train Loss : [5.26412] Val Loss : [8.22623] Val F1 Score : [0.60270]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ee659b878f4f18a870be3bd002d11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24218f6fc4247109a3a4d5245d80c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1183  100]\n",
      " [  93   34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.92      0.92      1283\n",
      "       1: 이상       0.25      0.27      0.26       127\n",
      "\n",
      "    accuracy                           0.86      1410\n",
      "   macro avg       0.59      0.59      0.59      1410\n",
      "weighted avg       0.87      0.86      0.86      1410\n",
      "\n",
      "Epoch [24], Train Loss : [5.20228] Val Loss : [8.16057] Val F1 Score : [0.59256]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06738c5593274dec8a4ea6ce4c38f50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c824aeeb224cff8279f045eb637abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1193   90]\n",
      " [  94   33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93      1283\n",
      "       1: 이상       0.27      0.26      0.26       127\n",
      "\n",
      "    accuracy                           0.87      1410\n",
      "   macro avg       0.60      0.59      0.60      1410\n",
      "weighted avg       0.87      0.87      0.87      1410\n",
      "\n",
      "Epoch [25], Train Loss : [5.34315] Val Loss : [8.13448] Val F1 Score : [0.59620]\n",
      "Epoch 00026: reducing learning rate of group 0 to 1.5625e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe07fbc234d40b0b9dbdc4a9a147a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07b08b2505048f5ad37ff21aa5feee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1203   80]\n",
      " [  93   34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.94      0.93      1283\n",
      "       1: 이상       0.30      0.27      0.28       127\n",
      "\n",
      "    accuracy                           0.88      1410\n",
      "   macro avg       0.61      0.60      0.61      1410\n",
      "weighted avg       0.87      0.88      0.87      1410\n",
      "\n",
      "Epoch [26], Train Loss : [5.18882] Val Loss : [8.16713] Val F1 Score : [0.60754]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee77c276a744090bb086e398edf76e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0485e291e484720bfd41c9a7dff2cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1196   87]\n",
      " [  93   34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93      1283\n",
      "       1: 이상       0.28      0.27      0.27       127\n",
      "\n",
      "    accuracy                           0.87      1410\n",
      "   macro avg       0.60      0.60      0.60      1410\n",
      "weighted avg       0.87      0.87      0.87      1410\n",
      "\n",
      "Epoch [27], Train Loss : [5.23520] Val Loss : [8.28811] Val F1 Score : [0.60210]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53be945fc0449f9b6d5ba77ea0bf5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b13da3ecc394d378dc77df60a1bef1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1195   88]\n",
      " [  94   33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93      1283\n",
      "       1: 이상       0.27      0.26      0.27       127\n",
      "\n",
      "    accuracy                           0.87      1410\n",
      "   macro avg       0.60      0.60      0.60      1410\n",
      "weighted avg       0.87      0.87      0.87      1410\n",
      "\n",
      "Epoch [28], Train Loss : [5.11283] Val Loss : [8.19312] Val F1 Score : [0.59768]\n",
      "Epoch 00029: reducing learning rate of group 0 to 7.8125e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baed650e65134505b30b917c8058fbee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6059d9e5b0b4488da59a74f064ae7d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1193   90]\n",
      " [  92   35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.93      0.93      0.93      1283\n",
      "       1: 이상       0.28      0.28      0.28       127\n",
      "\n",
      "    accuracy                           0.87      1410\n",
      "   macro avg       0.60      0.60      0.60      1410\n",
      "weighted avg       0.87      0.87      0.87      1410\n",
      "\n",
      "Epoch [29], Train Loss : [5.24749] Val Loss : [8.20219] Val F1 Score : [0.60345]\n",
      "Student Train Best Score는 0.6075387063402297 입니다.\n",
      "부분학습 종료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359c90d8ac794310836f1272f7bc09ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02301577422b401ca0b8ddd454c5ae6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6 152]\n",
      " [  0  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       1.00      0.04      0.07       158\n",
      "       1: 이상       0.06      1.00      0.12        10\n",
      "\n",
      "    accuracy                           0.10       168\n",
      "   macro avg       0.53      0.52      0.09       168\n",
      "weighted avg       0.94      0.10      0.08       168\n",
      "\n",
      "Epoch [0], Train Loss : [11.37188] Val Loss : [9.65049] Val F1 Score : [0.09472]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2fa567bf69408d8ef287b2aa6eaf79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42dbeae25cb148688b26ec5ea6800616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128  30]\n",
      " [  7   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.81      0.87       158\n",
      "       1: 이상       0.09      0.30      0.14        10\n",
      "\n",
      "    accuracy                           0.78       168\n",
      "   macro avg       0.52      0.56      0.51       168\n",
      "weighted avg       0.90      0.78      0.83       168\n",
      "\n",
      "Epoch [1], Train Loss : [5.56644] Val Loss : [5.88322] Val F1 Score : [0.50663]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ac883a3c57485cb6e21f6ae0cbffb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990e5f6997f44ed1bb5d7e3b849cd268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[140  18]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.89      0.92       158\n",
      "       1: 이상       0.10      0.20      0.13        10\n",
      "\n",
      "    accuracy                           0.85       168\n",
      "   macro avg       0.52      0.54      0.52       168\n",
      "weighted avg       0.90      0.85      0.87       168\n",
      "\n",
      "Epoch [2], Train Loss : [4.46987] Val Loss : [4.70732] Val F1 Score : [0.52418]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c202815f01824c648e8b687e28acf393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97766945635e462cbc16ad5d3cdcb101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148  10]\n",
      " [  7   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.94      0.95       158\n",
      "       1: 이상       0.23      0.30      0.26        10\n",
      "\n",
      "    accuracy                           0.90       168\n",
      "   macro avg       0.59      0.62      0.60       168\n",
      "weighted avg       0.91      0.90      0.90       168\n",
      "\n",
      "Epoch [3], Train Loss : [4.27028] Val Loss : [4.67239] Val F1 Score : [0.60328]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2fd7d0b1fb4ef5818af3eca8db1400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2919f1f2e62e449cbf6f43e1e646eb8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[147  11]\n",
      " [  7   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.93      0.94       158\n",
      "       1: 이상       0.21      0.30      0.25        10\n",
      "\n",
      "    accuracy                           0.89       168\n",
      "   macro avg       0.58      0.62      0.60       168\n",
      "weighted avg       0.91      0.89      0.90       168\n",
      "\n",
      "Epoch [4], Train Loss : [3.80073] Val Loss : [5.02419] Val F1 Score : [0.59615]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22abdce94f194644a123bc40d8d52a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0145a5f6a654d78a4cf0aff225070b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149   9]\n",
      " [  7   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.96      0.94      0.95       158\n",
      "       1: 이상       0.25      0.30      0.27        10\n",
      "\n",
      "    accuracy                           0.90       168\n",
      "   macro avg       0.60      0.62      0.61       168\n",
      "weighted avg       0.91      0.90      0.91       168\n",
      "\n",
      "Epoch [5], Train Loss : [3.47480] Val Loss : [5.14325] Val F1 Score : [0.61089]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82812fc924144616aab04d45236ea323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d8be614b1741ecb1b92f83942ec667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[150   8]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.95      0.95       158\n",
      "       1: 이상       0.20      0.20      0.20        10\n",
      "\n",
      "    accuracy                           0.90       168\n",
      "   macro avg       0.57      0.57      0.57       168\n",
      "weighted avg       0.90      0.90      0.90       168\n",
      "\n",
      "Epoch [6], Train Loss : [3.28078] Val Loss : [5.35782] Val F1 Score : [0.57468]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e653f78076e49e7a5407a126deb327f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad8d4b2496c4135a73efbadc1f84c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149   9]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.94      0.95       158\n",
      "       1: 이상       0.18      0.20      0.19        10\n",
      "\n",
      "    accuracy                           0.90       168\n",
      "   macro avg       0.57      0.57      0.57       168\n",
      "weighted avg       0.90      0.90      0.90       168\n",
      "\n",
      "Epoch [7], Train Loss : [2.98816] Val Loss : [5.66701] Val F1 Score : [0.56825]\n",
      "Epoch 00008: reducing learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4b3d484a014a7084d6a0e739ddbda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ddc3b755314cffbcf5e56fc0c508b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[150   8]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.95      0.95       158\n",
      "       1: 이상       0.20      0.20      0.20        10\n",
      "\n",
      "    accuracy                           0.90       168\n",
      "   macro avg       0.57      0.57      0.57       168\n",
      "weighted avg       0.90      0.90      0.90       168\n",
      "\n",
      "Epoch [8], Train Loss : [2.83258] Val Loss : [5.48722] Val F1 Score : [0.57468]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa58f4f50f84acc98ea88a64da57180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8be293b304a4baab1e8aad8b8b7a690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[150   8]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.95      0.95       158\n",
      "       1: 이상       0.20      0.20      0.20        10\n",
      "\n",
      "    accuracy                           0.90       168\n",
      "   macro avg       0.57      0.57      0.57       168\n",
      "weighted avg       0.90      0.90      0.90       168\n",
      "\n",
      "Epoch [9], Train Loss : [2.66555] Val Loss : [5.37602] Val F1 Score : [0.57468]\n",
      "Epoch 00010: reducing learning rate of group 0 to 2.5000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad88e096e7e430e97a2d3c16f98a7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5617465246b94e9f9e180b5228eda812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149   9]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.94      0.95       158\n",
      "       1: 이상       0.18      0.20      0.19        10\n",
      "\n",
      "    accuracy                           0.90       168\n",
      "   macro avg       0.57      0.57      0.57       168\n",
      "weighted avg       0.90      0.90      0.90       168\n",
      "\n",
      "Epoch [10], Train Loss : [2.57970] Val Loss : [5.19107] Val F1 Score : [0.56825]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f1c0ebc2ff4e15985f6a8f22a34cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad02b7a49be741fdb2e5d44c214068b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149   9]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.94      0.95       158\n",
      "       1: 이상       0.18      0.20      0.19        10\n",
      "\n",
      "    accuracy                           0.90       168\n",
      "   macro avg       0.57      0.57      0.57       168\n",
      "weighted avg       0.90      0.90      0.90       168\n",
      "\n",
      "Epoch [11], Train Loss : [2.54147] Val Loss : [5.07995] Val F1 Score : [0.56825]\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.2500e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab090ca74da94f358842055d19257bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6deee65e813a4d1fa07f04cd046462de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[146  12]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.92      0.94       158\n",
      "       1: 이상       0.14      0.20      0.17        10\n",
      "\n",
      "    accuracy                           0.88       168\n",
      "   macro avg       0.55      0.56      0.55       168\n",
      "weighted avg       0.90      0.88      0.89       168\n",
      "\n",
      "Epoch [12], Train Loss : [2.40727] Val Loss : [5.00592] Val F1 Score : [0.55128]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19489bf4ad5c4355aae64086a55f498e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6502a784eb39423cbfa00c430ecad55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[145  13]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.92      0.93       158\n",
      "       1: 이상       0.13      0.20      0.16        10\n",
      "\n",
      "    accuracy                           0.88       168\n",
      "   macro avg       0.54      0.56      0.55       168\n",
      "weighted avg       0.90      0.88      0.89       168\n",
      "\n",
      "Epoch [13], Train Loss : [2.44713] Val Loss : [4.98087] Val F1 Score : [0.54624]\n",
      "Epoch 00014: reducing learning rate of group 0 to 6.2500e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d453b5c6dd7a4ab3a924e53982ed8467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6450dd19bb4948e09edd2049f632bf51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [14], Train Loss : [2.40187] Val Loss : [4.97561] Val F1 Score : [0.53686]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99fa7ad3b4c94e18862d6216ba0884e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5746a7d860724ebeb823f0c3c9fdf30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [15], Train Loss : [2.55687] Val Loss : [4.97530] Val F1 Score : [0.53686]\n",
      "Epoch 00016: reducing learning rate of group 0 to 3.1250e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6472f24982274b54a8f8a829f6bce6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab6c747fdc945df91ea3d60820a367c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [16], Train Loss : [2.41495] Val Loss : [4.94202] Val F1 Score : [0.53686]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b038b05ab6e44d6bf019058c10c9d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c14872ffb942a9b5ffee40939001d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [17], Train Loss : [2.52805] Val Loss : [4.92508] Val F1 Score : [0.53686]\n",
      "Epoch 00018: reducing learning rate of group 0 to 1.5625e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e267cf5e111d4f0986a161ecdd61994a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21046c3149f42bab59fe18d0d0f0499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [18], Train Loss : [2.38172] Val Loss : [4.91893] Val F1 Score : [0.53686]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c27bbdec2ee4964931991c996a95a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a53364952384476bcb2c04335df9cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [19], Train Loss : [2.36277] Val Loss : [4.89566] Val F1 Score : [0.53686]\n",
      "Epoch 00020: reducing learning rate of group 0 to 7.8125e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8844ad3f0b1f479cbbfc49d502e3b614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891d7918824b428084c3ba423efc38e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [20], Train Loss : [2.40045] Val Loss : [4.89112] Val F1 Score : [0.53686]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865f6fcb06224a1d8076e71280556508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f867e1646f94d438f8aaf87fa602f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [21], Train Loss : [2.35862] Val Loss : [4.89619] Val F1 Score : [0.53686]\n",
      "Epoch 00022: reducing learning rate of group 0 to 3.9063e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7818085eef89417cb98ffb4ab5c61a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9cf28a4c2e45738e77eca5861a893a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [22], Train Loss : [2.53690] Val Loss : [4.91124] Val F1 Score : [0.53686]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd7f9538cf943d480aafe3f7013e0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b38a6041e244ba8ce19a77a0499f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [23], Train Loss : [2.44637] Val Loss : [4.89904] Val F1 Score : [0.53686]\n",
      "Epoch 00024: reducing learning rate of group 0 to 1.9531e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94860921f10e422cb5a261be6e1b99e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb649f4ac8254fb682de481be15e6b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [24], Train Loss : [2.38568] Val Loss : [4.89885] Val F1 Score : [0.53686]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5008fccec04427ca6bc4ebc9d2279a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69236c536b0943f2b36926abc807a302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [25], Train Loss : [2.38832] Val Loss : [4.89228] Val F1 Score : [0.53686]\n",
      "Epoch 00026: reducing learning rate of group 0 to 9.7656e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24a42d46089470e91ad06a71dc8cc49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ccb2cae71440c49b109ee89d9d638b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [26], Train Loss : [2.30780] Val Loss : [4.88370] Val F1 Score : [0.53686]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c219ae0b87264c33ac9be3c086a86a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc0a8c011f84787a8e4b48da369fca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [27], Train Loss : [2.36153] Val Loss : [4.86730] Val F1 Score : [0.53686]\n",
      "Epoch 00028: reducing learning rate of group 0 to 4.8828e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24878c5f297144369942d7f765a2b9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b43ddab406647169a2c00401d258755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [28], Train Loss : [2.48474] Val Loss : [4.86479] Val F1 Score : [0.53686]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb28aadb7ce24192833b9f38d407b043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8c2f8cce7b4f50839690fbf74cb977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [  8   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       0: 정상       0.95      0.91      0.93       158\n",
      "       1: 이상       0.12      0.20      0.15        10\n",
      "\n",
      "    accuracy                           0.86       168\n",
      "   macro avg       0.53      0.55      0.54       168\n",
      "weighted avg       0.90      0.86      0.88       168\n",
      "\n",
      "Epoch [29], Train Loss : [2.40450] Val Loss : [4.85624] Val F1 Score : [0.53686]\n",
      "Epoch 00030: reducing learning rate of group 0 to 2.4414e-06.\n",
      "Student Train Best Score는 0.6108859293572669 입니다.\n",
      "부분학습 종료\n",
      "전체 학습 종료\n"
     ]
    }
   ],
   "source": [
    "students = []\n",
    "\n",
    "for a, b, c, d, e in zip(s_train_loaders, s_val_loaders, train_X_list, test_list, teachers):\n",
    "    train_col_num = len(c.columns)\n",
    "    test_stage_features = d.iloc[:,:-1].columns\n",
    "#     print(test_stage_features)\n",
    "    test_col_num = len(test_stage_features)\n",
    "\n",
    "    student_model = Student()\n",
    "    student_model.eval()\n",
    "    optimizer = torch.optim.Adam(student_model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1, threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "\n",
    "    best_student_model = student_train(student_model, e, optimizer, a, b, scheduler, device)\n",
    "\n",
    "    students.append(best_student_model)\n",
    "    \n",
    "    print(\"부분학습 종료\")\n",
    "\n",
    "print(\"전체 학습 종료\")\n",
    "    \n",
    "# print(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "id": "836d8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_threshold(model, val_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "#     thresholds = [0.1, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "    thresholds = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    \n",
    "    best_score = 0\n",
    "    best_thr = None\n",
    "    with torch.no_grad():\n",
    "        for _, x_s, y in tqdm(iter(val_loader)):\n",
    "            x_s = x_s.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            model_pred = model(x_s)\n",
    "            \n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            pred_labels += model_pred.tolist()\n",
    "            true_labels += y.tolist()\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            pred_labels_thr = np.where(np.array(pred_labels) > threshold, 1, 0)\n",
    "            score_thr = competition_metric(true_labels, pred_labels_thr)\n",
    "            cf1 = confusion_matrix(true_labels, pred_labels_thr)  \n",
    "\n",
    "#             print(cf1)\n",
    "#             print(classification_report(true_labels, pred_labels_thr, target_names=[\"0: 정상\", \"1: 이상\"]))\n",
    "\n",
    "            if best_score < score_thr:\n",
    "                best_score = score_thr\n",
    "                best_thr = threshold\n",
    "                \n",
    "    return best_thr, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "id": "8795e830",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9cc13e348d04223a02d6ea5a1d196b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36108cc1454e47f28cacdb1836421845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold : [0.3], Score : [0.53977]\n",
      "부분 작업 종료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056238a5194e4826924f932fa9418345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eafcbbfb2ccd482c93f4653bbec91ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold : [0.25], Score : [0.51202]\n",
      "부분 작업 종료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637959f48e9843e0b7b51e0032c1bc97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f2e8c5c31248dc85be4bc26de5e7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold : [0.3], Score : [0.58700]\n",
      "부분 작업 종료\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745ac278a8b7407796f143ac009efbbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e13251fffdd481ca50a8ab2602fb737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold : [0.25], Score : [0.56078]\n",
      "부분 작업 종료\n",
      "전체 작업 종료\n"
     ]
    }
   ],
   "source": [
    "# for a, b in zip(students, s_val_loaders):\n",
    "    \n",
    "#     print(list(b))\n",
    "    \n",
    "for a, b, c, d, e, f in zip(s_train_loaders, s_val_loaders, train_X_list, test_list, teachers, students):\n",
    "    train_col_num = len(c.columns)\n",
    "    test_stage_features = d.iloc[:,:-1].columns\n",
    "    test_col_num = len(test_stage_features)\n",
    "\n",
    "\n",
    "    choose_threshold(f, b, device)\n",
    "    best_threshold, best_score = choose_threshold(f, b, device)\n",
    "    choose_threshold_result = f'Best Threshold : [{best_threshold}], Score : [{best_score:.5f}]'\n",
    "    print(choose_threshold_result)\n",
    "    \n",
    "    print(\"부분 작업 종료\")\n",
    "\n",
    "print(\"전체 작업 종료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "id": "400223ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder__x1_2008</th>\n",
       "      <th>encoder__x1_2009</th>\n",
       "      <th>encoder__x1_2010</th>\n",
       "      <th>encoder__x1_2011</th>\n",
       "      <th>encoder__x1_2012</th>\n",
       "      <th>encoder__x1_2013</th>\n",
       "      <th>encoder__x1_2014</th>\n",
       "      <th>encoder__x1_2015</th>\n",
       "      <th>encoder__x1_2016</th>\n",
       "      <th>encoder__x1_2017</th>\n",
       "      <th>...</th>\n",
       "      <th>FE</th>\n",
       "      <th>H2O</th>\n",
       "      <th>MN</th>\n",
       "      <th>MO</th>\n",
       "      <th>NI</th>\n",
       "      <th>TI</th>\n",
       "      <th>V</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294593</td>\n",
       "      <td>-0.077342</td>\n",
       "      <td>-0.352471</td>\n",
       "      <td>-0.375764</td>\n",
       "      <td>-0.144333</td>\n",
       "      <td>-0.131016</td>\n",
       "      <td>-0.083807</td>\n",
       "      <td>-0.737903</td>\n",
       "      <td>1.041387</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432480</td>\n",
       "      <td>-0.077342</td>\n",
       "      <td>-0.352471</td>\n",
       "      <td>-0.375764</td>\n",
       "      <td>-0.144333</td>\n",
       "      <td>-0.131016</td>\n",
       "      <td>-0.083807</td>\n",
       "      <td>0.986401</td>\n",
       "      <td>-0.183985</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294593</td>\n",
       "      <td>-0.077342</td>\n",
       "      <td>-0.352471</td>\n",
       "      <td>0.901335</td>\n",
       "      <td>-0.144333</td>\n",
       "      <td>-0.131016</td>\n",
       "      <td>-0.083807</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>-0.279014</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143751</td>\n",
       "      <td>-0.077342</td>\n",
       "      <td>-0.352471</td>\n",
       "      <td>-0.375764</td>\n",
       "      <td>-0.144333</td>\n",
       "      <td>-0.131016</td>\n",
       "      <td>-0.083807</td>\n",
       "      <td>-0.684101</td>\n",
       "      <td>0.591250</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.695458</td>\n",
       "      <td>-0.077342</td>\n",
       "      <td>-0.352471</td>\n",
       "      <td>-0.375764</td>\n",
       "      <td>-0.144333</td>\n",
       "      <td>-0.131016</td>\n",
       "      <td>-0.083807</td>\n",
       "      <td>0.388139</td>\n",
       "      <td>0.031080</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491684</td>\n",
       "      <td>-0.077342</td>\n",
       "      <td>-0.352471</td>\n",
       "      <td>-0.375764</td>\n",
       "      <td>-0.144333</td>\n",
       "      <td>7.917125</td>\n",
       "      <td>-0.083807</td>\n",
       "      <td>0.598527</td>\n",
       "      <td>0.176124</td>\n",
       "      <td>6017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294593</td>\n",
       "      <td>-0.077342</td>\n",
       "      <td>-0.352471</td>\n",
       "      <td>-0.375764</td>\n",
       "      <td>-0.144333</td>\n",
       "      <td>-0.131016</td>\n",
       "      <td>-0.083807</td>\n",
       "      <td>-0.737903</td>\n",
       "      <td>0.676276</td>\n",
       "      <td>6020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694531</td>\n",
       "      <td>-0.077342</td>\n",
       "      <td>-0.352471</td>\n",
       "      <td>-0.375764</td>\n",
       "      <td>-0.144333</td>\n",
       "      <td>-0.131016</td>\n",
       "      <td>-0.083807</td>\n",
       "      <td>0.040763</td>\n",
       "      <td>0.431202</td>\n",
       "      <td>6021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.938797</td>\n",
       "      <td>-0.077342</td>\n",
       "      <td>2.186212</td>\n",
       "      <td>-0.375764</td>\n",
       "      <td>-0.144333</td>\n",
       "      <td>-0.131016</td>\n",
       "      <td>-0.083807</td>\n",
       "      <td>-1.360026</td>\n",
       "      <td>-0.404052</td>\n",
       "      <td>6028.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.889388</td>\n",
       "      <td>-0.077342</td>\n",
       "      <td>-0.352471</td>\n",
       "      <td>-0.375764</td>\n",
       "      <td>-0.144333</td>\n",
       "      <td>-0.131016</td>\n",
       "      <td>-0.083807</td>\n",
       "      <td>-0.052420</td>\n",
       "      <td>-0.138971</td>\n",
       "      <td>6039.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>993 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     encoder__x1_2008  encoder__x1_2009  encoder__x1_2010  encoder__x1_2011  \\\n",
       "0                 0.0               0.0               1.0               0.0   \n",
       "1                 0.0               0.0               0.0               0.0   \n",
       "2                 0.0               0.0               0.0               0.0   \n",
       "3                 0.0               0.0               0.0               0.0   \n",
       "4                 0.0               1.0               0.0               0.0   \n",
       "..                ...               ...               ...               ...   \n",
       "988               0.0               0.0               0.0               0.0   \n",
       "989               0.0               0.0               0.0               0.0   \n",
       "990               0.0               0.0               0.0               0.0   \n",
       "991               1.0               0.0               0.0               0.0   \n",
       "992               0.0               0.0               0.0               0.0   \n",
       "\n",
       "     encoder__x1_2012  encoder__x1_2013  encoder__x1_2014  encoder__x1_2015  \\\n",
       "0                 0.0               0.0               0.0               0.0   \n",
       "1                 0.0               1.0               0.0               0.0   \n",
       "2                 0.0               0.0               1.0               0.0   \n",
       "3                 0.0               0.0               1.0               0.0   \n",
       "4                 0.0               0.0               0.0               0.0   \n",
       "..                ...               ...               ...               ...   \n",
       "988               0.0               1.0               0.0               0.0   \n",
       "989               0.0               0.0               1.0               0.0   \n",
       "990               0.0               1.0               0.0               0.0   \n",
       "991               0.0               0.0               0.0               0.0   \n",
       "992               0.0               1.0               0.0               0.0   \n",
       "\n",
       "     encoder__x1_2016  encoder__x1_2017  ...        FE       H2O        MN  \\\n",
       "0                 0.0               0.0  ... -0.294593 -0.077342 -0.352471   \n",
       "1                 0.0               0.0  ...  0.432480 -0.077342 -0.352471   \n",
       "2                 0.0               0.0  ... -0.294593 -0.077342 -0.352471   \n",
       "3                 0.0               0.0  ...  0.143751 -0.077342 -0.352471   \n",
       "4                 0.0               0.0  ...  1.695458 -0.077342 -0.352471   \n",
       "..                ...               ...  ...       ...       ...       ...   \n",
       "988               0.0               0.0  ...  0.491684 -0.077342 -0.352471   \n",
       "989               0.0               0.0  ... -0.294593 -0.077342 -0.352471   \n",
       "990               0.0               0.0  ...  0.694531 -0.077342 -0.352471   \n",
       "991               0.0               0.0  ...  1.938797 -0.077342  2.186212   \n",
       "992               0.0               0.0  ... -0.889388 -0.077342 -0.352471   \n",
       "\n",
       "           MO        NI        TI         V       V40        ZN   order  \n",
       "0   -0.375764 -0.144333 -0.131016 -0.083807 -0.737903  1.041387     2.0  \n",
       "1   -0.375764 -0.144333 -0.131016 -0.083807  0.986401 -0.183985     4.0  \n",
       "2    0.901335 -0.144333 -0.131016 -0.083807  0.736600 -0.279014    19.0  \n",
       "3   -0.375764 -0.144333 -0.131016 -0.083807 -0.684101  0.591250    21.0  \n",
       "4   -0.375764 -0.144333 -0.131016 -0.083807  0.388139  0.031080    38.0  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "988 -0.375764 -0.144333  7.917125 -0.083807  0.598527  0.176124  6017.0  \n",
       "989 -0.375764 -0.144333 -0.131016 -0.083807 -0.737903  0.676276  6020.0  \n",
       "990 -0.375764 -0.144333 -0.131016 -0.083807  0.040763  0.431202  6021.0  \n",
       "991 -0.375764 -0.144333 -0.131016 -0.083807 -1.360026 -0.404052  6028.0  \n",
       "992 -0.375764 -0.144333 -0.131016 -0.083807 -0.052420 -0.138971  6039.0  \n",
       "\n",
       "[993 rows x 31 columns]"
      ]
     },
     "execution_count": 945,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "e0b979f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.8498, -0.3947],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559,  1.7224,  0.1522],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559,  1.1441, -0.9415],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559,  1.1309, -0.9697],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.2682, -0.7048],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.2210, -1.0768]]), tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.4844, -0.2368],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559,  0.6963,  1.3643],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559,  0.4697,  2.0351],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  1.0000,  ..., -0.1559,  0.5909,  1.0204],\n",
      "        [ 0.0000,  1.0000,  0.0000,  ..., -0.1559, -0.4600, -0.0903],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559,  0.4047, -0.5018]]), tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.0502,  0.3495],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559,  0.9775, -1.0317],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.8159,  0.1014],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.5577,  0.9471],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.9096, -0.8908],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559,  0.5412, -1.6237]]), tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.4925,  0.5299],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559,  0.6894,  1.5841],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.5250, -0.3721],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.6318, -0.3891],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.1042,  0.1071],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -1.0916,  0.0225]]), tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -1.3049, -0.4623],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.9611, -0.2481],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.4681, -1.2911],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559,  1.3652,  1.6405],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559,  0.4192, -0.0170],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559,  0.5483, -2.0352]]), tensor([[ 1.0000,  0.0000,  0.0000,  ..., -0.1559,  0.7520,  1.4657],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ..., -0.1559, -0.3158,  1.4770],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.6733, -0.1241],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.2682,  0.3213],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  6.2858,  0.6543,  1.0034],\n",
      "        [ 0.0000,  0.0000,  1.0000,  ..., -0.1559, -0.4681,  0.4171]]), tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.1559,  2.3236, -0.5187],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -1.0304, -1.2347],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559,  0.0868,  0.0112],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -0.5087, -0.9528],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -1.9722,  1.1049],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1559, -1.8747, -1.0768]])]\n"
     ]
    }
   ],
   "source": [
    "test_loaders = []\n",
    "\n",
    "for i in test_list:\n",
    "\n",
    "    test_dataset = CustomDataset(i.iloc[:,:-1], None, False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False)\n",
    "    test_loaders.append(test_loader)\n",
    "\n",
    "# print(list(test_loaders[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "id": "e75a3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_datasets = CustomDataset(test, None, False)\n",
    "# test_loaders = DataLoader(test_datasets, batch_size = CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "id": "7f3df6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, threshold, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    # .eval함수는 evaluation 과정에서 사용하지 말아야 하는 layer들을 알아서 off 시키는 함수\n",
    "    \n",
    "    test_predict = []\n",
    "    with torch.no_grad():\n",
    "        for x in tqdm(test_loader):\n",
    "            x = x.float().to(device)\n",
    "            model_pred = model(x)\n",
    "\n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            test_predict += model_pred\n",
    "        \n",
    "    test_predict = np.where(np.array(test_predict) > threshold, 1, 0)  \n",
    "    # threshhold 보다 큰 값을 찾아서 1로 바꾸고, 아닌 것은 0으로 변경해라\n",
    "    print('Done.')\n",
    "    return test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "id": "73e49f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6d6b7ed8c44e4ea481617dc861ed0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "1667\n",
      "1667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724b20eb81e44449b0cd61b4aceae22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "993\n",
      "993\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9763680250ed4697a2fc7a18e33778f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "3021\n",
      "3021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27919fc19b46437393fbb79a4f043f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "360\n",
      "360\n",
      "6041\n",
      "6041\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "order_list = []\n",
    "for a, b, c in zip(students, test_loaders, test_list):\n",
    "    preds = inference(a, b, best_threshold, device)\n",
    "    print(len(preds))\n",
    "    print(len(c.order.tolist()))\n",
    "    pred_list.extend(preds)\n",
    "    order_list.extend(c.order.tolist())\n",
    "print(len(pred_list))\n",
    "print(len(order_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "91b9c0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'예측값': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  ...],\n",
       " '순서': [0.0,\n",
       "  11.0,\n",
       "  12.0,\n",
       "  18.0,\n",
       "  20.0,\n",
       "  24.0,\n",
       "  30.0,\n",
       "  33.0,\n",
       "  36.0,\n",
       "  37.0,\n",
       "  42.0,\n",
       "  43.0,\n",
       "  45.0,\n",
       "  47.0,\n",
       "  50.0,\n",
       "  51.0,\n",
       "  52.0,\n",
       "  57.0,\n",
       "  62.0,\n",
       "  68.0,\n",
       "  75.0,\n",
       "  79.0,\n",
       "  82.0,\n",
       "  84.0,\n",
       "  86.0,\n",
       "  92.0,\n",
       "  95.0,\n",
       "  99.0,\n",
       "  107.0,\n",
       "  108.0,\n",
       "  114.0,\n",
       "  115.0,\n",
       "  130.0,\n",
       "  131.0,\n",
       "  133.0,\n",
       "  145.0,\n",
       "  147.0,\n",
       "  156.0,\n",
       "  162.0,\n",
       "  165.0,\n",
       "  169.0,\n",
       "  170.0,\n",
       "  176.0,\n",
       "  180.0,\n",
       "  181.0,\n",
       "  186.0,\n",
       "  187.0,\n",
       "  188.0,\n",
       "  190.0,\n",
       "  195.0,\n",
       "  196.0,\n",
       "  199.0,\n",
       "  200.0,\n",
       "  203.0,\n",
       "  206.0,\n",
       "  208.0,\n",
       "  209.0,\n",
       "  217.0,\n",
       "  226.0,\n",
       "  227.0,\n",
       "  229.0,\n",
       "  230.0,\n",
       "  233.0,\n",
       "  234.0,\n",
       "  237.0,\n",
       "  240.0,\n",
       "  241.0,\n",
       "  242.0,\n",
       "  250.0,\n",
       "  251.0,\n",
       "  260.0,\n",
       "  268.0,\n",
       "  272.0,\n",
       "  274.0,\n",
       "  275.0,\n",
       "  280.0,\n",
       "  281.0,\n",
       "  284.0,\n",
       "  291.0,\n",
       "  292.0,\n",
       "  294.0,\n",
       "  298.0,\n",
       "  300.0,\n",
       "  301.0,\n",
       "  302.0,\n",
       "  304.0,\n",
       "  305.0,\n",
       "  308.0,\n",
       "  309.0,\n",
       "  313.0,\n",
       "  314.0,\n",
       "  316.0,\n",
       "  317.0,\n",
       "  318.0,\n",
       "  321.0,\n",
       "  341.0,\n",
       "  343.0,\n",
       "  345.0,\n",
       "  347.0,\n",
       "  351.0,\n",
       "  362.0,\n",
       "  367.0,\n",
       "  368.0,\n",
       "  371.0,\n",
       "  373.0,\n",
       "  377.0,\n",
       "  382.0,\n",
       "  386.0,\n",
       "  387.0,\n",
       "  395.0,\n",
       "  398.0,\n",
       "  401.0,\n",
       "  406.0,\n",
       "  407.0,\n",
       "  417.0,\n",
       "  424.0,\n",
       "  433.0,\n",
       "  434.0,\n",
       "  440.0,\n",
       "  441.0,\n",
       "  442.0,\n",
       "  451.0,\n",
       "  459.0,\n",
       "  463.0,\n",
       "  464.0,\n",
       "  468.0,\n",
       "  469.0,\n",
       "  471.0,\n",
       "  475.0,\n",
       "  477.0,\n",
       "  478.0,\n",
       "  482.0,\n",
       "  493.0,\n",
       "  497.0,\n",
       "  500.0,\n",
       "  501.0,\n",
       "  504.0,\n",
       "  507.0,\n",
       "  510.0,\n",
       "  511.0,\n",
       "  513.0,\n",
       "  518.0,\n",
       "  521.0,\n",
       "  535.0,\n",
       "  536.0,\n",
       "  542.0,\n",
       "  544.0,\n",
       "  557.0,\n",
       "  558.0,\n",
       "  560.0,\n",
       "  562.0,\n",
       "  563.0,\n",
       "  568.0,\n",
       "  571.0,\n",
       "  573.0,\n",
       "  577.0,\n",
       "  579.0,\n",
       "  585.0,\n",
       "  587.0,\n",
       "  589.0,\n",
       "  591.0,\n",
       "  595.0,\n",
       "  596.0,\n",
       "  600.0,\n",
       "  606.0,\n",
       "  609.0,\n",
       "  610.0,\n",
       "  612.0,\n",
       "  615.0,\n",
       "  616.0,\n",
       "  628.0,\n",
       "  637.0,\n",
       "  643.0,\n",
       "  644.0,\n",
       "  646.0,\n",
       "  648.0,\n",
       "  651.0,\n",
       "  652.0,\n",
       "  655.0,\n",
       "  657.0,\n",
       "  658.0,\n",
       "  667.0,\n",
       "  670.0,\n",
       "  675.0,\n",
       "  685.0,\n",
       "  686.0,\n",
       "  691.0,\n",
       "  693.0,\n",
       "  696.0,\n",
       "  697.0,\n",
       "  702.0,\n",
       "  703.0,\n",
       "  715.0,\n",
       "  718.0,\n",
       "  719.0,\n",
       "  722.0,\n",
       "  724.0,\n",
       "  726.0,\n",
       "  727.0,\n",
       "  728.0,\n",
       "  734.0,\n",
       "  737.0,\n",
       "  742.0,\n",
       "  746.0,\n",
       "  755.0,\n",
       "  756.0,\n",
       "  772.0,\n",
       "  773.0,\n",
       "  775.0,\n",
       "  776.0,\n",
       "  777.0,\n",
       "  779.0,\n",
       "  782.0,\n",
       "  790.0,\n",
       "  794.0,\n",
       "  795.0,\n",
       "  796.0,\n",
       "  803.0,\n",
       "  805.0,\n",
       "  806.0,\n",
       "  808.0,\n",
       "  811.0,\n",
       "  812.0,\n",
       "  816.0,\n",
       "  818.0,\n",
       "  820.0,\n",
       "  821.0,\n",
       "  827.0,\n",
       "  829.0,\n",
       "  831.0,\n",
       "  833.0,\n",
       "  837.0,\n",
       "  838.0,\n",
       "  842.0,\n",
       "  846.0,\n",
       "  853.0,\n",
       "  855.0,\n",
       "  867.0,\n",
       "  870.0,\n",
       "  874.0,\n",
       "  878.0,\n",
       "  879.0,\n",
       "  881.0,\n",
       "  884.0,\n",
       "  889.0,\n",
       "  890.0,\n",
       "  893.0,\n",
       "  898.0,\n",
       "  906.0,\n",
       "  911.0,\n",
       "  912.0,\n",
       "  918.0,\n",
       "  924.0,\n",
       "  932.0,\n",
       "  933.0,\n",
       "  936.0,\n",
       "  937.0,\n",
       "  945.0,\n",
       "  946.0,\n",
       "  947.0,\n",
       "  948.0,\n",
       "  952.0,\n",
       "  954.0,\n",
       "  963.0,\n",
       "  966.0,\n",
       "  968.0,\n",
       "  969.0,\n",
       "  972.0,\n",
       "  973.0,\n",
       "  975.0,\n",
       "  978.0,\n",
       "  979.0,\n",
       "  984.0,\n",
       "  985.0,\n",
       "  989.0,\n",
       "  990.0,\n",
       "  996.0,\n",
       "  997.0,\n",
       "  1005.0,\n",
       "  1016.0,\n",
       "  1021.0,\n",
       "  1025.0,\n",
       "  1026.0,\n",
       "  1028.0,\n",
       "  1033.0,\n",
       "  1035.0,\n",
       "  1037.0,\n",
       "  1039.0,\n",
       "  1042.0,\n",
       "  1044.0,\n",
       "  1057.0,\n",
       "  1060.0,\n",
       "  1062.0,\n",
       "  1064.0,\n",
       "  1078.0,\n",
       "  1083.0,\n",
       "  1085.0,\n",
       "  1086.0,\n",
       "  1089.0,\n",
       "  1091.0,\n",
       "  1096.0,\n",
       "  1097.0,\n",
       "  1101.0,\n",
       "  1103.0,\n",
       "  1104.0,\n",
       "  1105.0,\n",
       "  1115.0,\n",
       "  1117.0,\n",
       "  1121.0,\n",
       "  1122.0,\n",
       "  1131.0,\n",
       "  1133.0,\n",
       "  1135.0,\n",
       "  1140.0,\n",
       "  1143.0,\n",
       "  1145.0,\n",
       "  1146.0,\n",
       "  1147.0,\n",
       "  1150.0,\n",
       "  1151.0,\n",
       "  1152.0,\n",
       "  1154.0,\n",
       "  1157.0,\n",
       "  1161.0,\n",
       "  1165.0,\n",
       "  1173.0,\n",
       "  1176.0,\n",
       "  1179.0,\n",
       "  1182.0,\n",
       "  1186.0,\n",
       "  1187.0,\n",
       "  1189.0,\n",
       "  1190.0,\n",
       "  1199.0,\n",
       "  1203.0,\n",
       "  1206.0,\n",
       "  1208.0,\n",
       "  1209.0,\n",
       "  1210.0,\n",
       "  1214.0,\n",
       "  1219.0,\n",
       "  1227.0,\n",
       "  1232.0,\n",
       "  1234.0,\n",
       "  1235.0,\n",
       "  1237.0,\n",
       "  1238.0,\n",
       "  1241.0,\n",
       "  1247.0,\n",
       "  1257.0,\n",
       "  1263.0,\n",
       "  1265.0,\n",
       "  1268.0,\n",
       "  1280.0,\n",
       "  1281.0,\n",
       "  1282.0,\n",
       "  1283.0,\n",
       "  1285.0,\n",
       "  1286.0,\n",
       "  1287.0,\n",
       "  1288.0,\n",
       "  1289.0,\n",
       "  1291.0,\n",
       "  1298.0,\n",
       "  1301.0,\n",
       "  1302.0,\n",
       "  1305.0,\n",
       "  1306.0,\n",
       "  1313.0,\n",
       "  1314.0,\n",
       "  1315.0,\n",
       "  1318.0,\n",
       "  1319.0,\n",
       "  1325.0,\n",
       "  1333.0,\n",
       "  1339.0,\n",
       "  1344.0,\n",
       "  1346.0,\n",
       "  1347.0,\n",
       "  1354.0,\n",
       "  1365.0,\n",
       "  1366.0,\n",
       "  1369.0,\n",
       "  1371.0,\n",
       "  1376.0,\n",
       "  1380.0,\n",
       "  1384.0,\n",
       "  1387.0,\n",
       "  1390.0,\n",
       "  1391.0,\n",
       "  1400.0,\n",
       "  1402.0,\n",
       "  1403.0,\n",
       "  1407.0,\n",
       "  1408.0,\n",
       "  1411.0,\n",
       "  1412.0,\n",
       "  1413.0,\n",
       "  1415.0,\n",
       "  1418.0,\n",
       "  1423.0,\n",
       "  1424.0,\n",
       "  1428.0,\n",
       "  1433.0,\n",
       "  1436.0,\n",
       "  1439.0,\n",
       "  1441.0,\n",
       "  1445.0,\n",
       "  1449.0,\n",
       "  1450.0,\n",
       "  1451.0,\n",
       "  1454.0,\n",
       "  1456.0,\n",
       "  1461.0,\n",
       "  1465.0,\n",
       "  1466.0,\n",
       "  1469.0,\n",
       "  1473.0,\n",
       "  1478.0,\n",
       "  1480.0,\n",
       "  1483.0,\n",
       "  1484.0,\n",
       "  1490.0,\n",
       "  1491.0,\n",
       "  1493.0,\n",
       "  1494.0,\n",
       "  1498.0,\n",
       "  1499.0,\n",
       "  1500.0,\n",
       "  1502.0,\n",
       "  1506.0,\n",
       "  1510.0,\n",
       "  1511.0,\n",
       "  1517.0,\n",
       "  1518.0,\n",
       "  1522.0,\n",
       "  1524.0,\n",
       "  1531.0,\n",
       "  1537.0,\n",
       "  1541.0,\n",
       "  1546.0,\n",
       "  1550.0,\n",
       "  1553.0,\n",
       "  1558.0,\n",
       "  1568.0,\n",
       "  1572.0,\n",
       "  1573.0,\n",
       "  1581.0,\n",
       "  1582.0,\n",
       "  1583.0,\n",
       "  1584.0,\n",
       "  1587.0,\n",
       "  1589.0,\n",
       "  1598.0,\n",
       "  1604.0,\n",
       "  1606.0,\n",
       "  1613.0,\n",
       "  1617.0,\n",
       "  1621.0,\n",
       "  1624.0,\n",
       "  1626.0,\n",
       "  1631.0,\n",
       "  1640.0,\n",
       "  1644.0,\n",
       "  1646.0,\n",
       "  1647.0,\n",
       "  1651.0,\n",
       "  1654.0,\n",
       "  1655.0,\n",
       "  1661.0,\n",
       "  1665.0,\n",
       "  1678.0,\n",
       "  1680.0,\n",
       "  1684.0,\n",
       "  1686.0,\n",
       "  1690.0,\n",
       "  1691.0,\n",
       "  1694.0,\n",
       "  1695.0,\n",
       "  1696.0,\n",
       "  1697.0,\n",
       "  1698.0,\n",
       "  1707.0,\n",
       "  1708.0,\n",
       "  1711.0,\n",
       "  1714.0,\n",
       "  1722.0,\n",
       "  1723.0,\n",
       "  1726.0,\n",
       "  1735.0,\n",
       "  1740.0,\n",
       "  1744.0,\n",
       "  1748.0,\n",
       "  1751.0,\n",
       "  1753.0,\n",
       "  1754.0,\n",
       "  1760.0,\n",
       "  1767.0,\n",
       "  1768.0,\n",
       "  1769.0,\n",
       "  1774.0,\n",
       "  1787.0,\n",
       "  1788.0,\n",
       "  1789.0,\n",
       "  1795.0,\n",
       "  1798.0,\n",
       "  1799.0,\n",
       "  1803.0,\n",
       "  1811.0,\n",
       "  1812.0,\n",
       "  1816.0,\n",
       "  1822.0,\n",
       "  1827.0,\n",
       "  1829.0,\n",
       "  1830.0,\n",
       "  1840.0,\n",
       "  1848.0,\n",
       "  1852.0,\n",
       "  1853.0,\n",
       "  1860.0,\n",
       "  1864.0,\n",
       "  1865.0,\n",
       "  1880.0,\n",
       "  1882.0,\n",
       "  1883.0,\n",
       "  1886.0,\n",
       "  1887.0,\n",
       "  1892.0,\n",
       "  1895.0,\n",
       "  1896.0,\n",
       "  1905.0,\n",
       "  1916.0,\n",
       "  1917.0,\n",
       "  1919.0,\n",
       "  1927.0,\n",
       "  1939.0,\n",
       "  1947.0,\n",
       "  1948.0,\n",
       "  1950.0,\n",
       "  1954.0,\n",
       "  1955.0,\n",
       "  1976.0,\n",
       "  1978.0,\n",
       "  1982.0,\n",
       "  1990.0,\n",
       "  1992.0,\n",
       "  1993.0,\n",
       "  1994.0,\n",
       "  1999.0,\n",
       "  2001.0,\n",
       "  2003.0,\n",
       "  2006.0,\n",
       "  2007.0,\n",
       "  2008.0,\n",
       "  2016.0,\n",
       "  2017.0,\n",
       "  2018.0,\n",
       "  2021.0,\n",
       "  2029.0,\n",
       "  2044.0,\n",
       "  2047.0,\n",
       "  2051.0,\n",
       "  2060.0,\n",
       "  2065.0,\n",
       "  2068.0,\n",
       "  2071.0,\n",
       "  2074.0,\n",
       "  2078.0,\n",
       "  2080.0,\n",
       "  2081.0,\n",
       "  2084.0,\n",
       "  2087.0,\n",
       "  2088.0,\n",
       "  2092.0,\n",
       "  2098.0,\n",
       "  2101.0,\n",
       "  2111.0,\n",
       "  2114.0,\n",
       "  2117.0,\n",
       "  2118.0,\n",
       "  2119.0,\n",
       "  2120.0,\n",
       "  2121.0,\n",
       "  2122.0,\n",
       "  2125.0,\n",
       "  2126.0,\n",
       "  2129.0,\n",
       "  2139.0,\n",
       "  2141.0,\n",
       "  2150.0,\n",
       "  2153.0,\n",
       "  2157.0,\n",
       "  2162.0,\n",
       "  2164.0,\n",
       "  2171.0,\n",
       "  2173.0,\n",
       "  2174.0,\n",
       "  2176.0,\n",
       "  2181.0,\n",
       "  2182.0,\n",
       "  2183.0,\n",
       "  2184.0,\n",
       "  2187.0,\n",
       "  2193.0,\n",
       "  2195.0,\n",
       "  2199.0,\n",
       "  2202.0,\n",
       "  2203.0,\n",
       "  2205.0,\n",
       "  2206.0,\n",
       "  2209.0,\n",
       "  2213.0,\n",
       "  2217.0,\n",
       "  2223.0,\n",
       "  2225.0,\n",
       "  2227.0,\n",
       "  2228.0,\n",
       "  2233.0,\n",
       "  2237.0,\n",
       "  2241.0,\n",
       "  2243.0,\n",
       "  2244.0,\n",
       "  2245.0,\n",
       "  2247.0,\n",
       "  2251.0,\n",
       "  2252.0,\n",
       "  2253.0,\n",
       "  2254.0,\n",
       "  2255.0,\n",
       "  2257.0,\n",
       "  2261.0,\n",
       "  2265.0,\n",
       "  2266.0,\n",
       "  2272.0,\n",
       "  2278.0,\n",
       "  2281.0,\n",
       "  2288.0,\n",
       "  2289.0,\n",
       "  2290.0,\n",
       "  2295.0,\n",
       "  2296.0,\n",
       "  2301.0,\n",
       "  2309.0,\n",
       "  2318.0,\n",
       "  2320.0,\n",
       "  2324.0,\n",
       "  2330.0,\n",
       "  2345.0,\n",
       "  2353.0,\n",
       "  2357.0,\n",
       "  2365.0,\n",
       "  2374.0,\n",
       "  2376.0,\n",
       "  2379.0,\n",
       "  2380.0,\n",
       "  2385.0,\n",
       "  2389.0,\n",
       "  2390.0,\n",
       "  2393.0,\n",
       "  2396.0,\n",
       "  2398.0,\n",
       "  2400.0,\n",
       "  2401.0,\n",
       "  2402.0,\n",
       "  2404.0,\n",
       "  2405.0,\n",
       "  2410.0,\n",
       "  2413.0,\n",
       "  2414.0,\n",
       "  2418.0,\n",
       "  2419.0,\n",
       "  2420.0,\n",
       "  2424.0,\n",
       "  2427.0,\n",
       "  2435.0,\n",
       "  2437.0,\n",
       "  2439.0,\n",
       "  2440.0,\n",
       "  2442.0,\n",
       "  2443.0,\n",
       "  2444.0,\n",
       "  2447.0,\n",
       "  2451.0,\n",
       "  2454.0,\n",
       "  2457.0,\n",
       "  2460.0,\n",
       "  2462.0,\n",
       "  2464.0,\n",
       "  2467.0,\n",
       "  2469.0,\n",
       "  2492.0,\n",
       "  2493.0,\n",
       "  2496.0,\n",
       "  2505.0,\n",
       "  2514.0,\n",
       "  2515.0,\n",
       "  2516.0,\n",
       "  2520.0,\n",
       "  2522.0,\n",
       "  2527.0,\n",
       "  2530.0,\n",
       "  2533.0,\n",
       "  2543.0,\n",
       "  2545.0,\n",
       "  2547.0,\n",
       "  2551.0,\n",
       "  2554.0,\n",
       "  2558.0,\n",
       "  2565.0,\n",
       "  2567.0,\n",
       "  2576.0,\n",
       "  2587.0,\n",
       "  2589.0,\n",
       "  2590.0,\n",
       "  2596.0,\n",
       "  2599.0,\n",
       "  2602.0,\n",
       "  2605.0,\n",
       "  2613.0,\n",
       "  2614.0,\n",
       "  2615.0,\n",
       "  2619.0,\n",
       "  2623.0,\n",
       "  2626.0,\n",
       "  2631.0,\n",
       "  2633.0,\n",
       "  2635.0,\n",
       "  2644.0,\n",
       "  2646.0,\n",
       "  2653.0,\n",
       "  2656.0,\n",
       "  2657.0,\n",
       "  2658.0,\n",
       "  2660.0,\n",
       "  2665.0,\n",
       "  2672.0,\n",
       "  2682.0,\n",
       "  2683.0,\n",
       "  2685.0,\n",
       "  2692.0,\n",
       "  2697.0,\n",
       "  2703.0,\n",
       "  2705.0,\n",
       "  2714.0,\n",
       "  2719.0,\n",
       "  2734.0,\n",
       "  2736.0,\n",
       "  2737.0,\n",
       "  2738.0,\n",
       "  2740.0,\n",
       "  2744.0,\n",
       "  2747.0,\n",
       "  2749.0,\n",
       "  2750.0,\n",
       "  2752.0,\n",
       "  2754.0,\n",
       "  2768.0,\n",
       "  2772.0,\n",
       "  2773.0,\n",
       "  2774.0,\n",
       "  2775.0,\n",
       "  2780.0,\n",
       "  2781.0,\n",
       "  2786.0,\n",
       "  2787.0,\n",
       "  2790.0,\n",
       "  2791.0,\n",
       "  2795.0,\n",
       "  2801.0,\n",
       "  2805.0,\n",
       "  2810.0,\n",
       "  2815.0,\n",
       "  2816.0,\n",
       "  2822.0,\n",
       "  2823.0,\n",
       "  2830.0,\n",
       "  2835.0,\n",
       "  2840.0,\n",
       "  2841.0,\n",
       "  2854.0,\n",
       "  2856.0,\n",
       "  2857.0,\n",
       "  2859.0,\n",
       "  2869.0,\n",
       "  2871.0,\n",
       "  2874.0,\n",
       "  2876.0,\n",
       "  2877.0,\n",
       "  2880.0,\n",
       "  2881.0,\n",
       "  2885.0,\n",
       "  2889.0,\n",
       "  2894.0,\n",
       "  2897.0,\n",
       "  2900.0,\n",
       "  2902.0,\n",
       "  2905.0,\n",
       "  2912.0,\n",
       "  2919.0,\n",
       "  2923.0,\n",
       "  2924.0,\n",
       "  2927.0,\n",
       "  2929.0,\n",
       "  2937.0,\n",
       "  2943.0,\n",
       "  2944.0,\n",
       "  2945.0,\n",
       "  2947.0,\n",
       "  2948.0,\n",
       "  2951.0,\n",
       "  2953.0,\n",
       "  2954.0,\n",
       "  2962.0,\n",
       "  2963.0,\n",
       "  2966.0,\n",
       "  2968.0,\n",
       "  2973.0,\n",
       "  2974.0,\n",
       "  2975.0,\n",
       "  2978.0,\n",
       "  2983.0,\n",
       "  2985.0,\n",
       "  2989.0,\n",
       "  2990.0,\n",
       "  2993.0,\n",
       "  2999.0,\n",
       "  3002.0,\n",
       "  3003.0,\n",
       "  3004.0,\n",
       "  3022.0,\n",
       "  3023.0,\n",
       "  3024.0,\n",
       "  3033.0,\n",
       "  3045.0,\n",
       "  3046.0,\n",
       "  3047.0,\n",
       "  3049.0,\n",
       "  3054.0,\n",
       "  3068.0,\n",
       "  3070.0,\n",
       "  3074.0,\n",
       "  3076.0,\n",
       "  3078.0,\n",
       "  3079.0,\n",
       "  3080.0,\n",
       "  3081.0,\n",
       "  3084.0,\n",
       "  3102.0,\n",
       "  3105.0,\n",
       "  3110.0,\n",
       "  3112.0,\n",
       "  3118.0,\n",
       "  3121.0,\n",
       "  3124.0,\n",
       "  3126.0,\n",
       "  3127.0,\n",
       "  3131.0,\n",
       "  3134.0,\n",
       "  3137.0,\n",
       "  3141.0,\n",
       "  3144.0,\n",
       "  3150.0,\n",
       "  3151.0,\n",
       "  3157.0,\n",
       "  3161.0,\n",
       "  3162.0,\n",
       "  3163.0,\n",
       "  3171.0,\n",
       "  3180.0,\n",
       "  3181.0,\n",
       "  3193.0,\n",
       "  3199.0,\n",
       "  3201.0,\n",
       "  3202.0,\n",
       "  3216.0,\n",
       "  3218.0,\n",
       "  3220.0,\n",
       "  3223.0,\n",
       "  3238.0,\n",
       "  3239.0,\n",
       "  3240.0,\n",
       "  3241.0,\n",
       "  3248.0,\n",
       "  3250.0,\n",
       "  3252.0,\n",
       "  3253.0,\n",
       "  3254.0,\n",
       "  3255.0,\n",
       "  3256.0,\n",
       "  3265.0,\n",
       "  3266.0,\n",
       "  3267.0,\n",
       "  3271.0,\n",
       "  3275.0,\n",
       "  3276.0,\n",
       "  3282.0,\n",
       "  3284.0,\n",
       "  3286.0,\n",
       "  3288.0,\n",
       "  3294.0,\n",
       "  3295.0,\n",
       "  3299.0,\n",
       "  3311.0,\n",
       "  3312.0,\n",
       "  3319.0,\n",
       "  3325.0,\n",
       "  3327.0,\n",
       "  3328.0,\n",
       "  3332.0,\n",
       "  3338.0,\n",
       "  3341.0,\n",
       "  3342.0,\n",
       "  3347.0,\n",
       "  3358.0,\n",
       "  3362.0,\n",
       "  3364.0,\n",
       "  3368.0,\n",
       "  3370.0,\n",
       "  3371.0,\n",
       "  3372.0,\n",
       "  3388.0,\n",
       "  3389.0,\n",
       "  3391.0,\n",
       "  3394.0,\n",
       "  3398.0,\n",
       "  3399.0,\n",
       "  3408.0,\n",
       "  3412.0,\n",
       "  3413.0,\n",
       "  3419.0,\n",
       "  3422.0,\n",
       "  3426.0,\n",
       "  3427.0,\n",
       "  3438.0,\n",
       "  3444.0,\n",
       "  3450.0,\n",
       "  3453.0,\n",
       "  3454.0,\n",
       "  3461.0,\n",
       "  3463.0,\n",
       "  3470.0,\n",
       "  3471.0,\n",
       "  3476.0,\n",
       "  3479.0,\n",
       "  3486.0,\n",
       "  3494.0,\n",
       "  3499.0,\n",
       "  3503.0,\n",
       "  3504.0,\n",
       "  3509.0,\n",
       "  3510.0,\n",
       "  3513.0,\n",
       "  3515.0,\n",
       "  3518.0,\n",
       "  3523.0,\n",
       "  3530.0,\n",
       "  3531.0,\n",
       "  3537.0,\n",
       "  3538.0,\n",
       "  3539.0,\n",
       "  3549.0,\n",
       "  3550.0,\n",
       "  3558.0,\n",
       "  3559.0,\n",
       "  3564.0,\n",
       "  3569.0,\n",
       "  3571.0,\n",
       "  3582.0,\n",
       "  3583.0,\n",
       "  3588.0,\n",
       "  3591.0,\n",
       "  3593.0,\n",
       "  3602.0,\n",
       "  3604.0,\n",
       "  3606.0,\n",
       "  3610.0,\n",
       "  3611.0,\n",
       "  3617.0,\n",
       "  3619.0,\n",
       "  3627.0,\n",
       "  3631.0,\n",
       "  3635.0,\n",
       "  3639.0,\n",
       "  3642.0,\n",
       "  3643.0,\n",
       "  3644.0,\n",
       "  3646.0,\n",
       "  3650.0,\n",
       "  3651.0,\n",
       "  3657.0,\n",
       "  3659.0,\n",
       "  3662.0,\n",
       "  3665.0,\n",
       "  3667.0,\n",
       "  3672.0,\n",
       "  3675.0,\n",
       "  3682.0,\n",
       "  3688.0,\n",
       "  3691.0,\n",
       "  3694.0,\n",
       "  ...]}"
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"예측값\": pred_list, \"순서\": order_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "9ff39fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>예측값</th>\n",
       "      <th>순서</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>0</td>\n",
       "      <td>6036.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>0</td>\n",
       "      <td>6037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>0</td>\n",
       "      <td>6038.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>0</td>\n",
       "      <td>6039.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>1</td>\n",
       "      <td>6040.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6041 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      예측값      순서\n",
       "0       0     0.0\n",
       "2660    0     1.0\n",
       "1667    0     2.0\n",
       "2661    1     3.0\n",
       "1668    0     4.0\n",
       "...   ...     ...\n",
       "5678    0  6036.0\n",
       "5679    0  6037.0\n",
       "5680    0  6038.0\n",
       "2659    0  6039.0\n",
       "1666    1  6040.0\n",
       "\n",
       "[6041 rows x 2 columns]"
      ]
     },
     "execution_count": 951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({\"예측값\": pred_list, \"순서\": order_list})\n",
    "result.sort_values(by=[\"순서\"], inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "id": "0ea396b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result = result[\"예측값\"].tolist()\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "id": "e432dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# preds = inference(best_student_model, test_loaders, best_threshold, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "3a2081a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Y_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Y_LABEL\n",
       "0  TEST_0000        0\n",
       "1  TEST_0001        0\n",
       "2  TEST_0002        0\n",
       "3  TEST_0003        1\n",
       "4  TEST_0004        0"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit['Y_LABEL'] = final_result\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "id": "d486a345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정상값 개수 : 5386, 이상값 개수 : 655\n"
     ]
    }
   ],
   "source": [
    "pred_cnt = tuple(submit[\"Y_LABEL\"].value_counts())\n",
    "a, b = pred_cnt\n",
    "r = f\"정상값 개수 : {a}, 이상값 개수 : {b}\"\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "id": "84b73f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(f'./submits/submit{file_version}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "id": "84905804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ver': 53,\n",
       " 'CFG': {'EPOCHS': 30,\n",
       "  'LEARNING_RATE': 0.01,\n",
       "  'BATCH_SIZE': 256,\n",
       "  'SEED': 43,\n",
       "  'log_transform_turn': 1,\n",
       "  'skew_cut': 0.01,\n",
       "  'vif_cut': 10,\n",
       "  'corr_cut': 0.004,\n",
       "  'outlier_corr_cut': 100,\n",
       "  'T_Thresh': 0.3,\n",
       "  'S_Thresh': 0.325,\n",
       "  'reduct': 'sum',\n",
       "  'drop_rate': 0.2},\n",
       " 'Val_result': 'Best Threshold : [0.25], Score : [0.56078]',\n",
       " 'pred_cnt': '정상값 개수 : 5386, 이상값 개수 : 655'}"
      ]
     },
     "execution_count": 957,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = {\"ver\": file_version, \"CFG\": CFG, \"Val_result\": choose_threshold_result, \"pred_cnt\": r}\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12282840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f3449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de4a6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288462ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af48d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0062d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
