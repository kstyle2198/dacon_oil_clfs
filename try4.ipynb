{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4f1c89d",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "fb4705c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "960b8a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_version = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "1119d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS': 30,\n",
    "    'LEARNING_RATE':1e-2,    # 0.02\n",
    "    'BATCH_SIZE':256,\n",
    "    'SEED':42,\n",
    "    'CUT': 0.004,     # drop column correlation cut line\n",
    "    'T_Thresh': 0.3,     # Teacher model train Threshhold 최초 0.35\n",
    "    'S_Thresh': 0.325,     # Student model train Threshold 최초 0.35\n",
    "    'reduct' : 'sum',\n",
    "    'drop_p': 0\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "62be04f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "2f8f5798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364f89c",
   "metadata": {},
   "source": [
    "## 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "0e848820",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import missingno as msno\n",
    "msno.matrix(train, figsize=(16,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "2dd2d4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>COMPONENT_ARBITRARY</th>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SAMPLE_TRANSFER_DAY</th>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <th>AG</th>\n",
       "      <th>AL</th>\n",
       "      <th>B</th>\n",
       "      <th>BA</th>\n",
       "      <th>...</th>\n",
       "      <th>U25</th>\n",
       "      <th>U20</th>\n",
       "      <th>U14</th>\n",
       "      <th>U6</th>\n",
       "      <th>U4</th>\n",
       "      <th>V</th>\n",
       "      <th>V100</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "      <th>Y_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14095</td>\n",
       "      <td>14095</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2316.000000</td>\n",
       "      <td>2316.000000</td>\n",
       "      <td>2118.000000</td>\n",
       "      <td>2118.000000</td>\n",
       "      <td>2118.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>3724.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>14095</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>COMPONENT3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>7050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3146.082937</td>\n",
       "      <td>2013.652501</td>\n",
       "      <td>7.600568</td>\n",
       "      <td>387.416885</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>12.707698</td>\n",
       "      <td>64.026179</td>\n",
       "      <td>0.692799</td>\n",
       "      <td>...</td>\n",
       "      <td>29.870898</td>\n",
       "      <td>56.063472</td>\n",
       "      <td>239.938149</td>\n",
       "      <td>5488.693107</td>\n",
       "      <td>19415.597262</td>\n",
       "      <td>0.050656</td>\n",
       "      <td>13.576230</td>\n",
       "      <td>109.355815</td>\n",
       "      <td>588.646825</td>\n",
       "      <td>0.085349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4216.089809</td>\n",
       "      <td>3.964758</td>\n",
       "      <td>11.681628</td>\n",
       "      <td>550.016073</td>\n",
       "      <td>0.171926</td>\n",
       "      <td>86.968000</td>\n",
       "      <td>102.876871</td>\n",
       "      <td>2.905491</td>\n",
       "      <td>...</td>\n",
       "      <td>97.459625</td>\n",
       "      <td>184.332678</td>\n",
       "      <td>685.053457</td>\n",
       "      <td>15474.146283</td>\n",
       "      <td>40145.311444</td>\n",
       "      <td>0.475438</td>\n",
       "      <td>1.073718</td>\n",
       "      <td>49.612379</td>\n",
       "      <td>531.743393</td>\n",
       "      <td>0.279411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1655.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>636.750000</td>\n",
       "      <td>5409.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2227.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1753.000000</td>\n",
       "      <td>12691.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>111.300000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3797.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>39.250000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>5517.750000</td>\n",
       "      <td>24535.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>137.200000</td>\n",
       "      <td>1119.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>294451.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>368.000000</td>\n",
       "      <td>9650.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4630.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1651.000000</td>\n",
       "      <td>2932.000000</td>\n",
       "      <td>11296.000000</td>\n",
       "      <td>412627.000000</td>\n",
       "      <td>844421.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>29.900000</td>\n",
       "      <td>2840.500000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID COMPONENT_ARBITRARY    ANONYMOUS_1          YEAR  \\\n",
       "count         14095               14095   14095.000000  14095.000000   \n",
       "unique        14095                   4            NaN           NaN   \n",
       "top     TRAIN_00000          COMPONENT3            NaN           NaN   \n",
       "freq              1                7050            NaN           NaN   \n",
       "mean            NaN                 NaN    3146.082937   2013.652501   \n",
       "std             NaN                 NaN    4216.089809      3.964758   \n",
       "min             NaN                 NaN    1000.000000   2007.000000   \n",
       "25%             NaN                 NaN    1655.000000   2010.000000   \n",
       "50%             NaN                 NaN    2227.000000   2014.000000   \n",
       "75%             NaN                 NaN    3797.000000   2017.000000   \n",
       "max             NaN                 NaN  294451.000000   2022.000000   \n",
       "\n",
       "        SAMPLE_TRANSFER_DAY   ANONYMOUS_2            AG            AL  \\\n",
       "count          14095.000000  14095.000000  14095.000000  14095.000000   \n",
       "unique                  NaN           NaN           NaN           NaN   \n",
       "top                     NaN           NaN           NaN           NaN   \n",
       "freq                    NaN           NaN           NaN           NaN   \n",
       "mean               7.600568    387.416885      0.025825     12.707698   \n",
       "std               11.681628    550.016073      0.171926     86.968000   \n",
       "min                0.000000    200.000000      0.000000      0.000000   \n",
       "25%                3.000000    200.000000      0.000000      1.000000   \n",
       "50%                5.000000    200.000000      0.000000      2.000000   \n",
       "75%                8.000000    410.000000      0.000000      4.000000   \n",
       "max              368.000000   9650.000000      3.000000   4630.000000   \n",
       "\n",
       "                   B            BA  ...          U25          U20  \\\n",
       "count   14095.000000  14095.000000  ...  2316.000000  2316.000000   \n",
       "unique           NaN           NaN  ...          NaN          NaN   \n",
       "top              NaN           NaN  ...          NaN          NaN   \n",
       "freq             NaN           NaN  ...          NaN          NaN   \n",
       "mean       64.026179      0.692799  ...    29.870898    56.063472   \n",
       "std       102.876871      2.905491  ...    97.459625   184.332678   \n",
       "min         0.000000      0.000000  ...     0.000000     0.000000   \n",
       "25%         3.000000      0.000000  ...     3.000000     5.000000   \n",
       "50%        11.000000      0.000000  ...     7.000000    13.000000   \n",
       "75%       110.000000      0.000000  ...    23.000000    39.250000   \n",
       "max      2051.000000    216.000000  ...  1651.000000  2932.000000   \n",
       "\n",
       "                 U14             U6             U4             V         V100  \\\n",
       "count    2118.000000    2118.000000    2118.000000  14095.000000  3724.000000   \n",
       "unique           NaN            NaN            NaN           NaN          NaN   \n",
       "top              NaN            NaN            NaN           NaN          NaN   \n",
       "freq             NaN            NaN            NaN           NaN          NaN   \n",
       "mean      239.938149    5488.693107   19415.597262      0.050656    13.576230   \n",
       "std       685.053457   15474.146283   40145.311444      0.475438     1.073718   \n",
       "min         0.000000      15.000000     154.000000      0.000000     5.200000   \n",
       "25%        22.000000     636.750000    5409.250000      0.000000    12.900000   \n",
       "50%        57.000000    1753.000000   12691.500000      0.000000    13.500000   \n",
       "75%       189.000000    5517.750000   24535.750000      0.000000    14.200000   \n",
       "max     11296.000000  412627.000000  844421.000000     17.000000    29.900000   \n",
       "\n",
       "                 V40            ZN       Y_LABEL  \n",
       "count   14095.000000  14095.000000  14095.000000  \n",
       "unique           NaN           NaN           NaN  \n",
       "top              NaN           NaN           NaN  \n",
       "freq             NaN           NaN           NaN  \n",
       "mean      109.355815    588.646825      0.085349  \n",
       "std        49.612379    531.743393      0.279411  \n",
       "min         2.900000      0.000000      0.000000  \n",
       "25%        71.800000     37.000000      0.000000  \n",
       "50%       111.300000    520.000000      0.000000  \n",
       "75%       137.200000   1119.000000      0.000000  \n",
       "max      2840.500000   2132.000000      1.000000  \n",
       "\n",
       "[11 rows x 54 columns]"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "58bbb4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컬럼명: CD, 널값수: 1,394, 평균: 0.02, 중위수: 0.0, 최빈값: 0.0\n",
      "컬럼명: FH2O, 널값수: 10,205, 평균: 15.24, 중위수: 13.0, 최빈값: 14.0\n",
      "컬럼명: FNOX, 널값수: 10,205, 평균: 7.14, 중위수: 7.0, 최빈값: 6.0\n",
      "컬럼명: FOPTIMETHGLY, 널값수: 10,205, 평균: 0.53, 중위수: 0.0, 최빈값: 0.0\n",
      "컬럼명: FOXID, 널값수: 10,205, 평균: 12.5, 중위수: 12.0, 최빈값: 11.0\n",
      "컬럼명: FSO4, 널값수: 10,205, 평균: 20.28, 중위수: 20.0, 최빈값: 20.0\n",
      "컬럼명: FTBN, 널값수: 10,205, 평균: 8.78, 중위수: 8.7, 최빈값: 8.2\n",
      "컬럼명: FUEL, 널값수: 10,205, 평균: 0.19, 중위수: 0.0, 최빈값: 0.0\n",
      "컬럼명: K, 널값수: 2,299, 평균: 3.61, 중위수: 2.0, 최빈값: 0.0\n",
      "컬럼명: SOOTPERCENTAGE, 널값수: 10,205, 평균: 0.61, 중위수: 0.4, 최빈값: 0.2\n",
      "컬럼명: U100, 널값수: 11,779, 평균: 0.17, 중위수: 0.0, 최빈값: 0.0\n",
      "컬럼명: U75, 널값수: 11,779, 평균: 0.42, 중위수: 0.0, 최빈값: 0.0\n",
      "컬럼명: U50, 널값수: 11,779, 평균: 6.19, 중위수: 1.0, 최빈값: 0.0\n",
      "컬럼명: U25, 널값수: 11,779, 평균: 29.87, 중위수: 7.0, 최빈값: 1.0\n",
      "컬럼명: U20, 널값수: 11,779, 평균: 56.06, 중위수: 13.0, 최빈값: 4.0\n",
      "컬럼명: U14, 널값수: 11,977, 평균: 239.94, 중위수: 57.0, 최빈값: 14.0\n",
      "컬럼명: U6, 널값수: 11,977, 평균: 5488.69, 중위수: 1753.0, 최빈값: 300.0\n",
      "컬럼명: U4, 널값수: 11,977, 평균: 19415.6, 중위수: 12691.5, 최빈값: 6789.0\n",
      "컬럼명: V100, 널값수: 10,371, 평균: 13.58, 중위수: 13.5, 최빈값: 13.3\n"
     ]
    }
   ],
   "source": [
    "# 널값 칼럼값을 무엇으로 보간할까?\n",
    "null_columns = []\n",
    "for col in train.columns.tolist():\n",
    "    if train[col].isna().any():\n",
    "        null_columns.append(col)\n",
    "        print(f\"컬럼명: {col}, 널값수: {train[col].isna().sum():,}, 평균: {np.round(train[col].mean(),2)}, 중위수: {train[col].median()}, 최빈값: {train[col].mode().values[0]}\")\n",
    "    else:\n",
    "        pass   \n",
    "# null_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "1c07bd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD</th>\n",
       "      <th>FH2O</th>\n",
       "      <th>FNOX</th>\n",
       "      <th>FOPTIMETHGLY</th>\n",
       "      <th>FOXID</th>\n",
       "      <th>FSO4</th>\n",
       "      <th>FTBN</th>\n",
       "      <th>FUEL</th>\n",
       "      <th>K</th>\n",
       "      <th>SOOTPERCENTAGE</th>\n",
       "      <th>U100</th>\n",
       "      <th>U75</th>\n",
       "      <th>U50</th>\n",
       "      <th>U25</th>\n",
       "      <th>U20</th>\n",
       "      <th>U14</th>\n",
       "      <th>U6</th>\n",
       "      <th>U4</th>\n",
       "      <th>V100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12701.000000</td>\n",
       "      <td>3890.000000</td>\n",
       "      <td>3890.000000</td>\n",
       "      <td>3890.000000</td>\n",
       "      <td>3890.000000</td>\n",
       "      <td>3890.000000</td>\n",
       "      <td>3890.000000</td>\n",
       "      <td>3890.000000</td>\n",
       "      <td>11796.000000</td>\n",
       "      <td>3890.000000</td>\n",
       "      <td>2316.000000</td>\n",
       "      <td>2316.000000</td>\n",
       "      <td>2316.000000</td>\n",
       "      <td>2316.000000</td>\n",
       "      <td>2316.000000</td>\n",
       "      <td>2118.000000</td>\n",
       "      <td>2118.000000</td>\n",
       "      <td>2118.000000</td>\n",
       "      <td>3724.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.015589</td>\n",
       "      <td>15.242159</td>\n",
       "      <td>7.138303</td>\n",
       "      <td>0.532905</td>\n",
       "      <td>12.495373</td>\n",
       "      <td>20.284319</td>\n",
       "      <td>8.783239</td>\n",
       "      <td>0.185347</td>\n",
       "      <td>3.611224</td>\n",
       "      <td>0.609254</td>\n",
       "      <td>0.173575</td>\n",
       "      <td>0.417098</td>\n",
       "      <td>6.185233</td>\n",
       "      <td>29.870898</td>\n",
       "      <td>56.063472</td>\n",
       "      <td>239.938149</td>\n",
       "      <td>5488.693107</td>\n",
       "      <td>19415.597262</td>\n",
       "      <td>13.576230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.209407</td>\n",
       "      <td>17.591679</td>\n",
       "      <td>1.860775</td>\n",
       "      <td>0.621937</td>\n",
       "      <td>3.439535</td>\n",
       "      <td>3.234296</td>\n",
       "      <td>1.339355</td>\n",
       "      <td>0.899253</td>\n",
       "      <td>15.630404</td>\n",
       "      <td>0.652382</td>\n",
       "      <td>0.878892</td>\n",
       "      <td>1.626333</td>\n",
       "      <td>36.639482</td>\n",
       "      <td>97.459625</td>\n",
       "      <td>184.332678</td>\n",
       "      <td>685.053457</td>\n",
       "      <td>15474.146283</td>\n",
       "      <td>40145.311444</td>\n",
       "      <td>1.073718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>5.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>636.750000</td>\n",
       "      <td>5409.250000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1753.000000</td>\n",
       "      <td>12691.500000</td>\n",
       "      <td>13.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>39.250000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>5517.750000</td>\n",
       "      <td>24535.750000</td>\n",
       "      <td>14.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>27.700000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>705.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>939.000000</td>\n",
       "      <td>1651.000000</td>\n",
       "      <td>2932.000000</td>\n",
       "      <td>11296.000000</td>\n",
       "      <td>412627.000000</td>\n",
       "      <td>844421.000000</td>\n",
       "      <td>29.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CD         FH2O         FNOX  FOPTIMETHGLY        FOXID  \\\n",
       "count  12701.000000  3890.000000  3890.000000   3890.000000  3890.000000   \n",
       "mean       0.015589    15.242159     7.138303      0.532905    12.495373   \n",
       "std        0.209407    17.591679     1.860775      0.621937     3.439535   \n",
       "min        0.000000     6.000000     3.000000      0.000000     4.000000   \n",
       "25%        0.000000    11.000000     6.000000      0.000000    10.000000   \n",
       "50%        0.000000    13.000000     7.000000      0.000000    12.000000   \n",
       "75%        0.000000    15.000000     8.000000      1.000000    14.750000   \n",
       "max       18.000000   320.000000    38.000000     13.000000    68.000000   \n",
       "\n",
       "              FSO4         FTBN         FUEL             K  SOOTPERCENTAGE  \\\n",
       "count  3890.000000  3890.000000  3890.000000  11796.000000     3890.000000   \n",
       "mean     20.284319     8.783239     0.185347      3.611224        0.609254   \n",
       "std       3.234296     1.339355     0.899253     15.630404        0.652382   \n",
       "min      10.000000     0.000000     0.000000      0.000000        0.000000   \n",
       "25%      18.000000     8.100000     0.000000      0.000000        0.200000   \n",
       "50%      20.000000     8.700000     0.000000      2.000000        0.400000   \n",
       "75%      22.000000     9.600000     0.000000      3.000000        0.800000   \n",
       "max      68.000000    27.700000    12.000000    705.000000        6.500000   \n",
       "\n",
       "              U100          U75          U50          U25          U20  \\\n",
       "count  2316.000000  2316.000000  2316.000000  2316.000000  2316.000000   \n",
       "mean      0.173575     0.417098     6.185233    29.870898    56.063472   \n",
       "std       0.878892     1.626333    36.639482    97.459625   184.332678   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     3.000000     5.000000   \n",
       "50%       0.000000     0.000000     1.000000     7.000000    13.000000   \n",
       "75%       0.000000     0.000000     3.000000    23.000000    39.250000   \n",
       "max      18.000000    33.000000   939.000000  1651.000000  2932.000000   \n",
       "\n",
       "                U14             U6             U4         V100  \n",
       "count   2118.000000    2118.000000    2118.000000  3724.000000  \n",
       "mean     239.938149    5488.693107   19415.597262    13.576230  \n",
       "std      685.053457   15474.146283   40145.311444     1.073718  \n",
       "min        0.000000      15.000000     154.000000     5.200000  \n",
       "25%       22.000000     636.750000    5409.250000    12.900000  \n",
       "50%       57.000000    1753.000000   12691.500000    13.500000  \n",
       "75%      189.000000    5517.750000   24535.750000    14.200000  \n",
       "max    11296.000000  412627.000000  844421.000000    29.900000  "
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[null_columns].describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "bc0f5666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "14.0\n",
      "6.0\n",
      "0.0\n",
      "11.0\n",
      "20.0\n",
      "8.2\n",
      "0.0\n",
      "0.0\n",
      "0.2\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "4.0\n",
      "14.0\n",
      "300.0\n",
      "6789.0\n",
      "13.3\n"
     ]
    }
   ],
   "source": [
    "# nan 보간 : 평균 or 중위수 or 최빈값\n",
    "for col in null_columns:\n",
    "    보간값 = train[col].mode().values[0] # 최빈값\n",
    "    print(보간값)\n",
    "    train[col] = train[col].fillna(보간값)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "e1f69d1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "msno.matrix(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38edaad1",
   "metadata": {},
   "source": [
    "### 상관관계 확인(드랍칼럼 선정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "52af7020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(30, 5))\n",
    "sns.heatmap(train.loc[:,:].corr()[[\"Y_LABEL\"]].T, annot=True, linewidth=1, cmap=\"coolwarm\", vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "8b8a97c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y_LABEL</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>0.370512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>0.104840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FE</th>\n",
       "      <td>0.047992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NI</th>\n",
       "      <td>0.046806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <td>0.044197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>0.036731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PQINDEX</th>\n",
       "      <td>0.028966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>0.027923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TI</th>\n",
       "      <td>0.025637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CU</th>\n",
       "      <td>0.024975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MN</th>\n",
       "      <td>0.024274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V40</th>\n",
       "      <td>0.023195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>0.020959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>0.020862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNOX</th>\n",
       "      <td>0.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOPTIMETHGLY</th>\n",
       "      <td>0.016373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AG</th>\n",
       "      <td>0.014671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR</th>\n",
       "      <td>0.014233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOXID</th>\n",
       "      <td>0.011669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BE</th>\n",
       "      <td>0.010685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSO4</th>\n",
       "      <td>0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>0.008175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>0.007602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FH2O</th>\n",
       "      <td>0.006188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD</th>\n",
       "      <td>0.003960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTBN</th>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V100</th>\n",
       "      <td>0.003376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LI</th>\n",
       "      <td>0.002921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN</th>\n",
       "      <td>0.002359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U6</th>\n",
       "      <td>0.001467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MO</th>\n",
       "      <td>0.001206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U14</th>\n",
       "      <td>0.000352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOOTPERCENTAGE</th>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U20</th>\n",
       "      <td>-0.000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U4</th>\n",
       "      <td>-0.000281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SB</th>\n",
       "      <td>-0.002028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U25</th>\n",
       "      <td>-0.002432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U50</th>\n",
       "      <td>-0.003205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PB</th>\n",
       "      <td>-0.003549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H2O</th>\n",
       "      <td>-0.004262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMPLE_TRANSFER_DAY</th>\n",
       "      <td>-0.004315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FUEL</th>\n",
       "      <td>-0.005844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U100</th>\n",
       "      <td>-0.007233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U75</th>\n",
       "      <td>-0.008045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>-0.008807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA</th>\n",
       "      <td>-0.010820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>-0.027551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.029787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <td>-0.033641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <td>-0.087871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>-0.150379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Y_LABEL\n",
       "Y_LABEL              1.000000\n",
       "AL                   0.370512\n",
       "BA                   0.104840\n",
       "FE                   0.047992\n",
       "NI                   0.046806\n",
       "ANONYMOUS_1          0.044197\n",
       "SI                   0.036731\n",
       "PQINDEX              0.028966\n",
       "S                    0.027923\n",
       "TI                   0.025637\n",
       "CU                   0.024975\n",
       "MN                   0.024274\n",
       "V40                  0.023195\n",
       "K                    0.020959\n",
       "V                    0.020862\n",
       "FNOX                 0.018913\n",
       "FOPTIMETHGLY         0.016373\n",
       "AG                   0.014671\n",
       "CR                   0.014233\n",
       "FOXID                0.011669\n",
       "BE                   0.010685\n",
       "FSO4                 0.009778\n",
       "CO                   0.008175\n",
       "P                    0.007602\n",
       "FH2O                 0.006188\n",
       "CD                   0.003960\n",
       "FTBN                 0.003912\n",
       "V100                 0.003376\n",
       "LI                   0.002921\n",
       "SN                   0.002359\n",
       "U6                   0.001467\n",
       "MO                   0.001206\n",
       "U14                  0.000352\n",
       "SOOTPERCENTAGE       0.000212\n",
       "U20                 -0.000218\n",
       "U4                  -0.000281\n",
       "SB                  -0.002028\n",
       "U25                 -0.002432\n",
       "U50                 -0.003205\n",
       "PB                  -0.003549\n",
       "H2O                 -0.004262\n",
       "SAMPLE_TRANSFER_DAY -0.004315\n",
       "FUEL                -0.005844\n",
       "U100                -0.007233\n",
       "U75                 -0.008045\n",
       "MG                  -0.008807\n",
       "NA                  -0.010820\n",
       "ZN                  -0.027551\n",
       "B                   -0.029787\n",
       "ANONYMOUS_2         -0.033641\n",
       "YEAR                -0.087871\n",
       "CA                  -0.150379"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr1 = pd.DataFrame(train.corr()[\"Y_LABEL\"].sort_values(ascending=False))\n",
    "df_corr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "8a22400b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상관관계가 낮아서 드랍할 칼럼 개수 : 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.sort_values of                  Y_LABEL\n",
       "CD              0.003960\n",
       "FTBN            0.003912\n",
       "V100            0.003376\n",
       "LI              0.002921\n",
       "SN              0.002359\n",
       "U6              0.001467\n",
       "MO              0.001206\n",
       "U14             0.000352\n",
       "SOOTPERCENTAGE  0.000212\n",
       "U20            -0.000218\n",
       "U4             -0.000281\n",
       "SB             -0.002028\n",
       "U25            -0.002432\n",
       "U50            -0.003205\n",
       "PB             -0.003549>"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상관관계가 낮아서 제낄 칼럼들\n",
    "cutline = CFG['CUT']\n",
    "df_corr2 = df_corr1[(df_corr1[\"Y_LABEL\"] < cutline) & (df_corr1[\"Y_LABEL\"] > (cutline*-1))]\n",
    "print(f\"상관관계가 낮아서 드랍할 칼럼 개수 : {len(df_corr2.index)}\")\n",
    "df_corr2.sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "f87d6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = df_corr2.index.tolist()\n",
    "# drop_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "f7ad29df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "드랍하기 전 칼럼 갯수 : 54\n",
      "드랍후 칼럼 갯수 : 39\n"
     ]
    }
   ],
   "source": [
    "print(f\"드랍하기 전 칼럼 갯수 : {len(train.columns)}\")\n",
    "for col in drop_columns:\n",
    "    if col in train.columns:\n",
    "        train.drop(columns = col, axis = 1, inplace = True)\n",
    "    else:\n",
    "        pass\n",
    "print(f\"드랍후 칼럼 갯수 : {len(train.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "3f0d6e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "드랍하기 전 칼럼 갯수 : 19\n",
      "드랍후 칼럼 갯수 : 18\n"
     ]
    }
   ],
   "source": [
    "print(f\"드랍하기 전 칼럼 갯수 : {len(test.columns)}\")\n",
    "for col in drop_columns:\n",
    "    if col in test.columns:\n",
    "        test.drop(columns = col, axis = 1, inplace = True)\n",
    "    else:\n",
    "        pass\n",
    "print(f\"드랍후 칼럼 갯수 : {len(test.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "7803f54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SAMPLE_TRANSFER_DAY</th>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <th>AG</th>\n",
       "      <th>AL</th>\n",
       "      <th>B</th>\n",
       "      <th>BA</th>\n",
       "      <th>BE</th>\n",
       "      <th>CA</th>\n",
       "      <th>...</th>\n",
       "      <th>PQINDEX</th>\n",
       "      <th>S</th>\n",
       "      <th>SI</th>\n",
       "      <th>TI</th>\n",
       "      <th>U100</th>\n",
       "      <th>U75</th>\n",
       "      <th>V</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "      <th>Y_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "      <td>14095.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3146.082937</td>\n",
       "      <td>2013.652501</td>\n",
       "      <td>7.600568</td>\n",
       "      <td>387.416885</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>12.707698</td>\n",
       "      <td>64.026179</td>\n",
       "      <td>0.692799</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>1366.757574</td>\n",
       "      <td>...</td>\n",
       "      <td>415.159631</td>\n",
       "      <td>12029.318624</td>\n",
       "      <td>35.058248</td>\n",
       "      <td>0.707911</td>\n",
       "      <td>0.028521</td>\n",
       "      <td>0.068535</td>\n",
       "      <td>0.050656</td>\n",
       "      <td>109.355815</td>\n",
       "      <td>588.646825</td>\n",
       "      <td>0.085349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4216.089809</td>\n",
       "      <td>3.964758</td>\n",
       "      <td>11.681628</td>\n",
       "      <td>550.016073</td>\n",
       "      <td>0.171926</td>\n",
       "      <td>86.968000</td>\n",
       "      <td>102.876871</td>\n",
       "      <td>2.905491</td>\n",
       "      <td>0.152189</td>\n",
       "      <td>1481.924727</td>\n",
       "      <td>...</td>\n",
       "      <td>1528.191012</td>\n",
       "      <td>9325.610196</td>\n",
       "      <td>195.329029</td>\n",
       "      <td>6.897579</td>\n",
       "      <td>0.361961</td>\n",
       "      <td>0.677006</td>\n",
       "      <td>0.475438</td>\n",
       "      <td>49.612379</td>\n",
       "      <td>531.743393</td>\n",
       "      <td>0.279411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>386.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1655.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4440.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2227.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>8034.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>111.300000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3797.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2975.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>19750.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>137.200000</td>\n",
       "      <td>1119.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>294451.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>368.000000</td>\n",
       "      <td>9650.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4630.000000</td>\n",
       "      <td>2051.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6609.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>56761.000000</td>\n",
       "      <td>64160.000000</td>\n",
       "      <td>5459.000000</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2840.500000</td>\n",
       "      <td>2132.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ANONYMOUS_1          YEAR  SAMPLE_TRANSFER_DAY   ANONYMOUS_2  \\\n",
       "count   14095.000000  14095.000000         14095.000000  14095.000000   \n",
       "mean     3146.082937   2013.652501             7.600568    387.416885   \n",
       "std      4216.089809      3.964758            11.681628    550.016073   \n",
       "min      1000.000000   2007.000000             0.000000    200.000000   \n",
       "25%      1655.000000   2010.000000             3.000000    200.000000   \n",
       "50%      2227.000000   2014.000000             5.000000    200.000000   \n",
       "75%      3797.000000   2017.000000             8.000000    410.000000   \n",
       "max    294451.000000   2022.000000           368.000000   9650.000000   \n",
       "\n",
       "                 AG            AL             B            BA            BE  \\\n",
       "count  14095.000000  14095.000000  14095.000000  14095.000000  14095.000000   \n",
       "mean       0.025825     12.707698     64.026179      0.692799      0.006314   \n",
       "std        0.171926     86.968000    102.876871      2.905491      0.152189   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      1.000000      3.000000      0.000000      0.000000   \n",
       "50%        0.000000      2.000000     11.000000      0.000000      0.000000   \n",
       "75%        0.000000      4.000000    110.000000      0.000000      0.000000   \n",
       "max        3.000000   4630.000000   2051.000000    216.000000      9.000000   \n",
       "\n",
       "                 CA  ...       PQINDEX             S            SI  \\\n",
       "count  14095.000000  ...  14095.000000  14095.000000  14095.000000   \n",
       "mean    1366.757574  ...    415.159631  12029.318624     35.058248   \n",
       "std     1481.924727  ...   1528.191012   9325.610196    195.329029   \n",
       "min        0.000000  ...      0.000000    386.000000      0.000000   \n",
       "25%       48.000000  ...     12.000000   4440.500000      3.000000   \n",
       "50%      198.000000  ...     29.000000   8034.000000      6.000000   \n",
       "75%     2975.000000  ...    181.000000  19750.000000     12.000000   \n",
       "max     6609.000000  ...  56761.000000  64160.000000   5459.000000   \n",
       "\n",
       "                 TI          U100           U75             V           V40  \\\n",
       "count  14095.000000  14095.000000  14095.000000  14095.000000  14095.000000   \n",
       "mean       0.707911      0.028521      0.068535      0.050656    109.355815   \n",
       "std        6.897579      0.361961      0.677006      0.475438     49.612379   \n",
       "min        0.000000      0.000000      0.000000      0.000000      2.900000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000     71.800000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000    111.300000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000    137.200000   \n",
       "max      403.000000     18.000000     33.000000     17.000000   2840.500000   \n",
       "\n",
       "                 ZN       Y_LABEL  \n",
       "count  14095.000000  14095.000000  \n",
       "mean     588.646825      0.085349  \n",
       "std      531.743393      0.279411  \n",
       "min        0.000000      0.000000  \n",
       "25%       37.000000      0.000000  \n",
       "50%      520.000000      0.000000  \n",
       "75%     1119.000000      0.000000  \n",
       "max     2132.000000      1.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c09e44",
   "metadata": {},
   "source": [
    "### 수치형 데이터 이상치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "dffe00a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_number_features = ['ID','COMPONENT_ARBITRARY', 'YEAR', \"Y_LABEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "bb53ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns = \"ID\", axis = 1, inplace = True)\n",
    "test.drop(columns = \"ID\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "4cc30658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 인덱스 확인 함수\n",
    "# def get_outlier(df=None, col=None, weight=1.5):\n",
    "#     target = df[col]\n",
    "#     quantile_25 = np.quantile(target, 0.25)\n",
    "#     quantile_75 = np.quantile(target, 0.75)\n",
    "#     iqr = quantile_75 - quantile_25\n",
    "#     iqr_weight = iqr * weight\n",
    "#     lowest_val = quantile_25 - iqr_weight\n",
    "#     highest_val = quantile_75 + iqr_weight\n",
    "#     outlier_index = target[(target < lowest_val) | (target > highest_val)].index\n",
    "#     return outlier_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "3c061ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_outlier(test, \"CO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "b2955c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치칼럼 = []\n",
    "# for target1 in train.columns:\n",
    "# #     print(target1)\n",
    "#     huddle = 0.3  # 허들이상의 상관관계를 가진 칼럼에 대해서만 이상치 드랍\n",
    "    \n",
    "#     if target1 not in not_number_features and ((df_corr1.loc[[target1]].values[0][0] >= huddle) or (df_corr1.loc[[target1]].values[0][0] <= (huddle*-1))):\n",
    "#         print(target1)\n",
    "#         이상치칼럼.append(target1)\n",
    "        \n",
    "#         outlier_index = get_outlier(train, target1)\n",
    "#         print(f\"드랍대상 아웃라이어 인덱스 갯수 : {len(outlier_index)}\")\n",
    "        \n",
    "#         train.drop(index=outlier_index, inplace=True)\n",
    "\n",
    "#     else:\n",
    "#         pass\n",
    "    \n",
    "# print(이상치칼럼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "efec8218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "db97ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "cd82efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if target2 in 이상치칼럼 :\n",
    "#     print(target2)\n",
    "#     outlier_index2 = get_outlier(test, target2)\n",
    "#     print(f\"드랍대상 아웃라이어 인덱스 갯수 : {len(outlier_index2)}\")\n",
    "\n",
    "#     test.drop(index=outlier_index, inplace=True)\n",
    "# else:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "fe39e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d27220",
   "metadata": {},
   "source": [
    "### train, val 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "381106d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = train.drop(['Y_LABEL'], axis = 1)\n",
    "all_y = train['Y_LABEL']\n",
    "# test = test.drop(['ID'], axis = 1)\n",
    "train_X, val_X, train_y, val_y = train_test_split(all_X, all_y, test_size=0.2, random_state=CFG['SEED'], stratify=all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "67c88b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPONENT_ARBITRARY</th>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SAMPLE_TRANSFER_DAY</th>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <th>AG</th>\n",
       "      <th>AL</th>\n",
       "      <th>B</th>\n",
       "      <th>BA</th>\n",
       "      <th>BE</th>\n",
       "      <th>...</th>\n",
       "      <th>P</th>\n",
       "      <th>PQINDEX</th>\n",
       "      <th>S</th>\n",
       "      <th>SI</th>\n",
       "      <th>TI</th>\n",
       "      <th>U100</th>\n",
       "      <th>U75</th>\n",
       "      <th>V</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>COMPONENT3</td>\n",
       "      <td>3476</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2447</td>\n",
       "      <td>745</td>\n",
       "      <td>34000</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>142.4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13544</th>\n",
       "      <td>COMPONENT3</td>\n",
       "      <td>5753</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1065</td>\n",
       "      <td>1436</td>\n",
       "      <td>19430</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.5</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      COMPONENT_ARBITRARY  ANONYMOUS_1  YEAR  SAMPLE_TRANSFER_DAY  \\\n",
       "6216           COMPONENT3         3476  2016                    5   \n",
       "13544          COMPONENT3         5753  2014                    5   \n",
       "\n",
       "       ANONYMOUS_2  AG  AL    B  BA  BE  ...     P  PQINDEX      S  SI  TI  \\\n",
       "6216           200   0   4  109   0   0  ...  2447      745  34000  13   0   \n",
       "13544          200   0   0   20   0   0  ...  1065     1436  19430   5   0   \n",
       "\n",
       "       U100  U75  V    V40  ZN  \n",
       "6216    0.0  0.0  0  142.4  20  \n",
       "13544   0.0  0.0  0  120.5  24  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "a33a9597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPONENT_ARBITRARY</th>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SAMPLE_TRANSFER_DAY</th>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <th>AG</th>\n",
       "      <th>AL</th>\n",
       "      <th>B</th>\n",
       "      <th>BA</th>\n",
       "      <th>BE</th>\n",
       "      <th>...</th>\n",
       "      <th>P</th>\n",
       "      <th>PQINDEX</th>\n",
       "      <th>S</th>\n",
       "      <th>SI</th>\n",
       "      <th>TI</th>\n",
       "      <th>U100</th>\n",
       "      <th>U75</th>\n",
       "      <th>V</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13107</th>\n",
       "      <td>COMPONENT3</td>\n",
       "      <td>2085</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2125</td>\n",
       "      <td>114</td>\n",
       "      <td>28210</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146.7</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>COMPONENT3</td>\n",
       "      <td>1445</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>375</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>390</td>\n",
       "      <td>245</td>\n",
       "      <td>18650</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      COMPONENT_ARBITRARY  ANONYMOUS_1  YEAR  SAMPLE_TRANSFER_DAY  \\\n",
       "13107          COMPONENT3         2085  2012                   11   \n",
       "731            COMPONENT3         1445  2018                    5   \n",
       "\n",
       "       ANONYMOUS_2  AG  AL   B  BA  BE  ...     P  PQINDEX      S  SI  TI  \\\n",
       "13107          200   0   1  22   0   0  ...  2125      114  28210   7   0   \n",
       "731            375   0   3   0   0   0  ...   390      245  18650   2   0   \n",
       "\n",
       "       U100  U75  V    V40  ZN  \n",
       "13107   0.0  0.0  0  146.7  45  \n",
       "731     0.0  0.0  0  135.5  51  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61216472",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "fa894923",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['COMPONENT_ARBITRARY', 'YEAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "ddc2df5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPONENT_ARBITRARY</th>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SAMPLE_TRANSFER_DAY</th>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <th>AG</th>\n",
       "      <th>AL</th>\n",
       "      <th>B</th>\n",
       "      <th>BA</th>\n",
       "      <th>BE</th>\n",
       "      <th>...</th>\n",
       "      <th>P</th>\n",
       "      <th>PQINDEX</th>\n",
       "      <th>S</th>\n",
       "      <th>SI</th>\n",
       "      <th>TI</th>\n",
       "      <th>U100</th>\n",
       "      <th>U75</th>\n",
       "      <th>V</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>COMPONENT3</td>\n",
       "      <td>0.066945</td>\n",
       "      <td>2016</td>\n",
       "      <td>-0.219402</td>\n",
       "      <td>-0.340807</td>\n",
       "      <td>-0.14991</td>\n",
       "      <td>-0.109649</td>\n",
       "      <td>0.429454</td>\n",
       "      <td>-0.30818</td>\n",
       "      <td>-0.040725</td>\n",
       "      <td>...</td>\n",
       "      <td>2.717384</td>\n",
       "      <td>0.215891</td>\n",
       "      <td>2.350677</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.09805</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.640931</td>\n",
       "      <td>-1.069154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13544</th>\n",
       "      <td>COMPONENT3</td>\n",
       "      <td>0.572677</td>\n",
       "      <td>2014</td>\n",
       "      <td>-0.219402</td>\n",
       "      <td>-0.340807</td>\n",
       "      <td>-0.14991</td>\n",
       "      <td>-0.164876</td>\n",
       "      <td>-0.427729</td>\n",
       "      <td>-0.30818</td>\n",
       "      <td>-0.040725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274113</td>\n",
       "      <td>0.664284</td>\n",
       "      <td>0.791533</td>\n",
       "      <td>-0.154382</td>\n",
       "      <td>-0.09805</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.213439</td>\n",
       "      <td>-1.061642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      COMPONENT_ARBITRARY  ANONYMOUS_1  YEAR  SAMPLE_TRANSFER_DAY  \\\n",
       "6216           COMPONENT3     0.066945  2016            -0.219402   \n",
       "13544          COMPONENT3     0.572677  2014            -0.219402   \n",
       "\n",
       "       ANONYMOUS_2       AG        AL         B       BA        BE  ...  \\\n",
       "6216     -0.340807 -0.14991 -0.109649  0.429454 -0.30818 -0.040725  ...   \n",
       "13544    -0.340807 -0.14991 -0.164876 -0.427729 -0.30818 -0.040725  ...   \n",
       "\n",
       "              P   PQINDEX         S        SI       TI      U100     U75  \\\n",
       "6216   2.717384  0.215891  2.350677 -0.113002 -0.09805 -0.083955 -0.1138   \n",
       "13544  0.274113  0.664284  0.791533 -0.154382 -0.09805 -0.083955 -0.1138   \n",
       "\n",
       "              V       V40        ZN  \n",
       "6216  -0.105558  0.640931 -1.069154  \n",
       "13544 -0.105558  0.213439 -1.061642  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_values(value):\n",
    "    return value.values.reshape(-1, 1)\n",
    "\n",
    "for col in train_X.columns:\n",
    "    if col not in categorical_features:   # 범주형 칼럼이 아니라면 표준화\n",
    "        scaler = StandardScaler()\n",
    "        train_X[col] = scaler.fit_transform(get_values(train_X[col]))\n",
    "        val_X[col] = scaler.transform(get_values(val_X[col]))\n",
    "        if col in test.columns:\n",
    "            test[col] = scaler.transform(get_values(test[col]))\n",
    "            \n",
    "train_X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb9d17",
   "metadata": {},
   "source": [
    "### OneHotEncoding for Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "f96688d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(df, target_list):\n",
    "    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(drop='first', sparse=False), [0, 2])], remainder='passthrough')\n",
    "    df = ct.fit_transform(df)\n",
    "    df = pd.DataFrame(df)\n",
    "    new_name = ct.get_feature_names()\n",
    "    df.columns = new_name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "23f9b0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder__x0_COMPONENT2</th>\n",
       "      <th>encoder__x0_COMPONENT3</th>\n",
       "      <th>encoder__x0_COMPONENT4</th>\n",
       "      <th>encoder__x1_2008</th>\n",
       "      <th>encoder__x1_2009</th>\n",
       "      <th>encoder__x1_2010</th>\n",
       "      <th>encoder__x1_2011</th>\n",
       "      <th>encoder__x1_2012</th>\n",
       "      <th>encoder__x1_2013</th>\n",
       "      <th>encoder__x1_2014</th>\n",
       "      <th>...</th>\n",
       "      <th>P</th>\n",
       "      <th>PQINDEX</th>\n",
       "      <th>S</th>\n",
       "      <th>SI</th>\n",
       "      <th>TI</th>\n",
       "      <th>U100</th>\n",
       "      <th>U75</th>\n",
       "      <th>V</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.717384</td>\n",
       "      <td>0.215891</td>\n",
       "      <td>2.350677</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.09805</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.640931</td>\n",
       "      <td>-1.069154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274113</td>\n",
       "      <td>0.664284</td>\n",
       "      <td>0.791533</td>\n",
       "      <td>-0.154382</td>\n",
       "      <td>-0.09805</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.213439</td>\n",
       "      <td>-1.061642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171573</td>\n",
       "      <td>-0.263000</td>\n",
       "      <td>-0.968471</td>\n",
       "      <td>-0.164727</td>\n",
       "      <td>-0.09805</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>-0.223813</td>\n",
       "      <td>1.055072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.993489</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>-0.889818</td>\n",
       "      <td>-0.154382</td>\n",
       "      <td>-0.09805</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.119742</td>\n",
       "      <td>-0.261535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192788</td>\n",
       "      <td>-0.266894</td>\n",
       "      <td>-0.546207</td>\n",
       "      <td>-0.138865</td>\n",
       "      <td>-0.09805</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.250527</td>\n",
       "      <td>1.083244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11271</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.307225</td>\n",
       "      <td>-0.109210</td>\n",
       "      <td>1.729695</td>\n",
       "      <td>-0.144037</td>\n",
       "      <td>-0.09805</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.707300</td>\n",
       "      <td>-0.868189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11272</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576428</td>\n",
       "      <td>0.272995</td>\n",
       "      <td>0.381682</td>\n",
       "      <td>-0.087139</td>\n",
       "      <td>-0.09805</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.432065</td>\n",
       "      <td>-1.027834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11273</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072569</td>\n",
       "      <td>-0.253916</td>\n",
       "      <td>-0.061342</td>\n",
       "      <td>-0.164727</td>\n",
       "      <td>-0.09805</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>-0.471719</td>\n",
       "      <td>1.090757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11274</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.251606</td>\n",
       "      <td>-0.114401</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.076794</td>\n",
       "      <td>-0.09805</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.744388</td>\n",
       "      <td>-1.080423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412011</td>\n",
       "      <td>-0.244182</td>\n",
       "      <td>-0.041010</td>\n",
       "      <td>-0.102657</td>\n",
       "      <td>-0.09805</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>-0.727433</td>\n",
       "      <td>1.271063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11276 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       encoder__x0_COMPONENT2  encoder__x0_COMPONENT3  encoder__x0_COMPONENT4  \\\n",
       "0                         0.0                     1.0                     0.0   \n",
       "1                         0.0                     1.0                     0.0   \n",
       "2                         0.0                     0.0                     0.0   \n",
       "3                         0.0                     1.0                     0.0   \n",
       "4                         0.0                     0.0                     0.0   \n",
       "...                       ...                     ...                     ...   \n",
       "11271                     0.0                     1.0                     0.0   \n",
       "11272                     0.0                     1.0                     0.0   \n",
       "11273                     0.0                     0.0                     0.0   \n",
       "11274                     0.0                     1.0                     0.0   \n",
       "11275                     0.0                     0.0                     1.0   \n",
       "\n",
       "       encoder__x1_2008  encoder__x1_2009  encoder__x1_2010  encoder__x1_2011  \\\n",
       "0                   0.0               0.0               0.0               0.0   \n",
       "1                   0.0               0.0               0.0               0.0   \n",
       "2                   0.0               0.0               0.0               0.0   \n",
       "3                   0.0               0.0               0.0               0.0   \n",
       "4                   1.0               0.0               0.0               0.0   \n",
       "...                 ...               ...               ...               ...   \n",
       "11271               0.0               0.0               0.0               0.0   \n",
       "11272               0.0               0.0               0.0               0.0   \n",
       "11273               0.0               0.0               0.0               0.0   \n",
       "11274               0.0               0.0               0.0               0.0   \n",
       "11275               0.0               0.0               0.0               0.0   \n",
       "\n",
       "       encoder__x1_2012  encoder__x1_2013  encoder__x1_2014  ...         P  \\\n",
       "0                   0.0               0.0               0.0  ...  2.717384   \n",
       "1                   0.0               0.0               1.0  ...  0.274113   \n",
       "2                   0.0               0.0               0.0  ...  0.171573   \n",
       "3                   0.0               0.0               0.0  ... -0.993489   \n",
       "4                   0.0               0.0               0.0  ...  0.192788   \n",
       "...                 ...               ...               ...  ...       ...   \n",
       "11271               0.0               0.0               0.0  ...  2.307225   \n",
       "11272               0.0               0.0               1.0  ...  0.576428   \n",
       "11273               1.0               0.0               0.0  ...  0.072569   \n",
       "11274               0.0               0.0               0.0  ... -1.251606   \n",
       "11275               0.0               1.0               0.0  ...  0.412011   \n",
       "\n",
       "        PQINDEX         S        SI       TI      U100     U75         V  \\\n",
       "0      0.215891  2.350677 -0.113002 -0.09805 -0.083955 -0.1138 -0.105558   \n",
       "1      0.664284  0.791533 -0.154382 -0.09805 -0.083955 -0.1138 -0.105558   \n",
       "2     -0.263000 -0.968471 -0.164727 -0.09805 -0.083955 -0.1138 -0.105558   \n",
       "3      0.122449 -0.889818 -0.154382 -0.09805 -0.083955 -0.1138 -0.105558   \n",
       "4     -0.266894 -0.546207 -0.138865 -0.09805 -0.083955 -0.1138 -0.105558   \n",
       "...         ...       ...       ...      ...       ...     ...       ...   \n",
       "11271 -0.109210  1.729695 -0.144037 -0.09805 -0.083955 -0.1138 -0.105558   \n",
       "11272  0.272995  0.381682 -0.087139 -0.09805 -0.083955 -0.1138 -0.105558   \n",
       "11273 -0.253916 -0.061342 -0.164727 -0.09805 -0.083955 -0.1138 -0.105558   \n",
       "11274 -0.114401  0.002864 -0.076794 -0.09805 -0.083955 -0.1138 -0.105558   \n",
       "11275 -0.244182 -0.041010 -0.102657 -0.09805 -0.083955 -0.1138 -0.105558   \n",
       "\n",
       "            V40        ZN  \n",
       "0      0.640931 -1.069154  \n",
       "1      0.213439 -1.061642  \n",
       "2     -0.223813  1.055072  \n",
       "3      0.119742 -0.261535  \n",
       "4      0.250527  1.083244  \n",
       "...         ...       ...  \n",
       "11271  0.707300 -0.868189  \n",
       "11272  0.432065 -1.027834  \n",
       "11273 -0.471719  1.090757  \n",
       "11274  0.744388 -1.080423  \n",
       "11275 -0.727433  1.271063  \n",
       "\n",
       "[11276 rows x 53 columns]"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = onehot_encode(train_X, [0,2])\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "ccbd786b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder__x0_COMPONENT2</th>\n",
       "      <th>encoder__x0_COMPONENT3</th>\n",
       "      <th>encoder__x0_COMPONENT4</th>\n",
       "      <th>encoder__x1_2008</th>\n",
       "      <th>encoder__x1_2009</th>\n",
       "      <th>encoder__x1_2010</th>\n",
       "      <th>encoder__x1_2011</th>\n",
       "      <th>encoder__x1_2012</th>\n",
       "      <th>encoder__x1_2013</th>\n",
       "      <th>encoder__x1_2014</th>\n",
       "      <th>...</th>\n",
       "      <th>P</th>\n",
       "      <th>PQINDEX</th>\n",
       "      <th>S</th>\n",
       "      <th>SI</th>\n",
       "      <th>TI</th>\n",
       "      <th>U100</th>\n",
       "      <th>U75</th>\n",
       "      <th>V</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.148112</td>\n",
       "      <td>-0.193567</td>\n",
       "      <td>1.731086</td>\n",
       "      <td>-0.144037</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.724868</td>\n",
       "      <td>-1.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.919236</td>\n",
       "      <td>-0.108561</td>\n",
       "      <td>0.708064</td>\n",
       "      <td>-0.169900</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.506242</td>\n",
       "      <td>-1.010931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328918</td>\n",
       "      <td>-0.263000</td>\n",
       "      <td>-0.826040</td>\n",
       "      <td>-0.149210</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.125598</td>\n",
       "      <td>1.124564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079641</td>\n",
       "      <td>-0.255862</td>\n",
       "      <td>-0.809025</td>\n",
       "      <td>-0.092312</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>-0.461959</td>\n",
       "      <td>1.064463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125607</td>\n",
       "      <td>-0.266245</td>\n",
       "      <td>-0.840807</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.174399</td>\n",
       "      <td>1.115173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960067</td>\n",
       "      <td>-0.093636</td>\n",
       "      <td>0.823208</td>\n",
       "      <td>-0.102657</td>\n",
       "      <td>0.041759</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.558946</td>\n",
       "      <td>-0.817478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.303689</td>\n",
       "      <td>0.149054</td>\n",
       "      <td>2.057468</td>\n",
       "      <td>-0.118175</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.660451</td>\n",
       "      <td>-1.061642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.749515</td>\n",
       "      <td>0.192530</td>\n",
       "      <td>1.160719</td>\n",
       "      <td>-0.138865</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.435969</td>\n",
       "      <td>-1.059763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2817</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381956</td>\n",
       "      <td>-0.254564</td>\n",
       "      <td>-0.558727</td>\n",
       "      <td>-0.154382</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>-0.832842</td>\n",
       "      <td>1.009995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099088</td>\n",
       "      <td>-0.266245</td>\n",
       "      <td>-0.826361</td>\n",
       "      <td>-0.154382</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.1138</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.037758</td>\n",
       "      <td>0.925477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2819 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      encoder__x0_COMPONENT2  encoder__x0_COMPONENT3  encoder__x0_COMPONENT4  \\\n",
       "0                        0.0                     1.0                     0.0   \n",
       "1                        0.0                     1.0                     0.0   \n",
       "2                        0.0                     0.0                     0.0   \n",
       "3                        0.0                     0.0                     0.0   \n",
       "4                        0.0                     0.0                     0.0   \n",
       "...                      ...                     ...                     ...   \n",
       "2814                     0.0                     1.0                     0.0   \n",
       "2815                     0.0                     1.0                     0.0   \n",
       "2816                     0.0                     1.0                     0.0   \n",
       "2817                     0.0                     0.0                     1.0   \n",
       "2818                     0.0                     0.0                     0.0   \n",
       "\n",
       "      encoder__x1_2008  encoder__x1_2009  encoder__x1_2010  encoder__x1_2011  \\\n",
       "0                  0.0               0.0               0.0               0.0   \n",
       "1                  0.0               0.0               0.0               0.0   \n",
       "2                  0.0               0.0               0.0               0.0   \n",
       "3                  0.0               0.0               0.0               0.0   \n",
       "4                  0.0               0.0               0.0               1.0   \n",
       "...                ...               ...               ...               ...   \n",
       "2814               1.0               0.0               0.0               0.0   \n",
       "2815               0.0               1.0               0.0               0.0   \n",
       "2816               0.0               0.0               0.0               0.0   \n",
       "2817               0.0               0.0               0.0               0.0   \n",
       "2818               0.0               0.0               0.0               0.0   \n",
       "\n",
       "      encoder__x1_2012  encoder__x1_2013  encoder__x1_2014  ...         P  \\\n",
       "0                  1.0               0.0               0.0  ...  2.148112   \n",
       "1                  0.0               0.0               0.0  ... -0.919236   \n",
       "2                  0.0               0.0               0.0  ...  0.328918   \n",
       "3                  1.0               0.0               0.0  ...  0.079641   \n",
       "4                  0.0               0.0               0.0  ...  0.125607   \n",
       "...                ...               ...               ...  ...       ...   \n",
       "2814               0.0               0.0               0.0  ...  0.960067   \n",
       "2815               0.0               0.0               0.0  ...  2.303689   \n",
       "2816               0.0               0.0               0.0  ... -0.749515   \n",
       "2817               0.0               0.0               0.0  ...  0.381956   \n",
       "2818               1.0               0.0               0.0  ...  0.099088   \n",
       "\n",
       "       PQINDEX         S        SI        TI      U100     U75         V  \\\n",
       "0    -0.193567  1.731086 -0.144037 -0.098050 -0.083955 -0.1138 -0.105558   \n",
       "1    -0.108561  0.708064 -0.169900 -0.098050 -0.083955 -0.1138 -0.105558   \n",
       "2    -0.263000 -0.826040 -0.149210 -0.098050 -0.083955 -0.1138 -0.105558   \n",
       "3    -0.255862 -0.809025 -0.092312 -0.098050 -0.083955 -0.1138 -0.105558   \n",
       "4    -0.266245 -0.840807  0.000794 -0.098050 -0.083955 -0.1138 -0.105558   \n",
       "...        ...       ...       ...       ...       ...     ...       ...   \n",
       "2814 -0.093636  0.823208 -0.102657  0.041759 -0.083955 -0.1138 -0.105558   \n",
       "2815  0.149054  2.057468 -0.118175 -0.098050 -0.083955 -0.1138 -0.105558   \n",
       "2816  0.192530  1.160719 -0.138865 -0.098050 -0.083955 -0.1138 -0.105558   \n",
       "2817 -0.254564 -0.558727 -0.154382 -0.098050 -0.083955 -0.1138 -0.105558   \n",
       "2818 -0.266245 -0.826361 -0.154382 -0.098050 -0.083955 -0.1138 -0.105558   \n",
       "\n",
       "           V40        ZN  \n",
       "0     0.724868 -1.022200  \n",
       "1     0.506242 -1.010931  \n",
       "2     0.125598  1.124564  \n",
       "3    -0.461959  1.064463  \n",
       "4     0.174399  1.115173  \n",
       "...        ...       ...  \n",
       "2814  0.558946 -0.817478  \n",
       "2815  0.660451 -1.061642  \n",
       "2816  0.435969 -1.059763  \n",
       "2817 -0.832842  1.009995  \n",
       "2818  0.037758  0.925477  \n",
       "\n",
       "[2819 rows x 53 columns]"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X = onehot_encode(val_X, [0,2])\n",
    "val_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "41fbb7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder__x0_COMPONENT2</th>\n",
       "      <th>encoder__x0_COMPONENT3</th>\n",
       "      <th>encoder__x0_COMPONENT4</th>\n",
       "      <th>encoder__x1_2008</th>\n",
       "      <th>encoder__x1_2009</th>\n",
       "      <th>encoder__x1_2010</th>\n",
       "      <th>encoder__x1_2011</th>\n",
       "      <th>encoder__x1_2012</th>\n",
       "      <th>encoder__x1_2013</th>\n",
       "      <th>encoder__x1_2014</th>\n",
       "      <th>...</th>\n",
       "      <th>CU</th>\n",
       "      <th>FE</th>\n",
       "      <th>H2O</th>\n",
       "      <th>MN</th>\n",
       "      <th>NI</th>\n",
       "      <th>PQINDEX</th>\n",
       "      <th>TI</th>\n",
       "      <th>V</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261653</td>\n",
       "      <td>-0.354708</td>\n",
       "      <td>-0.042486</td>\n",
       "      <td>-0.240513</td>\n",
       "      <td>-0.193138</td>\n",
       "      <td>-0.261053</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>-0.356550</td>\n",
       "      <td>0.942381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261653</td>\n",
       "      <td>0.231304</td>\n",
       "      <td>-0.042486</td>\n",
       "      <td>0.022458</td>\n",
       "      <td>-0.193138</td>\n",
       "      <td>1.505263</td>\n",
       "      <td>0.041759</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.338368</td>\n",
       "      <td>-1.084180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144825</td>\n",
       "      <td>-0.370130</td>\n",
       "      <td>-0.042486</td>\n",
       "      <td>-0.240513</td>\n",
       "      <td>-0.193138</td>\n",
       "      <td>-0.260405</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>-1.273998</td>\n",
       "      <td>0.234305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238287</td>\n",
       "      <td>-0.022047</td>\n",
       "      <td>-0.042486</td>\n",
       "      <td>0.110115</td>\n",
       "      <td>-0.193138</td>\n",
       "      <td>4.928233</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.648739</td>\n",
       "      <td>-0.930169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222710</td>\n",
       "      <td>-0.352505</td>\n",
       "      <td>-0.042486</td>\n",
       "      <td>-0.240513</td>\n",
       "      <td>-0.193138</td>\n",
       "      <td>-0.257160</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>-0.901163</td>\n",
       "      <td>-0.225850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743064</td>\n",
       "      <td>1.925452</td>\n",
       "      <td>-0.042486</td>\n",
       "      <td>5.457192</td>\n",
       "      <td>0.339663</td>\n",
       "      <td>1.029617</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>-0.748906</td>\n",
       "      <td>1.077610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253864</td>\n",
       "      <td>1.240302</td>\n",
       "      <td>-0.042486</td>\n",
       "      <td>0.197772</td>\n",
       "      <td>-0.193138</td>\n",
       "      <td>0.182148</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>0.551138</td>\n",
       "      <td>-1.082302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269441</td>\n",
       "      <td>-0.264383</td>\n",
       "      <td>-0.042486</td>\n",
       "      <td>-0.240513</td>\n",
       "      <td>-0.193138</td>\n",
       "      <td>-0.222768</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>3.760255</td>\n",
       "      <td>-1.082302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213446</td>\n",
       "      <td>-0.376739</td>\n",
       "      <td>-0.042486</td>\n",
       "      <td>-0.240513</td>\n",
       "      <td>-0.193138</td>\n",
       "      <td>-0.264298</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>-1.141261</td>\n",
       "      <td>-0.208946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269441</td>\n",
       "      <td>-0.372333</td>\n",
       "      <td>-0.042486</td>\n",
       "      <td>-0.240513</td>\n",
       "      <td>-0.193138</td>\n",
       "      <td>-0.258458</td>\n",
       "      <td>-0.098050</td>\n",
       "      <td>-0.105558</td>\n",
       "      <td>-0.577128</td>\n",
       "      <td>0.715120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6041 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      encoder__x0_COMPONENT2  encoder__x0_COMPONENT3  encoder__x0_COMPONENT4  \\\n",
       "0                        0.0                     0.0                     0.0   \n",
       "1                        0.0                     1.0                     0.0   \n",
       "2                        1.0                     0.0                     0.0   \n",
       "3                        0.0                     1.0                     0.0   \n",
       "4                        1.0                     0.0                     0.0   \n",
       "...                      ...                     ...                     ...   \n",
       "6036                     0.0                     1.0                     0.0   \n",
       "6037                     0.0                     1.0                     0.0   \n",
       "6038                     0.0                     1.0                     0.0   \n",
       "6039                     1.0                     0.0                     0.0   \n",
       "6040                     0.0                     0.0                     0.0   \n",
       "\n",
       "      encoder__x1_2008  encoder__x1_2009  encoder__x1_2010  encoder__x1_2011  \\\n",
       "0                  0.0               0.0               0.0               0.0   \n",
       "1                  0.0               0.0               0.0               1.0   \n",
       "2                  0.0               0.0               1.0               0.0   \n",
       "3                  0.0               1.0               0.0               0.0   \n",
       "4                  0.0               0.0               0.0               0.0   \n",
       "...                ...               ...               ...               ...   \n",
       "6036               0.0               0.0               0.0               0.0   \n",
       "6037               0.0               0.0               0.0               0.0   \n",
       "6038               0.0               0.0               0.0               0.0   \n",
       "6039               0.0               0.0               0.0               0.0   \n",
       "6040               0.0               0.0               0.0               0.0   \n",
       "\n",
       "      encoder__x1_2012  encoder__x1_2013  encoder__x1_2014  ...        CU  \\\n",
       "0                  0.0               0.0               0.0  ... -0.261653   \n",
       "1                  0.0               0.0               0.0  ... -0.261653   \n",
       "2                  0.0               0.0               0.0  ... -0.144825   \n",
       "3                  0.0               0.0               0.0  ... -0.238287   \n",
       "4                  0.0               1.0               0.0  ... -0.222710   \n",
       "...                ...               ...               ...  ...       ...   \n",
       "6036               0.0               0.0               1.0  ...  0.743064   \n",
       "6037               0.0               0.0               0.0  ... -0.253864   \n",
       "6038               0.0               0.0               1.0  ... -0.269441   \n",
       "6039               0.0               1.0               0.0  ...  0.213446   \n",
       "6040               0.0               0.0               0.0  ... -0.269441   \n",
       "\n",
       "            FE       H2O        MN        NI   PQINDEX        TI         V  \\\n",
       "0    -0.354708 -0.042486 -0.240513 -0.193138 -0.261053 -0.098050 -0.105558   \n",
       "1     0.231304 -0.042486  0.022458 -0.193138  1.505263  0.041759 -0.105558   \n",
       "2    -0.370130 -0.042486 -0.240513 -0.193138 -0.260405 -0.098050 -0.105558   \n",
       "3    -0.022047 -0.042486  0.110115 -0.193138  4.928233 -0.098050 -0.105558   \n",
       "4    -0.352505 -0.042486 -0.240513 -0.193138 -0.257160 -0.098050 -0.105558   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6036  1.925452 -0.042486  5.457192  0.339663  1.029617 -0.098050 -0.105558   \n",
       "6037  1.240302 -0.042486  0.197772 -0.193138  0.182148 -0.098050 -0.105558   \n",
       "6038 -0.264383 -0.042486 -0.240513 -0.193138 -0.222768 -0.098050 -0.105558   \n",
       "6039 -0.376739 -0.042486 -0.240513 -0.193138 -0.264298 -0.098050 -0.105558   \n",
       "6040 -0.372333 -0.042486 -0.240513 -0.193138 -0.258458 -0.098050 -0.105558   \n",
       "\n",
       "           V40        ZN  \n",
       "0    -0.356550  0.942381  \n",
       "1     0.338368 -1.084180  \n",
       "2    -1.273998  0.234305  \n",
       "3     0.648739 -0.930169  \n",
       "4    -0.901163 -0.225850  \n",
       "...        ...       ...  \n",
       "6036 -0.748906  1.077610  \n",
       "6037  0.551138 -1.082302  \n",
       "6038  3.760255 -1.082302  \n",
       "6039 -1.141261 -0.208946  \n",
       "6040 -0.577128  0.715120  \n",
       "\n",
       "[6041 rows x 33 columns]"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = onehot_encode(test, [0,2])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "47c3bd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['encoder__x0_COMPONENT2', 'encoder__x0_COMPONENT3',\n",
       "       'encoder__x0_COMPONENT4', 'encoder__x1_2008', 'encoder__x1_2009',\n",
       "       'encoder__x1_2010', 'encoder__x1_2011', 'encoder__x1_2012',\n",
       "       'encoder__x1_2013', 'encoder__x1_2014', 'encoder__x1_2015',\n",
       "       'encoder__x1_2016', 'encoder__x1_2017', 'encoder__x1_2018',\n",
       "       'encoder__x1_2019', 'encoder__x1_2020', 'encoder__x1_2021',\n",
       "       'encoder__x1_2022', 'ANONYMOUS_1', 'ANONYMOUS_2', 'AG', 'CO', 'CR',\n",
       "       'CU', 'FE', 'H2O', 'MN', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stage_features = test.columns\n",
    "# Inference(실제 진단 환경)에 사용하는 컬럼\n",
    "test_stage_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "cd0465e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 33\n"
     ]
    }
   ],
   "source": [
    "train_col_num = len(train_X.columns)\n",
    "test_col_num = len(test.columns)\n",
    "print(train_col_num, test_col_num) # Drop후 칼럼 갯수 (nn 시작 노드 갯수에 맞춰주기 위해 변수에 담아놓음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "110b82ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#저장하기\n",
    "with open(f\"./data/refined_train_X{file_version}\", 'wb') as pickle_filename:\n",
    "\tpickle.dump(train_X, pickle_filename)\n",
    "\n",
    "with open(f\"./data/refined_train_y{file_version}\", 'wb') as pickle_filename:\n",
    "\tpickle.dump(train_y, pickle_filename)\n",
    "    \n",
    "with open(f\"./data/refined_val_X{file_version}\", 'wb') as pickle_filename:\n",
    "\tpickle.dump(val_X, pickle_filename)\n",
    "\n",
    "with open(f\"./data/refined_val_y{file_version}\", 'wb') as pickle_filename:\n",
    "\tpickle.dump(val_y, pickle_filename)\n",
    "    \n",
    "with open(f\"./data/refined_test{file_version}\", 'wb') as pickle_filename:\n",
    "\tpickle.dump(test, pickle_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "0589360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불러오기\n",
    "with open(f\"./data/refined_train_X{file_version}\", 'rb') as pickle_filename:\n",
    "\ttrain_X = pickle.load(pickle_filename)\n",
    "\n",
    "with open(f\"./data/refined_train_y{file_version}\", 'rb') as pickle_filename:\n",
    "\ttrain_y = pickle.load(pickle_filename)\n",
    "    \n",
    "with open(f\"./data/refined_val_X{file_version}\", 'rb') as pickle_filename:\n",
    "\tval_X = pickle.load(pickle_filename)\n",
    "\n",
    "with open(f\"./data/refined_val_y{file_version}\", 'rb') as pickle_filename:\n",
    "\tval_y = pickle.load(pickle_filename)     \n",
    "\n",
    "with open(f\"./data/refined_test{file_version}\", 'rb') as pickle_filename:\n",
    "\ttest = pickle.load(pickle_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "217d12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_X, data_y, distillation=False):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.data_X = data_X\n",
    "        self.data_y = data_y\n",
    "        self.distillation = distillation\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.distillation:\n",
    "            # 지식 증류 학습 시\n",
    "            teacher_X = torch.Tensor(self.data_X.iloc[index])\n",
    "            student_X = torch.Tensor(self.data_X[test_stage_features].iloc[index])\n",
    "            y = self.data_y.values[index]\n",
    "            return teacher_X, student_X, y\n",
    "        else:\n",
    "            if self.data_y is None:\n",
    "                test_X = torch.Tensor(self.data_X.iloc[index])\n",
    "                return test_X\n",
    "            else:\n",
    "                teacher_X = torch.Tensor(self.data_X.iloc[index])\n",
    "                y = self.data_y.values[index]\n",
    "                return teacher_X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "48b7e9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([ 0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0669, -0.2194, -0.3408, -0.1499, -0.1096,  0.4295,\n",
       "          -0.3082, -0.0407,  1.1846, -0.1179, -0.0117, -0.2461, -0.0375, -0.2828,\n",
       "          -0.3583, -0.2119, -0.0549, -0.1256, -0.1072, -0.0425, -0.1360, -0.2854,\n",
       "           0.0225,  0.6670, -0.1931,  2.7174,  0.2159,  2.3507, -0.1130, -0.0980,\n",
       "          -0.0840, -0.1138, -0.1056,  0.6409, -1.0692]),\n",
       "  0),\n",
       " (tensor([ 0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.5727, -0.2194, -0.3408, -0.1499, -0.1649, -0.4277,\n",
       "          -0.3082, -0.0407, -0.7973, -0.1179, -0.1089, -0.2539, -0.0375, -0.2828,\n",
       "          -0.3583, -0.2119, -0.0549, -0.2203, -0.1072, -0.0425, -0.2017, -0.2854,\n",
       "          -0.2405, -0.0705, -0.1931,  0.2741,  0.6643,  0.7915, -0.1544, -0.0980,\n",
       "          -0.0840, -0.1138, -0.1056,  0.2134, -1.0616]),\n",
       "  0)]"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = CustomDataset(train_X, train_y, False)\n",
    "val_dataset = CustomDataset(val_X, val_y, False)\n",
    "list(train_dataset)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "50bab7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[ 0.0000,  0.0000,  1.0000,  ..., -0.1056, -0.7879,  0.4033],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ..., -0.1056,  0.0612,  1.5040],\n",
       "          [ 0.0000,  0.0000,  1.0000,  ..., -0.1056, -0.7216,  1.1039],\n",
       "          ...,\n",
       "          [ 1.0000,  0.0000,  0.0000,  ..., -0.1056, -1.2584,  0.2287],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ..., -0.1056, -0.4249,  0.8973],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ..., -0.1056, -0.3644,  1.0025]]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0])],\n",
       " [tensor([[ 0.0000,  1.0000,  0.0000,  ..., -0.1056,  0.3052, -1.0447],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ..., -0.1056, -0.1789,  0.5085],\n",
       "          [ 0.0000,  1.0000,  0.0000,  ..., -0.1056,  1.1211, -1.0748],\n",
       "          ...,\n",
       "          [ 0.0000,  1.0000,  0.0000,  ..., -0.1056,  5.3336, -0.9677],\n",
       "          [ 0.0000,  1.0000,  0.0000,  ..., -0.1056,  0.6331, -1.0053],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ..., -0.1056, -0.1457,  0.6907]]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])]]"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False)\n",
    "list(train_loader)[:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "db671aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Teacher, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=train_col_num, out_features=256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=CFG['drop_p']),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=256, out_features=1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(p=CFG['drop_p']),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=CFG['drop_p']),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=256, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7cd916",
   "metadata": {},
   "source": [
    "#### BCELOSS : https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "c13f0b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    # Loss Function 정의\n",
    "    criterion = nn.BCELoss(reduction=CFG[\"reduct\"]).to(device)\n",
    "\n",
    "    for epoch in range(CFG[\"EPOCHS\"]):\n",
    "        train_loss = []\n",
    "  \n",
    "        model.train()\n",
    "        for X, y in tqdm(train_loader):\n",
    "            X = X.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_pred = model(X)\n",
    "            \n",
    "            loss = criterion(y_pred, y.reshape(-1, 1))  # loss_fn(input, target)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        val_loss, val_score = validation_teacher(model, val_loader, criterion, device)\n",
    "        \n",
    "        print(f'Epoch [{epoch}], Train Loss : [{np.mean(train_loss) :.5f}] Val Loss : [{np.mean(val_loss) :.5f}] Val F1 Score : [{val_score:.5f}]')\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_score)\n",
    "            \n",
    "        if best_score < val_score:\n",
    "            best_model = model\n",
    "            best_score = val_score\n",
    "    print(f\"Teacher Train Best Score는 {best_score} 입니다.\")\n",
    "    return best_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "f183e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def competition_metric(true, pred):\n",
    "    return f1_score(true, pred, average=\"macro\")\n",
    "\n",
    "def validation_teacher(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = []\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    threshold = CFG['T_Thresh']     \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(val_loader):\n",
    "            X = X.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            model_pred = model(X.to(device))\n",
    "            \n",
    "            loss = criterion(model_pred, y.reshape(-1, 1))\n",
    "            val_loss.append(loss.item())      \n",
    "            \n",
    "            model_pred = model_pred.squeeze(1).to('cpu')  # squeeze함수는 차원이 1인 차원을 제거해준다.\n",
    "            pred_labels += model_pred.tolist()\n",
    "            true_labels += y.tolist()\n",
    "        \n",
    "        #print(pred_labels[0:10])\n",
    "        # 오일상태는 0: 정상, 1: 이상\n",
    "        # 어느 임계점 thrshold보다 큰 예측 라벨을 1로 하고, 나머지를 0으로 할 것인가?\n",
    "        pred_labels = np.where(np.array(pred_labels) > threshold, 1, 0)\n",
    "        #print(pred_labels[0:10])\n",
    "        \n",
    "        val_f1 = competition_metric(true_labels, pred_labels)\n",
    "    return val_loss, val_f1   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5e1be",
   "metadata": {},
   "source": [
    "#### 옵티마이저 (Optimizer)\n",
    "\n",
    "+ 손실 함수를 기반으로 모델이 어떻게 업데이트해야하는지를 결정 \n",
    "\n",
    "+ optimizer는 step()을 통해 전달받은 파라미터를 모델 업데이트\n",
    "\n",
    "+ 모든 옵티마이저는 기본으로 torch.optim.Optimzer(params, defaults) 클래스를 사용\n",
    "\n",
    "+ zero_grad()를 이용해 옵티마이저에 사용된 파라미터의 기울기를 0으로 설정\n",
    "\n",
    "+ torch.optim.lr_scheduler를 이용해 epoch에 따라 학습률 조절\n",
    "\n",
    "+ 파이토치 주요 옵티마이저: optim.Adadelta, optim.Adagrad, optim.Adam , optim.RMSprop, optim.SGD\n",
    "\n",
    "* TORCH.OPTIM : https://pytorch.org/docs/stable/optim.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f4e816",
   "metadata": {},
   "source": [
    "#### 학습률 스케줄러 (Learning rate scheduler)\n",
    "\n",
    "+ 학습시 특성 조건에 따라 학습률을 조정하여 최적화 진행\n",
    "\n",
    "+ 일정 횟수 이상이 되면 학습률을 감소시키거나, 전역 최소점 근처에가 하면 학습률을 줄이는 등  \n",
    "\n",
    "+ optim.lr_scheduler.LamdbaLR : 람다 함수를 이용해 그 결과를 학습률로 설정\n",
    "\n",
    "+ optim.lr_scheduler.StepLR : 단계 마다 학습률을 감마 비율로 감소\n",
    "\n",
    "+ optim.lr_scheduler.MultiStepLR : StepLR과 비슷하지만 지정된 에포카에서만 감마 비율로 감소\n",
    "\n",
    "+ optim.lr_scheduler.ExponentialLR : epoch마다 이전 학습률에 감마만큼 곱함\n",
    "\n",
    "+ optim.lr_scheduler.CosineAnnealingLR : 학습률을 코사인 함수의 형태로 변화시켜 학습률을 조절\n",
    "\n",
    "+ optim.lr_scheduler.ReduceLROnPlateau : 학습이 잘 되는지 아닌지에 따라 동적으로 학습률 변화 \n",
    "+ 링크 : https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html?highlight=reducelronplateau#torch.optim.lr_scheduler.ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "466f5872",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "------------------------------\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165025f62026405f8f4f49ee5ae1544c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbab2c7fe2d8430caf211fcb0b99f56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [58.54288] Val Loss : [40.83861] Val F1 Score : [0.81518]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ca416b2fd141019b4cbab708ebee4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc26251627ca4198aaca1a61b4310eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [45.12052] Val Loss : [39.71172] Val F1 Score : [0.81062]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b247ea95f9c43c5a64095fbff54ac54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef16a407fa2479d8ae484b59728e280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [40.95422] Val Loss : [38.10140] Val F1 Score : [0.81402]\n",
      "Epoch 00003: reducing learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af433dd195494137abcbda95364f892d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f2c7a99a4841f5baea1d0bb68f4685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [38.76433] Val Loss : [37.72807] Val F1 Score : [0.81717]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20274936f0dd495888a7114b2b22ed12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e153c15c144ee891459335642169a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [35.98156] Val Loss : [38.47191] Val F1 Score : [0.80959]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b44ae96fd8f443fb9121a27bbd8313e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fbe68c0da174a8f890228a72e33ccfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [34.95864] Val Loss : [39.23111] Val F1 Score : [0.79711]\n",
      "Epoch 00006: reducing learning rate of group 0 to 2.5000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6547574b2ff6495dbf72b9885a7c005c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045d3133ce9c4b8c88eddff09b7a7b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [32.18836] Val Loss : [39.07606] Val F1 Score : [0.81175]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fbb892d9455442b9384aa7db3accce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3b0dfb423d4822b25c95a575a6662b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [30.87383] Val Loss : [39.87220] Val F1 Score : [0.81041]\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.2500e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed5303a92024d5da8e53ffb9a66fd68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d4a5f7df4143eb9f0394c9f600ea08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [28.87156] Val Loss : [40.64657] Val F1 Score : [0.80270]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b333e5d914dd43ce9a79660ff7f144ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81552deccee8476898ba02db746ea2e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [27.52665] Val Loss : [42.20159] Val F1 Score : [0.80931]\n",
      "Epoch 00010: reducing learning rate of group 0 to 6.2500e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd2b847028a4c68896482a53656c2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c24e76169c4808a3b1373ab7f27e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [25.42081] Val Loss : [41.74238] Val F1 Score : [0.81605]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21104eb4d44b47248cdd736841f1c4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbd2b78e88a429e8abbdbbc70361533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [24.69127] Val Loss : [44.00047] Val F1 Score : [0.78629]\n",
      "Epoch 00012: reducing learning rate of group 0 to 3.1250e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5aee97901e47daba2b423f0a8347ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5d164bb1fb452b85820e9d18224967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [23.96260] Val Loss : [42.62296] Val F1 Score : [0.80836]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbcf9dcc86646fc8915fc820dc90e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89a8af9126e4b69a41470100b6f29ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [23.00214] Val Loss : [43.91697] Val F1 Score : [0.81597]\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.5625e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae40fa181912445aa1d63e4b5904be55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3194b21f695f4766849f2246cb17e800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [22.75997] Val Loss : [43.78376] Val F1 Score : [0.80999]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91165991b41c4d7aaf47c78c4397afdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d1239b9a9a47d49566b3bd8f74f025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Train Loss : [22.12780] Val Loss : [44.35823] Val F1 Score : [0.80350]\n",
      "Epoch 00016: reducing learning rate of group 0 to 7.8125e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63b1b1d0f9046dca61c156ad73d4634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4f35a1611544d68202736c46f8b2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Train Loss : [21.85436] Val Loss : [44.01054] Val F1 Score : [0.80903]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ba2df7742c487cb5e43f2ce98df97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1da8f80899d4e2891f579de3514faa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Train Loss : [21.33538] Val Loss : [45.27459] Val F1 Score : [0.80505]\n",
      "Epoch 00018: reducing learning rate of group 0 to 3.9063e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25aab749bf9345c7bd88ae37d8cfd8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810e714ad1b04d139553d47922eece83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Train Loss : [21.60313] Val Loss : [45.24181] Val F1 Score : [0.80587]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e09eda7a5cd4ea6bcdd83963767c64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0d632907174fadb914740abe0e960c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Train Loss : [21.23878] Val Loss : [45.38057] Val F1 Score : [0.79809]\n",
      "Epoch 00020: reducing learning rate of group 0 to 1.9531e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286ad708a70c42c1a1843f5ca46c0191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abd891551f043a3b3293d12cea0bd04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Train Loss : [21.04919] Val Loss : [44.02147] Val F1 Score : [0.81834]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3ec95aeec64295b4e7272929a5c589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab5b73557f34b90a3ffb5171df53e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Train Loss : [21.38878] Val Loss : [44.83651] Val F1 Score : [0.80994]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71405b000f94871aea6cc303e0dcb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba86f3aa2e14fd395b6dcf228f551de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Train Loss : [21.66888] Val Loss : [44.01445] Val F1 Score : [0.81163]\n",
      "Epoch 00023: reducing learning rate of group 0 to 9.7656e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff00fe4cd9324c398f0a464a853e5ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d550cb92308b4dc995d4cb0e65090cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Train Loss : [21.25690] Val Loss : [44.51148] Val F1 Score : [0.79659]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0d540a48814358a1d654bfe035c781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24aa8e668ae455e879af13c03b014b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Train Loss : [21.35381] Val Loss : [46.00065] Val F1 Score : [0.78701]\n",
      "Epoch 00025: reducing learning rate of group 0 to 4.8828e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0037ad3e2c294940bff5c7c46da5cdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d3837cc515425d9cbad3eacd55d955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Train Loss : [21.27909] Val Loss : [45.04483] Val F1 Score : [0.78986]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033818fa67fe4a9280f5592f115d5a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799c60a80de849e7a7b954534436caa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Train Loss : [21.02602] Val Loss : [44.92903] Val F1 Score : [0.82377]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7182a49ed47a40d8825b13a7601726f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f85f2b69b714381b4124d1e13fb469d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Train Loss : [21.40947] Val Loss : [44.02776] Val F1 Score : [0.81854]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3911798eaa5947838300ef081e917094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcec40266fd4075a07b1de5215f2bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Train Loss : [21.55055] Val Loss : [44.98437] Val F1 Score : [0.82189]\n",
      "Epoch 00029: reducing learning rate of group 0 to 2.4414e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af31c8f7ce942ffbf90ecf4ae1c6376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16994b09830442d0b687185a41718aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], Train Loss : [21.18143] Val Loss : [44.01791] Val F1 Score : [0.81075]\n",
      "Teacher Train Best Score는 0.8237684421105277 입니다.\n"
     ]
    }
   ],
   "source": [
    "model = Teacher()\n",
    "model.eval()\n",
    "print(\"-\"*30)\n",
    "# print(list(model.parameters()))   # check out the parameters\n",
    "print(\"-\"*30)\n",
    "# print(model.state_dict())   # list the named parameters\n",
    "print(\"-\"*30)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1, threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "\n",
    "teacher_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "627a68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./models/teacher_net{file_version}.pth\"\n",
    "torch.save(teacher_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "89707003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model = Teacher()\n",
    "teacher_model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "b5047ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Student, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=test_col_num, out_features=128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(p=CFG['drop_p']),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=128, out_features=512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=CFG['drop_p']),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=512, out_features=128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(p=CFG['drop_p']),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=128, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "fa70fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function 정의\n",
    "\n",
    "def distillation(student_logits, labels, teacher_logits, alpha):\n",
    "    \n",
    "    distillation_loss = nn.BCELoss(reduction=CFG[\"reduct\"])(student_logits, teacher_logits)\n",
    "    student_loss = nn.BCELoss()(student_logits, labels.reshape(-1, 1))\n",
    "    \n",
    "    \n",
    "    return alpha * student_loss + (1-alpha) * distillation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "c0faeae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distill_loss(output, target, teacher_output, loss_fn=distillation, opt=optimizer):\n",
    "    loss_b = loss_fn(output, target, teacher_output, alpha=0.1)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss_b.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss_b.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "c48a9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_train(s_model, t_model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    s_model.to(device)\n",
    "    t_model.to(device)\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(CFG[\"EPOCHS\"]):\n",
    "        train_loss = []\n",
    "        s_model.train()\n",
    "        t_model.eval()\n",
    "        \n",
    "        for X_t, X_s, y in tqdm(train_loader):\n",
    "            X_t = X_t.float().to(device)\n",
    "            X_s = X_s.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = s_model(X_s)\n",
    "            with torch.no_grad():\n",
    "                teacher_output = t_model(X_t)\n",
    "                \n",
    "            loss_b = distill_loss(output, y, teacher_output, loss_fn=distillation, opt=optimizer)\n",
    "\n",
    "            train_loss.append(loss_b)\n",
    "\n",
    "        val_loss, val_score = validation_student(s_model, t_model, val_loader, distill_loss, device)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{np.mean(train_loss) :.5f}] Val Loss : [{np.mean(val_loss) :.5f}] Val F1 Score : [{val_score:.5f}]')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_score)\n",
    "            \n",
    "        if best_score < val_score:\n",
    "            best_model = s_model\n",
    "            best_score = val_score\n",
    "    \n",
    "    print(f\"Student Train Best Score는 {best_score} 입니다.\")\n",
    "        \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "40c58ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_student(s_model, t_model, val_loader, criterion, device):\n",
    "    s_model.eval()\n",
    "    t_model.eval()\n",
    "\n",
    "    val_loss = []\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    threshold = CFG['S_Thresh']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_t, X_s, y in tqdm(val_loader):\n",
    "            X_t = X_t.float().to(device)\n",
    "            X_s = X_s.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            model_pred = s_model(X_s)\n",
    "            teacher_output = t_model(X_t)\n",
    "            \n",
    "            loss_b = distill_loss(model_pred, y, teacher_output, loss_fn=distillation, opt=None)\n",
    "            val_loss.append(loss_b)\n",
    "            \n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            pred_labels += model_pred.tolist()\n",
    "            true_labels += y.tolist()\n",
    "        \n",
    "        pred_labels = np.where(np.array(pred_labels) > threshold, 1, 0)\n",
    "        val_f1 = competition_metric(true_labels, pred_labels)\n",
    "    return val_loss, val_f1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "d9a826b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_X, train_y, True)\n",
    "val_dataset = CustomDataset(val_X, val_y, True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "fb3e89bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c84e6d3b124581a6a25220295c9807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e15c3fcc7f4a4aa83ef53202a7c3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [71.49958] Val Loss : [57.55123] Val F1 Score : [0.48846]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb7e8034cab44fda28cb1134281ba0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e873d4d1d384cb2867db3ae444a0847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [61.90295] Val Loss : [57.08297] Val F1 Score : [0.48708]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41a64726c92400a8cc5bdbb74e730a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69532d8fc2294069aedfc61ca2639306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [61.07176] Val Loss : [55.74254] Val F1 Score : [0.49514]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21cd793d6b3e43fc8ce1864ea5afba23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466bca8954a545f1b058062d4f292df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [60.00526] Val Loss : [55.36090] Val F1 Score : [0.50150]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2ccbae1a30480b8a4e40edc992af4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d108e2605bde432dabc04539984999a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [59.62777] Val Loss : [56.67359] Val F1 Score : [0.51630]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489e957c572145a4af0de150066b04d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7365a0b24bf04fe18b12cb8c85102d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [59.24992] Val Loss : [55.12876] Val F1 Score : [0.54666]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24c4bb0014b43cab7e01e95813eab20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db40251005f74d74a7e858070c40db00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [58.81344] Val Loss : [56.00815] Val F1 Score : [0.50131]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c185fd879b4064b6409aaa679dc1bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7480a382f7f547d588ff9da7524aabae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [58.76152] Val Loss : [56.05918] Val F1 Score : [0.50002]\n",
      "Epoch 00008: reducing learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dacb62bf1ac44a30a02eae191c12e467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e37f121f5d7444a81e4bf720525f4f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [57.22662] Val Loss : [56.06219] Val F1 Score : [0.54778]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1925a678684e4e93abd82d843eaec9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4776cdef5b84bf4b4f1786dc92a372d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [56.80024] Val Loss : [56.76622] Val F1 Score : [0.53979]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c0e668ed3f45e18cd1815556ea2987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e68f7b767b4bfd8972490b7bcd75a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [56.42064] Val Loss : [55.52934] Val F1 Score : [0.54407]\n",
      "Epoch 00011: reducing learning rate of group 0 to 2.5000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c921b26aac874455822c294c6992ff74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003a31b0232a4dd28ccddc21d0c07888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [55.66106] Val Loss : [55.54372] Val F1 Score : [0.54905]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad40518b6c6f4e5a8fa9899f9db700ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b383b5a74a45eb87452df617cec6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [55.26685] Val Loss : [56.64359] Val F1 Score : [0.55764]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ffd8b6ac0f42dd849262267dafd066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd262411fd7424492917a4ed6ad730d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [54.84243] Val Loss : [56.62895] Val F1 Score : [0.54808]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6123ff7b1ac40ad958efb01bc999126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cab2d03ca5a4f7e80d3d41629f711cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [54.53430] Val Loss : [56.64868] Val F1 Score : [0.53033]\n",
      "Epoch 00015: reducing learning rate of group 0 to 1.2500e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b085892efb4db1a7a3cb9d07f5e81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebac855715f042a9ba7f998af3187bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Train Loss : [54.01412] Val Loss : [57.25967] Val F1 Score : [0.55253]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275ea286dd814c75a5f1c98a1e813025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5423fe797a1d4ee0ae32ad1bcddc587e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Train Loss : [53.57227] Val Loss : [56.32880] Val F1 Score : [0.54584]\n",
      "Epoch 00017: reducing learning rate of group 0 to 6.2500e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c02a6d770b4845859302d1da88dfa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ab5aafabbe457490cf299163894e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Train Loss : [53.08401] Val Loss : [56.51326] Val F1 Score : [0.54064]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d46f691cf845cdbdbb4803342107e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319d6cb603e444a9ab289305b72a43b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Train Loss : [52.77612] Val Loss : [58.12414] Val F1 Score : [0.55880]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379a0ddd662c4133ac51454c7d0ef62e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7cdbc58d3047cf822e123d3cb739b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Train Loss : [52.69601] Val Loss : [57.34368] Val F1 Score : [0.55242]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9389c99a128c4810809c9b876a414ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f3cd6aae3a48f2a0016ed11be93a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Train Loss : [52.54927] Val Loss : [56.88538] Val F1 Score : [0.54648]\n",
      "Epoch 00021: reducing learning rate of group 0 to 3.1250e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10559000e61a41fa8d3e360298231b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94beaba5c5b49099ef32860ecba5970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Train Loss : [52.20005] Val Loss : [57.39043] Val F1 Score : [0.56295]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba347c6c162a4d68b135d089e133fb7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c30f6968f9c4e3a97c44a1401520805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Train Loss : [52.14010] Val Loss : [57.55277] Val F1 Score : [0.55419]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d4e19ff4534dafaa320cff0eb42d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18857f01ff1b40a88053569cc83d47dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Train Loss : [51.91685] Val Loss : [57.10961] Val F1 Score : [0.56524]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd33145fc55440f5a56c267ef93f35c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ac41c78ecd43fca84948e4cb989ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Train Loss : [51.93077] Val Loss : [57.47592] Val F1 Score : [0.55176]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae150d568c140f6b4441435180bc279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ef31a446594ab5a43271e2bdeab749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Train Loss : [51.80195] Val Loss : [57.35273] Val F1 Score : [0.54832]\n",
      "Epoch 00026: reducing learning rate of group 0 to 1.5625e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739d76d9f9e04ef0b0c7122dd47cd09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd32083799d440eaa623ef797a317617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Train Loss : [51.78518] Val Loss : [57.34876] Val F1 Score : [0.55555]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97915ad03aa6479ead5bec5b9169fd97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da27caf0512426aa7b1c704458500fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Train Loss : [51.61250] Val Loss : [57.49995] Val F1 Score : [0.53706]\n",
      "Epoch 00028: reducing learning rate of group 0 to 7.8125e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066b93e2e1b545cb9d756443e77c455f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390e864393664ae58fb54104988cb609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Train Loss : [51.46853] Val Loss : [58.58504] Val F1 Score : [0.55295]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec120b984c9408b9f4c1b1aac28bc22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62bc8d8007645c0b4da9ef722731365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], Train Loss : [51.59907] Val Loss : [57.81631] Val F1 Score : [0.55625]\n",
      "Epoch 00030: reducing learning rate of group 0 to 3.9063e-05.\n",
      "Student Train Best Score는 0.5652449063812226 입니다.\n"
     ]
    }
   ],
   "source": [
    "student_model = Student()\n",
    "student_model.eval()\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1, threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "\n",
    "best_student_model = student_train(student_model, teacher_model, optimizer, train_loader, val_loader, scheduler, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "7daa9177",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH1 = f\"./models/student_net{file_version}.pth\"\n",
    "torch.save(best_student_model.state_dict(), PATH1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "e0685b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_student_model = Student()\n",
    "best_student_model.load_state_dict(torch.load(PATH1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "14972350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_threshold(model, val_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "#     thresholds = [0.1, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "    thresholds = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    \n",
    "    best_score = 0\n",
    "    best_thr = None\n",
    "    with torch.no_grad():\n",
    "        for _, x_s, y in tqdm(iter(val_loader)):\n",
    "            x_s = x_s.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            model_pred = model(x_s)\n",
    "            \n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            pred_labels += model_pred.tolist()\n",
    "            true_labels += y.tolist()\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            pred_labels_thr = np.where(np.array(pred_labels) > threshold, 1, 0)\n",
    "            score_thr = competition_metric(true_labels, pred_labels_thr)\n",
    "            if best_score < score_thr:\n",
    "                best_score = score_thr\n",
    "                best_thr = threshold\n",
    "    return best_thr, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "e27a1c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1181078adb8c4a13ab445e77ddb9a697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold : [0.25], Score : [0.57517]\n"
     ]
    }
   ],
   "source": [
    "best_threshold, best_score = choose_threshold(best_student_model, val_loader, device)\n",
    "print(f'Best Threshold : [{best_threshold}], Score : [{best_score:.5f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "2d43cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets = CustomDataset(test, None, False)\n",
    "test_loaders = DataLoader(test_datasets, batch_size = CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "830cde01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, threshold, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    # .eval함수는 evaluation 과정에서 사용하지 말아야 하는 layer들을 알아서 off 시키는 함수\n",
    "    \n",
    "    test_predict = []\n",
    "    with torch.no_grad():\n",
    "        for x in tqdm(test_loader):\n",
    "            x = x.float().to(device)\n",
    "            model_pred = model(x)\n",
    "\n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            test_predict += model_pred\n",
    "        \n",
    "    test_predict = np.where(np.array(test_predict) > threshold, 1, 0)  \n",
    "    # threshhold 보다 큰 값을 찾아서 1로 바꾸고, 아닌 것은 0으로 변경해라\n",
    "    print('Done.')\n",
    "    return test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "ccb78109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139a2d4df47f4d06952cfc148d2b1831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "preds = inference(best_student_model, test_loaders, best_threshold, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "1776ac77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Y_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Y_LABEL\n",
       "0  TEST_0000        0\n",
       "1  TEST_0001        0\n",
       "2  TEST_0002        0\n",
       "3  TEST_0003        0\n",
       "4  TEST_0004        0"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit['Y_LABEL'] = preds\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "ee7db9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(f'./submits/submit{file_version}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ef03dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
